{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"21-8-14-1 training.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"HdWZctCnRBKG"},"source":["# GPU Check"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"h3Wbn3yeIxD2","executionInfo":{"status":"ok","timestamp":1628957001662,"user_tz":-360,"elapsed":16,"user":{"displayName":"Md.safirur Rashid, 170041020","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj4vsxiS6hdwcIxlWkCOlOKX6Yb9qvDnhTv0OE=s64","userId":"07083869211232678860"}},"outputId":"f9976d6f-1b53-4dad-80f9-e8f8b38c488c"},"source":["!nvidia-smi -L"],"execution_count":1,"outputs":[{"output_type":"stream","text":["GPU 0: Tesla T4 (UUID: GPU-99ac5507-37ad-aab7-e0c3-57ca618da5f0)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"LoE1A_vsRFVJ"},"source":["# Git Clone"]},{"cell_type":"code","metadata":{"id":"sQ0GLBd0RuKZ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1628957015460,"user_tz":-360,"elapsed":6032,"user":{"displayName":"Md.safirur Rashid, 170041020","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj4vsxiS6hdwcIxlWkCOlOKX6Yb9qvDnhTv0OE=s64","userId":"07083869211232678860"}},"outputId":"9ef45b0a-dad0-466f-84a6-1910367d3542"},"source":["!git clone https://github.com/jackyjsy/CVPR21Chal-SLR.git"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Cloning into 'CVPR21Chal-SLR'...\n","remote: Enumerating objects: 673, done.\u001b[K\n","remote: Counting objects: 100% (673/673), done.\u001b[K\n","remote: Compressing objects: 100% (531/531), done.\u001b[K\n","remote: Total 673 (delta 216), reused 585 (delta 130), pack-reused 0\u001b[K\n","Receiving objects: 100% (673/673), 51.71 MiB | 29.34 MiB/s, done.\n","Resolving deltas: 100% (216/216), done.\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"2YOoaHAVRHZY"},"source":["# Drive Mount"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fzXNBkoCtSiv","executionInfo":{"status":"ok","timestamp":1628957035126,"user_tz":-360,"elapsed":19672,"user":{"displayName":"Md.safirur Rashid, 170041020","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj4vsxiS6hdwcIxlWkCOlOKX6Yb9qvDnhTv0OE=s64","userId":"07083869211232678860"}},"outputId":"46a47031-8ce9-47cc-a5b3-a5fe2f88c356"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":3,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"Gf8YICWbSXfv"},"source":["# Preprocessed data copying"]},{"cell_type":"code","metadata":{"id":"mGliByqwtmWF","executionInfo":{"status":"ok","timestamp":1628957039736,"user_tz":-360,"elapsed":560,"user":{"displayName":"Md.safirur Rashid, 170041020","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj4vsxiS6hdwcIxlWkCOlOKX6Yb9qvDnhTv0OE=s64","userId":"07083869211232678860"}}},"source":["import shutil\n","import os"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"id":"PkUYDm3LSnTX","executionInfo":{"status":"ok","timestamp":1628957040208,"user_tz":-360,"elapsed":4,"user":{"displayName":"Md.safirur Rashid, 170041020","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj4vsxiS6hdwcIxlWkCOlOKX6Yb9qvDnhTv0OE=s64","userId":"07083869211232678860"}}},"source":["#data_type = 'joint'\n","data_type = 'joint_motion'\n","#data_type = 'bone'\n","#data_type = 'bone_motion'"],"execution_count":5,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"gv9reaifC4hd"},"source":["# Train Data"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":36},"id":"X0p28MSftb9F","executionInfo":{"status":"ok","timestamp":1628957095909,"user_tz":-360,"elapsed":54878,"user":{"displayName":"Md.safirur Rashid, 170041020","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj4vsxiS6hdwcIxlWkCOlOKX6Yb9qvDnhTv0OE=s64","userId":"07083869211232678860"}},"outputId":"3911991e-e232-4b55-adb2-0d2ac5db7429"},"source":["original = f'/content/drive/.shortcut-targets-by-id/1MwfX64WpeVyGAW0MhcasmbihkfgJwbtY/Darkpose_outputs/train_val/train_val_data_{data_type}.npy'\n","target = f'/content/data/sign/27_2/'\n","os.makedirs(os.path.dirname(target), exist_ok=True)\n","shutil.copy(original, target)\n","\n","original = f'/content/drive/.shortcut-targets-by-id/1MwfX64WpeVyGAW0MhcasmbihkfgJwbtY/Darkpose_outputs/train_val/train_val_labels.pkl'\n","target = f'/content/data/sign/27_2/'\n","os.makedirs(os.path.dirname(target), exist_ok=True)\n","shutil.copy(original, target)"],"execution_count":6,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'/content/data/sign/27_2/train_val_labels.pkl'"]},"metadata":{"tags":[]},"execution_count":6}]},{"cell_type":"markdown","metadata":{"id":"pkW104q6DYbf"},"source":["# Valid Data"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":36},"id":"m4rY1IvFKNCa","executionInfo":{"status":"ok","timestamp":1628957104955,"user_tz":-360,"elapsed":9054,"user":{"displayName":"Md.safirur Rashid, 170041020","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj4vsxiS6hdwcIxlWkCOlOKX6Yb9qvDnhTv0OE=s64","userId":"07083869211232678860"}},"outputId":"7327d4b0-32b6-4e87-b2c6-b8a3a9bbb760"},"source":["original = f'/content/drive/.shortcut-targets-by-id/1MwfX64WpeVyGAW0MhcasmbihkfgJwbtY/Darkpose_outputs/test_data_{data_type}.npy'\n","target = r'/content/data/sign/27_2/'\n","os.makedirs(os.path.dirname(target), exist_ok=True)\n","shutil.copy(original, target)\n","\n","original = r'/content/drive/.shortcut-targets-by-id/1MwfX64WpeVyGAW0MhcasmbihkfgJwbtY/Darkpose_outputs/test_label.pkl'\n","target = r'/content/data/sign/27_2/'\n","os.makedirs(os.path.dirname(target), exist_ok=True)\n","shutil.copy(original, target)"],"execution_count":7,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'/content/data/sign/27_2/test_label.pkl'"]},"metadata":{"tags":[]},"execution_count":7}]},{"cell_type":"markdown","metadata":{"id":"LN0FuKDIUHwa"},"source":["# Imports"]},{"cell_type":"code","metadata":{"id":"h2TSGeynmzMd","executionInfo":{"status":"ok","timestamp":1628957116634,"user_tz":-360,"elapsed":3910,"user":{"displayName":"Md.safirur Rashid, 170041020","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj4vsxiS6hdwcIxlWkCOlOKX6Yb9qvDnhTv0OE=s64","userId":"07083869211232678860"}}},"source":["from __future__ import print_function\n","import argparse\n","from argparse import ArgumentParser,Namespace\n","import os\n","import time\n","import numpy as np\n","import yaml\n","import pickle\n","from collections import OrderedDict\n","# torch\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from torch.autograd import Variable\n","from tqdm import tqdm\n","import shutil\n","from torch.optim.lr_scheduler import ReduceLROnPlateau, MultiStepLR\n","import random\n","import inspect\n","import torch.backends.cudnn as cudnn\n","import torch.nn.functional as F"],"execution_count":8,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"PHdDisu1ULYu"},"source":["# Seed fixing"]},{"cell_type":"code","metadata":{"id":"YJaTr2dCRypd","executionInfo":{"status":"ok","timestamp":1628957117016,"user_tz":-360,"elapsed":386,"user":{"displayName":"Md.safirur Rashid, 170041020","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj4vsxiS6hdwcIxlWkCOlOKX6Yb9qvDnhTv0OE=s64","userId":"07083869211232678860"}}},"source":["def init_seed(_):\n","    torch.cuda.manual_seed_all(1)\n","    torch.manual_seed(1)\n","    np.random.seed(1)\n","    random.seed(1)\n","    # torch.backends.cudnn.enabled = False\n","    torch.backends.cudnn.deterministic = True\n","    torch.backends.cudnn.benchmark = False"],"execution_count":9,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"lajR7EowV5J2"},"source":["# To import the data or model in load_data and load_model"]},{"cell_type":"code","metadata":{"id":"gdmXjH2zfaZf","executionInfo":{"status":"ok","timestamp":1628957117018,"user_tz":-360,"elapsed":5,"user":{"displayName":"Md.safirur Rashid, 170041020","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj4vsxiS6hdwcIxlWkCOlOKX6Yb9qvDnhTv0OE=s64","userId":"07083869211232678860"}}},"source":["def import_class(name):\n","    components = name.split('.')\n","    mod = __import__(components[0])  # import return model\n","    for comp in components[1:]:\n","        mod = getattr(mod, comp)\n","    return mod"],"execution_count":10,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"-UEE1YcuVWZF"},"source":["# Main Class\n","\n","Ami only line 247 nije nije disi\n","\n","to create the saving directory"]},{"cell_type":"code","metadata":{"id":"t-1dCIbpeJQK","executionInfo":{"status":"ok","timestamp":1628957187214,"user_tz":-360,"elapsed":1069,"user":{"displayName":"Md.safirur Rashid, 170041020","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj4vsxiS6hdwcIxlWkCOlOKX6Yb9qvDnhTv0OE=s64","userId":"07083869211232678860"}}},"source":["class Processor():\n","    \"\"\" \n","        Processor for Skeleton-based Action Recgnition\n","    \"\"\"\n","\n","    def __init__(self, arg):\n","\n","        arg.model_saved_name = f\"/content/drive/MyDrive/Colab Notebooks/CVPR21-Bh/Final_train/finetune/{data_type}/save_models/\"+ arg.Experiment_name\n","        arg.work_dir = f\"/content/drive/MyDrive/Colab Notebooks/CVPR21-Bh/Final_train/finetune/{data_type}/work_dir/\" + arg.Experiment_name\n","        self.arg = arg\n","        self.save_arg()\n","        if arg.phase == 'train':\n","            if not arg.train_feeder_args['debug']:\n","                if os.path.isdir(arg.model_saved_name):\n","                    print('log_dir: ', arg.model_saved_name, 'already exist')\n","                    answer = input('delete it? y/n:')\n","                    if answer == 'y':\n","                        shutil.rmtree(arg.model_saved_name)\n","                        print('Dir removed: ', arg.model_saved_name)\n","                        input(\n","                            'Refresh the website of tensorboard by pressing any keys')\n","                    else:\n","                        print('Dir not removed: ', arg.model_saved_name)\n","\n","        self.global_step = 0\n","        self.load_model()\n","        self.load_optimizer()\n","        self.load_data()\n","        self.lr = self.arg.base_lr\n","        self.best_acc = 0\n","\n","    def load_data(self):\n","        Feeder = import_class(self.arg.feeder)\n","        self.data_loader = dict()\n","        if self.arg.phase == 'train':\n","            self.data_loader['train'] = torch.utils.data.DataLoader(\n","                dataset=Feeder(**self.arg.train_feeder_args),\n","                batch_size=self.arg.batch_size,\n","                shuffle=True,\n","                num_workers=self.arg.num_worker,\n","                drop_last=True,\n","                worker_init_fn=init_seed)\n","        self.data_loader['test'] = torch.utils.data.DataLoader(\n","            dataset=Feeder(**self.arg.test_feeder_args),\n","            batch_size=self.arg.test_batch_size,\n","            shuffle=False,\n","            num_workers=self.arg.num_worker,\n","            drop_last=False,\n","            worker_init_fn=init_seed)\n","\n","    def load_model(self):\n","        output_device = self.arg.device[0] if type(\n","            self.arg.device) is list else self.arg.device\n","        self.output_device = output_device\n","        Model = import_class(self.arg.model)\n","        shutil.copy2(inspect.getfile(Model), self.arg.work_dir)\n","        self.model = Model(**self.arg.model_args).cuda(output_device)\n","        # print(self.model)\n","        self.loss = nn.CrossEntropyLoss().cuda(output_device)\n","        # self.loss = LabelSmoothingCrossEntropy().cuda(output_device)\n","\n","        if self.arg.weights:\n","            self.print_log('Load weights from {}.'.format(self.arg.weights))\n","            if '.pkl' in self.arg.weights:\n","                with open(self.arg.weights, 'r') as f:\n","                    weights = pickle.load(f)\n","            else:\n","                weights = torch.load(self.arg.weights)\n","\n","            weights = OrderedDict(\n","                [[k.split('module.')[-1],\n","                  v.cuda(output_device)] for k, v in weights.items()])\n","\n","            for w in self.arg.ignore_weights:\n","                if weights.pop(w, None) is not None:\n","                    self.print_log('Sucessfully Remove Weights: {}.'.format(w))\n","                else:\n","                    self.print_log('Can Not Remove Weights: {}.'.format(w))\n","\n","            try:\n","                self.model.load_state_dict(weights)\n","            except:\n","                state = self.model.state_dict()\n","                diff = list(set(state.keys()).difference(set(weights.keys())))\n","                print('Can not find these weights:')\n","                for d in diff:\n","                    print('  ' + d)\n","                state.update(weights)\n","                self.model.load_state_dict(state)\n","\n","        if type(self.arg.device) is list:\n","            if len(self.arg.device) > 1:\n","                self.model = nn.DataParallel(\n","                    self.model,\n","                    device_ids=self.arg.device,\n","                    output_device=output_device)\n","\n","    def load_optimizer(self):\n","        if self.arg.optimizer == 'SGD':\n","\n","            params_dict = dict(self.model.named_parameters())\n","            params = []\n","\n","            for key, value in params_dict.items():\n","                decay_mult = 0.0 if 'bias' in key else 1.0\n","\n","                lr_mult = 1.0\n","                weight_decay = 1e-4\n","\n","                params += [{'params': value, 'lr': self.arg.base_lr, 'lr_mult': lr_mult,\n","                            'decay_mult': decay_mult, 'weight_decay': weight_decay}]\n","\n","            self.optimizer = optim.SGD(\n","                params,\n","                momentum=0.9,\n","                nesterov=self.arg.nesterov)\n","        elif self.arg.optimizer == 'Adam':\n","            self.optimizer = optim.Adam(\n","                self.model.parameters(),\n","                lr=self.arg.base_lr,\n","                weight_decay=self.arg.weight_decay)\n","        else:\n","            raise ValueError()\n","\n","        self.lr_scheduler = ReduceLROnPlateau(self.optimizer, mode='min', factor=0.1,\n","                                              patience=10, verbose=True,\n","                                              threshold=1e-4, threshold_mode='rel',\n","                                              cooldown=0)\n","\n","    def save_arg(self):\n","        # save arg\n","        arg_dict = vars(self.arg)\n","\n","        if not os.path.exists(self.arg.work_dir):\n","            os.makedirs(self.arg.work_dir)\n","            os.makedirs(self.arg.work_dir + '/eval_results')\n","\n","        with open('{}/config.yaml'.format(self.arg.work_dir), 'w') as f:\n","            yaml.dump(arg_dict, f)\n","\n","    def adjust_learning_rate(self, epoch):\n","        if self.arg.optimizer == 'SGD' or self.arg.optimizer == 'Adam':\n","            if epoch < self.arg.warm_up_epoch:\n","                lr = self.arg.base_lr * (epoch + 1) / self.arg.warm_up_epoch\n","            else:\n","                lr = self.arg.base_lr * (\n","                    0.1 ** np.sum(epoch >= np.array(self.arg.step)))\n","            for param_group in self.optimizer.param_groups:\n","                param_group['lr'] = lr\n","            return lr\n","        else:\n","            raise ValueError()\n","\n","    def print_time(self):\n","        localtime = time.asctime(time.localtime(time.time()))\n","        self.print_log(\"Local current time :  \" + localtime)\n","\n","    def print_log(self, str, print_time=True):\n","        if print_time:\n","            localtime = time.asctime(time.localtime(time.time()))\n","            str = \"[ \" + localtime + ' ] ' + str\n","        print(str)\n","        if self.arg.print_log:\n","            with open('{}/log.txt'.format(self.arg.work_dir), 'a') as f:\n","                print(str, file=f)\n","\n","    def record_time(self):\n","        self.cur_time = time.time()\n","        return self.cur_time\n","\n","    def split_time(self):\n","        split_time = time.time() - self.cur_time\n","        self.record_time()\n","        return split_time\n","\n","    def train(self, epoch, save_model=False):\n","        self.model.train()\n","        self.print_log('Training epoch: {}'.format(epoch + 1))\n","        loader = self.data_loader['train']\n","        self.adjust_learning_rate(epoch)\n","        loss_value = []\n","        self.record_time()\n","        timer = dict(dataloader=0.001, model=0.001, statistics=0.001)\n","        process = tqdm(loader)\n","        if epoch >= self.arg.only_train_epoch:\n","            print('only train part, require grad')\n","            for key, value in self.model.named_parameters():\n","                if 'DecoupleA' in key:\n","                    value.requires_grad = True\n","                    print(key + '-require grad')\n","        else:\n","            print('only train part, do not require grad')\n","            for key, value in self.model.named_parameters():\n","                if 'DecoupleA' in key:\n","                    value.requires_grad = False\n","                    print(key + '-not require grad')\n","        for batch_idx, (data, label, index) in enumerate(process):\n","            self.global_step += 1\n","            # get data\n","            data = Variable(data.float().cuda(\n","                self.output_device), requires_grad=False)\n","            label = Variable(label.long().cuda(\n","                self.output_device), requires_grad=False)\n","            timer['dataloader'] += self.split_time()\n","\n","            # forward\n","            if epoch < 100:\n","                keep_prob = -(1 - self.arg.keep_rate) / 100 * epoch + 1.0\n","            else:\n","                keep_prob = self.arg.keep_rate\n","            output = self.model(data, keep_prob)\n","\n","            if isinstance(output, tuple):\n","                output, l1 = output\n","                l1 = l1.mean()\n","            else:\n","                l1 = 0\n","            loss = self.loss(output, label) + l1\n","\n","            self.optimizer.zero_grad()\n","            loss.backward()\n","            self.optimizer.step()\n","            loss_value.append(loss.data)\n","            timer['model'] += self.split_time()\n","\n","            value, predict_label = torch.max(output.data, 1)\n","            acc = torch.mean((predict_label == label.data).float())\n","\n","            self.lr = self.optimizer.param_groups[0]['lr']\n","\n","            if self.global_step % self.arg.log_interval == 0:\n","                self.print_log(\n","                    '\\tBatch({}/{}) done. Loss: {:.4f}  lr:{:.6f}'.format(\n","                        batch_idx, len(loader), loss.data, self.lr))\n","            timer['statistics'] += self.split_time()\n","\n","        # statistics of time consumption and loss\n","        proportion = {\n","            k: '{:02d}%'.format(int(round(v * 100 / sum(timer.values()))))\n","            for k, v in timer.items()\n","        }\n","\n","        state_dict = self.model.state_dict()\n","        weights = OrderedDict([[k.split('module.')[-1],\n","                                v.cpu()] for k, v in state_dict.items()])\n","\n","        os.makedirs(os.path.dirname(f'/content/drive/MyDrive/Colab Notebooks/CVPR21-Bh/Final_train/finetune/{data_type}/save_models/'), exist_ok=True)\n","        torch.save(weights, self.arg.model_saved_name +\n","                   '-' + str(epoch) + '.pt')\n","\n","    def eval(self, epoch, save_score=False, loader_name=['test'], wrong_file=None, result_file=None):\n","        if wrong_file is not None:\n","            f_w = open(wrong_file, 'w')\n","        if result_file is not None:\n","            f_r = open(result_file, 'w')\n","        self.model.eval()\n","        with torch.no_grad():\n","            self.print_log('Eval epoch: {}'.format(epoch + 1))\n","            for ln in loader_name:\n","                loss_value = []\n","                score_frag = []\n","                right_num_total = 0\n","                total_num = 0\n","                loss_total = 0\n","                step = 0\n","                process = tqdm(self.data_loader[ln])\n","\n","                for batch_idx, (data, label, index) in enumerate(process):\n","                    data = Variable(\n","                        data.float().cuda(self.output_device),\n","                        requires_grad=False)\n","                    label = Variable(\n","                        label.long().cuda(self.output_device),\n","                        requires_grad=False)\n","\n","                    with torch.no_grad():\n","                        output = self.model(data)\n","\n","                    if isinstance(output, tuple):\n","                        output, l1 = output\n","                        l1 = l1.mean()\n","                    else:\n","                        l1 = 0\n","                    loss = self.loss(output, label)\n","                    score_frag.append(output.data.cpu().numpy())\n","                    loss_value.append(loss.data.cpu().numpy())\n","\n","                    _, predict_label = torch.max(output.data, 1)\n","                    step += 1\n","\n","                    if wrong_file is not None or result_file is not None:\n","                        predict = list(predict_label.cpu().numpy())\n","                        true = list(label.data.cpu().numpy())\n","                        for i, x in enumerate(predict):\n","                            if result_file is not None:\n","                                f_r.write(str(x) + ',' + str(true[i]) + '\\n')\n","                            if x != true[i] and wrong_file is not None:\n","                                f_w.write(str(index[i]) + ',' +\n","                                        str(x) + ',' + str(true[i]) + '\\n')\n","                score = np.concatenate(score_frag)\n","\n","                if 'UCLA' in arg.Experiment_name:\n","                    self.data_loader[ln].dataset.sample_name = np.arange(\n","                        len(score))\n","\n","                accuracy = self.data_loader[ln].dataset.top_k(score, 1)\n","                if accuracy > self.best_acc:\n","                    self.best_acc = accuracy\n","                    score_dict = dict(\n","                        zip(self.data_loader[ln].dataset.sample_name, score))\n","\n","                    with open(f'/content/drive/MyDrive/Colab Notebooks/CVPR21-Bh/Final_train/finetune/{data_type}/work_dir/' + arg.Experiment_name + '/eval_results/best_acc' + '.pkl'.format(\n","                            epoch, accuracy), 'wb') as f:\n","                        pickle.dump(score_dict, f)\n","\n","                print('Eval Accuracy: ', accuracy,\n","                    ' model: ', self.arg.model_saved_name)\n","\n","                score_dict = dict(\n","                    zip(self.data_loader[ln].dataset.sample_name, score))\n","                self.print_log('\\tMean {} loss of {} batches: {}.'.format(\n","                    ln, len(self.data_loader[ln]), np.mean(loss_value)))\n","                for k in self.arg.show_topk:\n","                    self.print_log('\\tTop{}: {:.2f}%'.format(\n","                        k, 100 * self.data_loader[ln].dataset.top_k(score, k)))\n","\n","                with open(f'/content/drive/MyDrive/Colab Notebooks/CVPR21-Bh/Final_train/finetune/{data_type}/work_dir/' + arg.Experiment_name + '/eval_results/epoch_' + str(epoch) + '_' + str(accuracy) + '.pkl'.format(\n","                        epoch, accuracy), 'wb') as f:\n","                    pickle.dump(score_dict, f)\n","        return np.mean(loss_value)\n","    def start(self):\n","        if self.arg.phase == 'train':\n","            self.print_log('Parameters:\\n{}\\n'.format(str(vars(self.arg))))\n","            self.global_step = self.arg.start_epoch * \\\n","                len(self.data_loader['train']) / self.arg.batch_size\n","            for epoch in range(self.arg.start_epoch, self.arg.num_epoch):\n","                save_model = ((epoch + 1) % self.arg.save_interval == 0) or (\n","                    epoch + 1 == self.arg.num_epoch)\n","\n","                self.train(epoch, save_model=save_model)\n","\n","                val_loss = self.eval(\n","                    epoch,\n","                    save_score=self.arg.save_score,\n","                    loader_name=['test'])\n","\n","                # self.lr_scheduler.step(val_loss)\n","\n","            print('best accuracy: ', self.best_acc,\n","                  ' model_name: ', self.arg.model_saved_name)\n","\n","        elif self.arg.phase == 'test':\n","            if not self.arg.test_feeder_args['debug']:\n","                wf = self.arg.model_saved_name + '_wrong.txt'\n","                rf = self.arg.model_saved_name + '_right.txt'\n","            else:\n","                wf = rf = None\n","            if self.arg.weights is None:\n","                raise ValueError('Please appoint --weights.')\n","            self.arg.print_log = False\n","            self.print_log('Model:   {}.'.format(self.arg.model))\n","            self.print_log('Weights: {}.'.format(self.arg.weights))\n","            self.eval(epoch=self.arg.start_epoch, save_score=self.arg.save_score,\n","                      loader_name=['test'], wrong_file=wf, result_file=rf)\n","            self.print_log('Done.\\n')"],"execution_count":14,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"hS0r2JIOWpek"},"source":["# Passed Arguments"]},{"cell_type":"code","metadata":{"id":"066bp_UieZYs","executionInfo":{"status":"ok","timestamp":1628957187800,"user_tz":-360,"elapsed":6,"user":{"displayName":"Md.safirur Rashid, 170041020","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj4vsxiS6hdwcIxlWkCOlOKX6Yb9qvDnhTv0OE=s64","userId":"07083869211232678860"}}},"source":["arg = Namespace(\n","    Experiment_name=f'{data_type}_27_2_finetune', \n","    base_lr=0.01, \n","    batch_size=64, \n","    config=f'/content/CVPR21Chal-SLR/SL-GCN/config/sign/finetune/train_{data_type}.yaml', \n","    device=[0], \n","    eval_interval=5, \n","    feeder='feeders.feeder.Feeder', \n","    groups=8, \n","    ignore_weights=[], \n","    keep_rate=0.9, \n","    log_interval=100, \n","    model='model.decouple_gcn_attn.Model', \n","    model_args={\n","        'num_class': 226, \n","        'num_point': 27, \n","        'num_person': 1, \n","        'graph': 'graph.sign_27.Graph', \n","        'groups': 16, \n","        'block_size': 41, \n","        'graph_args': {'labeling_mode': 'spatial'}\n","    }, \n","    model_saved_name='', \n","    nesterov=True, \n","    num_epoch=100, \n","    num_worker=32, \n","    only_train_epoch=1, \n","    only_train_part=True, \n","    optimizer='SGD', \n","    phase='train', \n","    print_log=True, \n","    save_interval=2, \n","    save_score=False, \n","    seed=1, \n","    show_topk=[1, 5], \n","    start_epoch=0, ###############################################################\n","    step=[50], \n","    test_batch_size=64, \n","    test_feeder_args={\n","        'data_path': f'/content/data/sign/27_2/test_data_{data_type}.npy', \n","        'label_path': f'/content/data/sign/27_2/test_label.pkl', \n","        'random_mirror': False, \n","        'normalization': True\n","    }, \n","    train_feeder_args={\n","        'data_path': f'/content/data/sign/27_2/train_val_data_{data_type}.npy', \n","        'label_path': f'/content/data/sign/27_2/train_val_labels.pkl', \n","        'debug': False, \n","        'random_choose': True, \n","        'window_size': 100, \n","        'random_shift': True, \n","        'normalization': True, \n","        'random_mirror': True, \n","        'random_mirror_p': 0.5, \n","        'is_vector': False\n","    }, \n","    warm_up_epoch=0, \n","    weight_decay=0.0001, \n","    ##############################################\n","    # To continue use specific path else None    #\n","    ##############################################\n","    weights=f'/content/drive/MyDrive/Colab Notebooks/CVPR21-Bh/Final_train/{data_type}/save_models/sign_{data_type}_final-169.pt', \n","    work_dir='./work_dir/temp'\n",")"],"execution_count":15,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"6u0wbvo6X5h6"},"source":["# Main cell to run\n","Personal suggestion:\n","\n","Ei cell ta ekta copy koire run koris as amader onek baar e train korte hobe and re run korle prev output erase hoye jay.\n","\n","Also koy step por por latest .pt file ta nije nije download koire nis just in case."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"83NBgJX-WDwt","outputId":"0e79e015-25aa-4ba5-aa7d-81fbf978e651"},"source":["%cd /content/CVPR21Chal-SLR/SL-GCN\n","init_seed(0)\n","processor = Processor(arg)\n","processor.start()\n","%cd /content"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/content/CVPR21Chal-SLR/SL-GCN\n"],"name":"stdout"},{"output_type":"stream","text":["/content/CVPR21Chal-SLR/SL-GCN/model/decouple_gcn_attn.py:29: UserWarning: nn.init.kaiming_normal is now deprecated in favor of nn.init.kaiming_normal_.\n","  nn.init.kaiming_normal(conv.weight, mode='fan_out')\n","/content/CVPR21Chal-SLR/SL-GCN/model/decouple_gcn_attn.py:30: UserWarning: nn.init.constant is now deprecated in favor of nn.init.constant_.\n","  nn.init.constant(conv.bias, 0)\n","/content/CVPR21Chal-SLR/SL-GCN/model/decouple_gcn_attn.py:34: UserWarning: nn.init.constant is now deprecated in favor of nn.init.constant_.\n","  nn.init.constant(bn.weight, scale)\n","/content/CVPR21Chal-SLR/SL-GCN/model/decouple_gcn_attn.py:35: UserWarning: nn.init.constant is now deprecated in favor of nn.init.constant_.\n","  nn.init.constant(bn.bias, 0)\n","/content/CVPR21Chal-SLR/SL-GCN/model/decouple_gcn_attn.py:113: UserWarning: nn.init.constant is now deprecated in favor of nn.init.constant_.\n","  nn.init.constant(self.Linear_bias, 1e-6)\n","/content/CVPR21Chal-SLR/SL-GCN/model/decouple_gcn_attn.py:119: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  eye_array), requires_grad=False, device='cuda'), requires_grad=False)  # [c,25,25]\n","/content/CVPR21Chal-SLR/SL-GCN/model/decouple_gcn_attn.py:252: UserWarning: nn.init.normal is now deprecated in favor of nn.init.normal_.\n","  nn.init.normal(self.fc.weight, 0, math.sqrt(2. / num_class))\n"],"name":"stderr"},{"output_type":"stream","text":["Attention Enabled!\n","Attention Enabled!\n","Attention Enabled!\n","Attention Enabled!\n","Attention Enabled!\n","Attention Enabled!\n","Attention Enabled!\n","Attention Enabled!\n","Attention Enabled!\n","Attention Enabled!\n","[ Sat Aug 14 16:06:48 2021 ] Load weights from /content/drive/MyDrive/Colab Notebooks/CVPR21-Bh/Final_train/joint_motion/save_models/sign_joint_motion_final-169.pt.\n","32560\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 32 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n"],"name":"stderr"},{"output_type":"stream","text":["3742\n","[ Sat Aug 14 16:07:03 2021 ] Parameters:\n","{'Experiment_name': 'joint_motion_27_2_finetune', 'base_lr': 0.01, 'batch_size': 64, 'config': '/content/CVPR21Chal-SLR/SL-GCN/config/sign/finetune/train_joint_motion.yaml', 'device': [0], 'eval_interval': 5, 'feeder': 'feeders.feeder.Feeder', 'groups': 8, 'ignore_weights': [], 'keep_rate': 0.9, 'log_interval': 100, 'model': 'model.decouple_gcn_attn.Model', 'model_args': {'num_class': 226, 'num_point': 27, 'num_person': 1, 'graph': 'graph.sign_27.Graph', 'groups': 16, 'block_size': 41, 'graph_args': {'labeling_mode': 'spatial'}}, 'model_saved_name': '/content/drive/MyDrive/Colab Notebooks/CVPR21-Bh/Final_train/finetune/joint_motion/save_models/joint_motion_27_2_finetune', 'nesterov': True, 'num_epoch': 100, 'num_worker': 32, 'only_train_epoch': 1, 'only_train_part': True, 'optimizer': 'SGD', 'phase': 'train', 'print_log': True, 'save_interval': 2, 'save_score': False, 'seed': 1, 'show_topk': [1, 5], 'start_epoch': 0, 'step': [50], 'test_batch_size': 64, 'test_feeder_args': {'data_path': '/content/data/sign/27_2/test_data_joint_motion.npy', 'label_path': '/content/data/sign/27_2/test_label.pkl', 'random_mirror': False, 'normalization': True}, 'train_feeder_args': {'data_path': '/content/data/sign/27_2/train_val_data_joint_motion.npy', 'label_path': '/content/data/sign/27_2/train_val_labels.pkl', 'debug': False, 'random_choose': True, 'window_size': 100, 'random_shift': True, 'normalization': True, 'random_mirror': True, 'random_mirror_p': 0.5, 'is_vector': False}, 'warm_up_epoch': 0, 'weight_decay': 0.0001, 'weights': '/content/drive/MyDrive/Colab Notebooks/CVPR21-Bh/Final_train/joint_motion/save_models/sign_joint_motion_final-169.pt', 'work_dir': '/content/drive/MyDrive/Colab Notebooks/CVPR21-Bh/Final_train/finetune/joint_motion/work_dir/joint_motion_27_2_finetune'}\n","\n","[ Sat Aug 14 16:07:03 2021 ] Training epoch: 1\n"],"name":"stdout"},{"output_type":"stream","text":["\r  0%|          | 0/508 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["only train part, do not require grad\n","l1.gcn1.DecoupleA-not require grad\n","l2.gcn1.DecoupleA-not require grad\n","l3.gcn1.DecoupleA-not require grad\n","l4.gcn1.DecoupleA-not require grad\n","l5.gcn1.DecoupleA-not require grad\n","l6.gcn1.DecoupleA-not require grad\n","l7.gcn1.DecoupleA-not require grad\n","l8.gcn1.DecoupleA-not require grad\n","l9.gcn1.DecoupleA-not require grad\n","l10.gcn1.DecoupleA-not require grad\n"],"name":"stdout"},{"output_type":"stream","text":[" 20%|█▉        | 100/508 [01:18<05:17,  1.28it/s]"],"name":"stderr"},{"output_type":"stream","text":["[ Sat Aug 14 16:08:22 2021 ] \tBatch(99/508) done. Loss: 0.1886  lr:0.010000\n"],"name":"stdout"},{"output_type":"stream","text":[" 39%|███▉      | 200/508 [02:37<04:08,  1.24it/s]"],"name":"stderr"},{"output_type":"stream","text":["[ Sat Aug 14 16:09:41 2021 ] \tBatch(199/508) done. Loss: 0.0201  lr:0.010000\n"],"name":"stdout"},{"output_type":"stream","text":[" 59%|█████▉    | 300/508 [03:58<02:49,  1.23it/s]"],"name":"stderr"},{"output_type":"stream","text":["[ Sat Aug 14 16:11:02 2021 ] \tBatch(299/508) done. Loss: 0.0013  lr:0.010000\n"],"name":"stdout"},{"output_type":"stream","text":[" 79%|███████▊  | 400/508 [05:19<01:27,  1.23it/s]"],"name":"stderr"},{"output_type":"stream","text":["[ Sat Aug 14 16:12:23 2021 ] \tBatch(399/508) done. Loss: 0.0986  lr:0.010000\n"],"name":"stdout"},{"output_type":"stream","text":[" 98%|█████████▊| 500/508 [06:41<00:06,  1.23it/s]"],"name":"stderr"},{"output_type":"stream","text":["[ Sat Aug 14 16:13:44 2021 ] \tBatch(499/508) done. Loss: 0.0021  lr:0.010000\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 508/508 [06:48<00:00,  1.24it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["[ Sat Aug 14 16:13:52 2021 ] Eval epoch: 1\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 59/59 [00:27<00:00,  2.13it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["Eval Accuracy:  0.8834847675040085  model:  /content/drive/MyDrive/Colab Notebooks/CVPR21-Bh/Final_train/finetune/joint_motion/save_models/joint_motion_27_2_finetune\n","[ Sat Aug 14 16:14:20 2021 ] \tMean test loss of 59 batches: 0.6088219285011292.\n","[ Sat Aug 14 16:14:20 2021 ] \tTop1: 88.35%\n","[ Sat Aug 14 16:14:20 2021 ] \tTop5: 97.78%\n","[ Sat Aug 14 16:14:20 2021 ] Training epoch: 2\n"],"name":"stdout"},{"output_type":"stream","text":["\r  0%|          | 0/508 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["only train part, require grad\n","l1.gcn1.DecoupleA-require grad\n","l2.gcn1.DecoupleA-require grad\n","l3.gcn1.DecoupleA-require grad\n","l4.gcn1.DecoupleA-require grad\n","l5.gcn1.DecoupleA-require grad\n","l6.gcn1.DecoupleA-require grad\n","l7.gcn1.DecoupleA-require grad\n","l8.gcn1.DecoupleA-require grad\n","l9.gcn1.DecoupleA-require grad\n","l10.gcn1.DecoupleA-require grad\n"],"name":"stdout"},{"output_type":"stream","text":["/content/CVPR21Chal-SLR/SL-GCN/model/dropSke.py:29: UserWarning: undefined skeleton graph\n","  warnings.warn('undefined skeleton graph')\n","/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:652: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)\n","  return torch.max_pool1d(input, kernel_size, stride, padding, dilation, ceil_mode)\n"," 18%|█▊        | 92/508 [01:26<06:25,  1.08it/s]"],"name":"stderr"},{"output_type":"stream","text":["[ Sat Aug 14 16:15:47 2021 ] \tBatch(91/508) done. Loss: 0.0047  lr:0.010000\n"],"name":"stdout"},{"output_type":"stream","text":[" 38%|███▊      | 192/508 [02:59<04:52,  1.08it/s]"],"name":"stderr"},{"output_type":"stream","text":["[ Sat Aug 14 16:17:19 2021 ] \tBatch(191/508) done. Loss: 0.0014  lr:0.010000\n"],"name":"stdout"},{"output_type":"stream","text":[" 57%|█████▋    | 292/508 [04:31<03:20,  1.08it/s]"],"name":"stderr"},{"output_type":"stream","text":["[ Sat Aug 14 16:18:52 2021 ] \tBatch(291/508) done. Loss: 0.0015  lr:0.010000\n"],"name":"stdout"},{"output_type":"stream","text":[" 77%|███████▋  | 392/508 [06:04<01:47,  1.08it/s]"],"name":"stderr"},{"output_type":"stream","text":["[ Sat Aug 14 16:20:25 2021 ] \tBatch(391/508) done. Loss: 0.0048  lr:0.010000\n"],"name":"stdout"},{"output_type":"stream","text":[" 97%|█████████▋| 492/508 [07:37<00:14,  1.08it/s]"],"name":"stderr"},{"output_type":"stream","text":["[ Sat Aug 14 16:21:57 2021 ] \tBatch(491/508) done. Loss: 0.0289  lr:0.010000\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 508/508 [07:52<00:00,  1.07it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["[ Sat Aug 14 16:22:13 2021 ] Eval epoch: 2\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 59/59 [00:27<00:00,  2.13it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["Eval Accuracy:  0.8856226616782469  model:  /content/drive/MyDrive/Colab Notebooks/CVPR21-Bh/Final_train/finetune/joint_motion/save_models/joint_motion_27_2_finetune\n","[ Sat Aug 14 16:22:41 2021 ] \tMean test loss of 59 batches: 0.5927085876464844.\n","[ Sat Aug 14 16:22:41 2021 ] \tTop1: 88.56%\n","[ Sat Aug 14 16:22:41 2021 ] \tTop5: 97.92%\n","[ Sat Aug 14 16:22:41 2021 ] Training epoch: 3\n"],"name":"stdout"},{"output_type":"stream","text":["\r  0%|          | 0/508 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["only train part, require grad\n","l1.gcn1.DecoupleA-require grad\n","l2.gcn1.DecoupleA-require grad\n","l3.gcn1.DecoupleA-require grad\n","l4.gcn1.DecoupleA-require grad\n","l5.gcn1.DecoupleA-require grad\n","l6.gcn1.DecoupleA-require grad\n","l7.gcn1.DecoupleA-require grad\n","l8.gcn1.DecoupleA-require grad\n","l9.gcn1.DecoupleA-require grad\n","l10.gcn1.DecoupleA-require grad\n"],"name":"stdout"},{"output_type":"stream","text":[" 17%|█▋        | 84/508 [01:19<06:32,  1.08it/s]"],"name":"stderr"},{"output_type":"stream","text":["[ Sat Aug 14 16:24:01 2021 ] \tBatch(83/508) done. Loss: 0.0052  lr:0.010000\n"],"name":"stdout"},{"output_type":"stream","text":[" 36%|███▌      | 184/508 [02:52<05:00,  1.08it/s]"],"name":"stderr"},{"output_type":"stream","text":["[ Sat Aug 14 16:25:33 2021 ] \tBatch(183/508) done. Loss: 0.0130  lr:0.010000\n"],"name":"stdout"},{"output_type":"stream","text":[" 56%|█████▌    | 284/508 [04:24<03:28,  1.08it/s]"],"name":"stderr"},{"output_type":"stream","text":["[ Sat Aug 14 16:27:06 2021 ] \tBatch(283/508) done. Loss: 0.0141  lr:0.010000\n"],"name":"stdout"},{"output_type":"stream","text":[" 76%|███████▌  | 384/508 [05:57<01:54,  1.08it/s]"],"name":"stderr"},{"output_type":"stream","text":["[ Sat Aug 14 16:28:38 2021 ] \tBatch(383/508) done. Loss: 0.0017  lr:0.010000\n"],"name":"stdout"},{"output_type":"stream","text":[" 95%|█████████▌| 484/508 [07:29<00:22,  1.08it/s]"],"name":"stderr"},{"output_type":"stream","text":["[ Sat Aug 14 16:30:11 2021 ] \tBatch(483/508) done. Loss: 0.0138  lr:0.010000\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 508/508 [07:52<00:00,  1.07it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["[ Sat Aug 14 16:30:34 2021 ] Eval epoch: 3\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 59/59 [00:27<00:00,  2.14it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["Eval Accuracy:  0.8821485836451096  model:  /content/drive/MyDrive/Colab Notebooks/CVPR21-Bh/Final_train/finetune/joint_motion/save_models/joint_motion_27_2_finetune\n","[ Sat Aug 14 16:31:02 2021 ] \tMean test loss of 59 batches: 0.5901781320571899.\n","[ Sat Aug 14 16:31:02 2021 ] \tTop1: 88.21%\n","[ Sat Aug 14 16:31:02 2021 ] \tTop5: 97.84%\n","[ Sat Aug 14 16:31:02 2021 ] Training epoch: 4\n"],"name":"stdout"},{"output_type":"stream","text":["\r  0%|          | 0/508 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["only train part, require grad\n","l1.gcn1.DecoupleA-require grad\n","l2.gcn1.DecoupleA-require grad\n","l3.gcn1.DecoupleA-require grad\n","l4.gcn1.DecoupleA-require grad\n","l5.gcn1.DecoupleA-require grad\n","l6.gcn1.DecoupleA-require grad\n","l7.gcn1.DecoupleA-require grad\n","l8.gcn1.DecoupleA-require grad\n","l9.gcn1.DecoupleA-require grad\n","l10.gcn1.DecoupleA-require grad\n"],"name":"stdout"},{"output_type":"stream","text":[" 15%|█▍        | 76/508 [01:12<06:41,  1.08it/s]"],"name":"stderr"},{"output_type":"stream","text":["[ Sat Aug 14 16:32:14 2021 ] \tBatch(75/508) done. Loss: 0.0089  lr:0.010000\n"],"name":"stdout"},{"output_type":"stream","text":[" 35%|███▍      | 176/508 [02:44<05:07,  1.08it/s]"],"name":"stderr"},{"output_type":"stream","text":["[ Sat Aug 14 16:33:47 2021 ] \tBatch(175/508) done. Loss: 0.0405  lr:0.010000\n"],"name":"stdout"},{"output_type":"stream","text":[" 54%|█████▍    | 276/508 [04:17<03:35,  1.08it/s]"],"name":"stderr"},{"output_type":"stream","text":["[ Sat Aug 14 16:35:19 2021 ] \tBatch(275/508) done. Loss: 0.0038  lr:0.010000\n"],"name":"stdout"},{"output_type":"stream","text":[" 74%|███████▍  | 376/508 [05:50<02:02,  1.08it/s]"],"name":"stderr"},{"output_type":"stream","text":["[ Sat Aug 14 16:36:52 2021 ] \tBatch(375/508) done. Loss: 0.0008  lr:0.010000\n"],"name":"stdout"},{"output_type":"stream","text":[" 94%|█████████▎| 476/508 [07:22<00:29,  1.08it/s]"],"name":"stderr"},{"output_type":"stream","text":["[ Sat Aug 14 16:38:25 2021 ] \tBatch(475/508) done. Loss: 0.0108  lr:0.010000\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 508/508 [07:53<00:00,  1.07it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["[ Sat Aug 14 16:38:55 2021 ] Eval epoch: 4\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 59/59 [00:27<00:00,  2.13it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["Eval Accuracy:  0.8818813468733298  model:  /content/drive/MyDrive/Colab Notebooks/CVPR21-Bh/Final_train/finetune/joint_motion/save_models/joint_motion_27_2_finetune\n","[ Sat Aug 14 16:39:23 2021 ] \tMean test loss of 59 batches: 0.606727123260498.\n","[ Sat Aug 14 16:39:23 2021 ] \tTop1: 88.19%\n","[ Sat Aug 14 16:39:23 2021 ] \tTop5: 97.65%\n","[ Sat Aug 14 16:39:23 2021 ] Training epoch: 5\n"],"name":"stdout"},{"output_type":"stream","text":["\r  0%|          | 0/508 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["only train part, require grad\n","l1.gcn1.DecoupleA-require grad\n","l2.gcn1.DecoupleA-require grad\n","l3.gcn1.DecoupleA-require grad\n","l4.gcn1.DecoupleA-require grad\n","l5.gcn1.DecoupleA-require grad\n","l6.gcn1.DecoupleA-require grad\n","l7.gcn1.DecoupleA-require grad\n","l8.gcn1.DecoupleA-require grad\n","l9.gcn1.DecoupleA-require grad\n","l10.gcn1.DecoupleA-require grad\n"],"name":"stdout"},{"output_type":"stream","text":[" 13%|█▎        | 68/508 [01:05<06:47,  1.08it/s]"],"name":"stderr"},{"output_type":"stream","text":["[ Sat Aug 14 16:40:28 2021 ] \tBatch(67/508) done. Loss: 0.0034  lr:0.010000\n"],"name":"stdout"},{"output_type":"stream","text":[" 33%|███▎      | 168/508 [02:37<05:15,  1.08it/s]"],"name":"stderr"},{"output_type":"stream","text":["[ Sat Aug 14 16:42:01 2021 ] \tBatch(167/508) done. Loss: 0.0013  lr:0.010000\n"],"name":"stdout"},{"output_type":"stream","text":[" 53%|█████▎    | 268/508 [04:10<03:42,  1.08it/s]"],"name":"stderr"},{"output_type":"stream","text":["[ Sat Aug 14 16:43:33 2021 ] \tBatch(267/508) done. Loss: 0.0117  lr:0.010000\n"],"name":"stdout"},{"output_type":"stream","text":[" 72%|███████▏  | 368/508 [05:42<02:09,  1.08it/s]"],"name":"stderr"},{"output_type":"stream","text":["[ Sat Aug 14 16:45:06 2021 ] \tBatch(367/508) done. Loss: 0.0024  lr:0.010000\n"],"name":"stdout"},{"output_type":"stream","text":[" 92%|█████████▏| 468/508 [07:15<00:37,  1.08it/s]"],"name":"stderr"},{"output_type":"stream","text":["[ Sat Aug 14 16:46:38 2021 ] \tBatch(467/508) done. Loss: 0.0012  lr:0.010000\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 508/508 [07:53<00:00,  1.07it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["[ Sat Aug 14 16:47:16 2021 ] Eval epoch: 5\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 59/59 [00:27<00:00,  2.13it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["Eval Accuracy:  0.8834847675040085  model:  /content/drive/MyDrive/Colab Notebooks/CVPR21-Bh/Final_train/finetune/joint_motion/save_models/joint_motion_27_2_finetune\n","[ Sat Aug 14 16:47:44 2021 ] \tMean test loss of 59 batches: 0.6177825927734375.\n","[ Sat Aug 14 16:47:44 2021 ] \tTop1: 88.35%\n","[ Sat Aug 14 16:47:44 2021 ] \tTop5: 97.51%\n","[ Sat Aug 14 16:47:44 2021 ] Training epoch: 6\n"],"name":"stdout"},{"output_type":"stream","text":["\r  0%|          | 0/508 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["only train part, require grad\n","l1.gcn1.DecoupleA-require grad\n","l2.gcn1.DecoupleA-require grad\n","l3.gcn1.DecoupleA-require grad\n","l4.gcn1.DecoupleA-require grad\n","l5.gcn1.DecoupleA-require grad\n","l6.gcn1.DecoupleA-require grad\n","l7.gcn1.DecoupleA-require grad\n","l8.gcn1.DecoupleA-require grad\n","l9.gcn1.DecoupleA-require grad\n","l10.gcn1.DecoupleA-require grad\n"],"name":"stdout"},{"output_type":"stream","text":[" 12%|█▏        | 60/508 [00:57<06:53,  1.08it/s]"],"name":"stderr"},{"output_type":"stream","text":["[ Sat Aug 14 16:48:42 2021 ] \tBatch(59/508) done. Loss: 0.0052  lr:0.010000\n"],"name":"stdout"},{"output_type":"stream","text":[" 31%|███▏      | 160/508 [02:30<05:22,  1.08it/s]"],"name":"stderr"},{"output_type":"stream","text":["[ Sat Aug 14 16:50:14 2021 ] \tBatch(159/508) done. Loss: 0.0034  lr:0.010000\n"],"name":"stdout"},{"output_type":"stream","text":[" 51%|█████     | 260/508 [04:02<03:50,  1.07it/s]"],"name":"stderr"},{"output_type":"stream","text":["[ Sat Aug 14 16:51:47 2021 ] \tBatch(259/508) done. Loss: 0.0144  lr:0.010000\n"],"name":"stdout"},{"output_type":"stream","text":[" 71%|███████   | 360/508 [05:35<02:17,  1.08it/s]"],"name":"stderr"},{"output_type":"stream","text":["[ Sat Aug 14 16:53:20 2021 ] \tBatch(359/508) done. Loss: 0.0023  lr:0.010000\n"],"name":"stdout"},{"output_type":"stream","text":[" 91%|█████████ | 460/508 [07:07<00:44,  1.08it/s]"],"name":"stderr"},{"output_type":"stream","text":["[ Sat Aug 14 16:54:52 2021 ] \tBatch(459/508) done. Loss: 0.0033  lr:0.010000\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 508/508 [07:53<00:00,  1.07it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["[ Sat Aug 14 16:55:38 2021 ] Eval epoch: 6\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 59/59 [00:27<00:00,  2.13it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["Eval Accuracy:  0.8893639764831641  model:  /content/drive/MyDrive/Colab Notebooks/CVPR21-Bh/Final_train/finetune/joint_motion/save_models/joint_motion_27_2_finetune\n","[ Sat Aug 14 16:56:06 2021 ] \tMean test loss of 59 batches: 0.5902441740036011.\n","[ Sat Aug 14 16:56:06 2021 ] \tTop1: 88.94%\n","[ Sat Aug 14 16:56:06 2021 ] \tTop5: 97.70%\n","[ Sat Aug 14 16:56:06 2021 ] Training epoch: 7\n"],"name":"stdout"},{"output_type":"stream","text":["\r  0%|          | 0/508 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["only train part, require grad\n","l1.gcn1.DecoupleA-require grad\n","l2.gcn1.DecoupleA-require grad\n","l3.gcn1.DecoupleA-require grad\n","l4.gcn1.DecoupleA-require grad\n","l5.gcn1.DecoupleA-require grad\n","l6.gcn1.DecoupleA-require grad\n","l7.gcn1.DecoupleA-require grad\n","l8.gcn1.DecoupleA-require grad\n","l9.gcn1.DecoupleA-require grad\n","l10.gcn1.DecoupleA-require grad\n"],"name":"stdout"},{"output_type":"stream","text":[" 10%|█         | 52/508 [00:50<07:01,  1.08it/s]"],"name":"stderr"},{"output_type":"stream","text":["[ Sat Aug 14 16:56:56 2021 ] \tBatch(51/508) done. Loss: 0.0015  lr:0.010000\n"],"name":"stdout"},{"output_type":"stream","text":[" 30%|██▉       | 152/508 [02:22<05:29,  1.08it/s]"],"name":"stderr"},{"output_type":"stream","text":["[ Sat Aug 14 16:58:28 2021 ] \tBatch(151/508) done. Loss: 0.0112  lr:0.010000\n"],"name":"stdout"},{"output_type":"stream","text":[" 50%|████▉     | 252/508 [03:54<03:57,  1.08it/s]"],"name":"stderr"},{"output_type":"stream","text":["[ Sat Aug 14 17:00:01 2021 ] \tBatch(251/508) done. Loss: 0.0070  lr:0.010000\n"],"name":"stdout"},{"output_type":"stream","text":[" 69%|██████▉   | 352/508 [05:27<02:24,  1.08it/s]"],"name":"stderr"},{"output_type":"stream","text":["[ Sat Aug 14 17:01:33 2021 ] \tBatch(351/508) done. Loss: 0.0058  lr:0.010000\n"],"name":"stdout"},{"output_type":"stream","text":[" 89%|████████▉ | 452/508 [07:00<00:51,  1.08it/s]"],"name":"stderr"},{"output_type":"stream","text":["[ Sat Aug 14 17:03:06 2021 ] \tBatch(451/508) done. Loss: 0.0118  lr:0.010000\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 508/508 [07:52<00:00,  1.07it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["[ Sat Aug 14 17:03:59 2021 ] Eval epoch: 7\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 59/59 [00:27<00:00,  2.14it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["Eval Accuracy:  0.8850881881346874  model:  /content/drive/MyDrive/Colab Notebooks/CVPR21-Bh/Final_train/finetune/joint_motion/save_models/joint_motion_27_2_finetune\n","[ Sat Aug 14 17:04:26 2021 ] \tMean test loss of 59 batches: 0.5874069929122925.\n","[ Sat Aug 14 17:04:26 2021 ] \tTop1: 88.51%\n","[ Sat Aug 14 17:04:26 2021 ] \tTop5: 97.68%\n","[ Sat Aug 14 17:04:27 2021 ] Training epoch: 8\n"],"name":"stdout"},{"output_type":"stream","text":["\r  0%|          | 0/508 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["only train part, require grad\n","l1.gcn1.DecoupleA-require grad\n","l2.gcn1.DecoupleA-require grad\n","l3.gcn1.DecoupleA-require grad\n","l4.gcn1.DecoupleA-require grad\n","l5.gcn1.DecoupleA-require grad\n","l6.gcn1.DecoupleA-require grad\n","l7.gcn1.DecoupleA-require grad\n","l8.gcn1.DecoupleA-require grad\n","l9.gcn1.DecoupleA-require grad\n","l10.gcn1.DecoupleA-require grad\n"],"name":"stdout"},{"output_type":"stream","text":["  9%|▊         | 44/508 [00:42<07:09,  1.08it/s]"],"name":"stderr"},{"output_type":"stream","text":["[ Sat Aug 14 17:05:09 2021 ] \tBatch(43/508) done. Loss: 0.0155  lr:0.010000\n"],"name":"stdout"},{"output_type":"stream","text":[" 28%|██▊       | 144/508 [02:15<05:36,  1.08it/s]"],"name":"stderr"},{"output_type":"stream","text":["[ Sat Aug 14 17:06:42 2021 ] \tBatch(143/508) done. Loss: 0.0048  lr:0.010000\n"],"name":"stdout"},{"output_type":"stream","text":[" 48%|████▊     | 244/508 [03:47<04:04,  1.08it/s]"],"name":"stderr"},{"output_type":"stream","text":["[ Sat Aug 14 17:08:14 2021 ] \tBatch(243/508) done. Loss: 0.0045  lr:0.010000\n"],"name":"stdout"},{"output_type":"stream","text":[" 68%|██████▊   | 344/508 [05:20<02:32,  1.08it/s]"],"name":"stderr"},{"output_type":"stream","text":["[ Sat Aug 14 17:09:47 2021 ] \tBatch(343/508) done. Loss: 0.0023  lr:0.010000\n"],"name":"stdout"},{"output_type":"stream","text":[" 87%|████████▋ | 444/508 [06:52<00:59,  1.08it/s]"],"name":"stderr"},{"output_type":"stream","text":["[ Sat Aug 14 17:11:19 2021 ] \tBatch(443/508) done. Loss: 0.0074  lr:0.010000\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 508/508 [07:52<00:00,  1.07it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["[ Sat Aug 14 17:12:20 2021 ] Eval epoch: 8\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 59/59 [00:27<00:00,  2.14it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["Eval Accuracy:  0.8877605558524853  model:  /content/drive/MyDrive/Colab Notebooks/CVPR21-Bh/Final_train/finetune/joint_motion/save_models/joint_motion_27_2_finetune\n","[ Sat Aug 14 17:12:47 2021 ] \tMean test loss of 59 batches: 0.5858182907104492.\n","[ Sat Aug 14 17:12:47 2021 ] \tTop1: 88.78%\n","[ Sat Aug 14 17:12:47 2021 ] \tTop5: 97.70%\n","[ Sat Aug 14 17:12:48 2021 ] Training epoch: 9\n"],"name":"stdout"},{"output_type":"stream","text":["\r  0%|          | 0/508 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["only train part, require grad\n","l1.gcn1.DecoupleA-require grad\n","l2.gcn1.DecoupleA-require grad\n","l3.gcn1.DecoupleA-require grad\n","l4.gcn1.DecoupleA-require grad\n","l5.gcn1.DecoupleA-require grad\n","l6.gcn1.DecoupleA-require grad\n","l7.gcn1.DecoupleA-require grad\n","l8.gcn1.DecoupleA-require grad\n","l9.gcn1.DecoupleA-require grad\n","l10.gcn1.DecoupleA-require grad\n"],"name":"stdout"},{"output_type":"stream","text":["  7%|▋         | 36/508 [00:35<07:18,  1.08it/s]"],"name":"stderr"},{"output_type":"stream","text":["[ Sat Aug 14 17:13:23 2021 ] \tBatch(35/508) done. Loss: 0.0023  lr:0.010000\n"],"name":"stdout"},{"output_type":"stream","text":[" 27%|██▋       | 136/508 [02:07<05:44,  1.08it/s]"],"name":"stderr"},{"output_type":"stream","text":["[ Sat Aug 14 17:14:55 2021 ] \tBatch(135/508) done. Loss: 0.0043  lr:0.010000\n"],"name":"stdout"},{"output_type":"stream","text":[" 46%|████▋     | 236/508 [03:40<04:12,  1.08it/s]"],"name":"stderr"},{"output_type":"stream","text":["[ Sat Aug 14 17:16:28 2021 ] \tBatch(235/508) done. Loss: 0.0020  lr:0.010000\n"],"name":"stdout"},{"output_type":"stream","text":[" 66%|██████▌   | 336/508 [05:13<02:39,  1.08it/s]"],"name":"stderr"},{"output_type":"stream","text":["[ Sat Aug 14 17:18:01 2021 ] \tBatch(335/508) done. Loss: 0.0045  lr:0.010000\n"],"name":"stdout"},{"output_type":"stream","text":[" 86%|████████▌ | 436/508 [06:45<01:06,  1.08it/s]"],"name":"stderr"},{"output_type":"stream","text":["[ Sat Aug 14 17:19:33 2021 ] \tBatch(435/508) done. Loss: 0.0264  lr:0.010000\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 508/508 [07:53<00:00,  1.07it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["[ Sat Aug 14 17:20:41 2021 ] Eval epoch: 9\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 59/59 [00:27<00:00,  2.13it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["Eval Accuracy:  0.8861571352218065  model:  /content/drive/MyDrive/Colab Notebooks/CVPR21-Bh/Final_train/finetune/joint_motion/save_models/joint_motion_27_2_finetune\n","[ Sat Aug 14 17:21:09 2021 ] \tMean test loss of 59 batches: 0.5836244821548462.\n","[ Sat Aug 14 17:21:09 2021 ] \tTop1: 88.62%\n","[ Sat Aug 14 17:21:09 2021 ] \tTop5: 97.70%\n","[ Sat Aug 14 17:21:09 2021 ] Training epoch: 10\n"],"name":"stdout"},{"output_type":"stream","text":["\r  0%|          | 0/508 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["only train part, require grad\n","l1.gcn1.DecoupleA-require grad\n","l2.gcn1.DecoupleA-require grad\n","l3.gcn1.DecoupleA-require grad\n","l4.gcn1.DecoupleA-require grad\n","l5.gcn1.DecoupleA-require grad\n","l6.gcn1.DecoupleA-require grad\n","l7.gcn1.DecoupleA-require grad\n","l8.gcn1.DecoupleA-require grad\n","l9.gcn1.DecoupleA-require grad\n","l10.gcn1.DecoupleA-require grad\n"],"name":"stdout"},{"output_type":"stream","text":["  6%|▌         | 28/508 [00:28<07:27,  1.07it/s]"],"name":"stderr"},{"output_type":"stream","text":["[ Sat Aug 14 17:21:37 2021 ] \tBatch(27/508) done. Loss: 0.0040  lr:0.010000\n"],"name":"stdout"},{"output_type":"stream","text":[" 25%|██▌       | 128/508 [02:00<05:52,  1.08it/s]"],"name":"stderr"},{"output_type":"stream","text":["[ Sat Aug 14 17:23:09 2021 ] \tBatch(127/508) done. Loss: 0.0017  lr:0.010000\n"],"name":"stdout"},{"output_type":"stream","text":[" 45%|████▍     | 228/508 [03:33<04:19,  1.08it/s]"],"name":"stderr"},{"output_type":"stream","text":["[ Sat Aug 14 17:24:42 2021 ] \tBatch(227/508) done. Loss: 0.0037  lr:0.010000\n"],"name":"stdout"},{"output_type":"stream","text":[" 65%|██████▍   | 328/508 [05:05<02:47,  1.08it/s]"],"name":"stderr"},{"output_type":"stream","text":["[ Sat Aug 14 17:26:15 2021 ] \tBatch(327/508) done. Loss: 0.0021  lr:0.010000\n"],"name":"stdout"},{"output_type":"stream","text":[" 84%|████████▍ | 428/508 [06:38<01:14,  1.08it/s]"],"name":"stderr"},{"output_type":"stream","text":["[ Sat Aug 14 17:27:47 2021 ] \tBatch(427/508) done. Loss: 0.0260  lr:0.010000\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 508/508 [07:53<00:00,  1.07it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["[ Sat Aug 14 17:29:02 2021 ] Eval epoch: 10\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 59/59 [00:27<00:00,  2.14it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["Eval Accuracy:  0.8866916087653661  model:  /content/drive/MyDrive/Colab Notebooks/CVPR21-Bh/Final_train/finetune/joint_motion/save_models/joint_motion_27_2_finetune\n","[ Sat Aug 14 17:29:30 2021 ] \tMean test loss of 59 batches: 0.5952447056770325.\n","[ Sat Aug 14 17:29:30 2021 ] \tTop1: 88.67%\n","[ Sat Aug 14 17:29:30 2021 ] \tTop5: 97.62%\n","[ Sat Aug 14 17:29:30 2021 ] Training epoch: 11\n"],"name":"stdout"},{"output_type":"stream","text":["\r  0%|          | 0/508 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["only train part, require grad\n","l1.gcn1.DecoupleA-require grad\n","l2.gcn1.DecoupleA-require grad\n","l3.gcn1.DecoupleA-require grad\n","l4.gcn1.DecoupleA-require grad\n","l5.gcn1.DecoupleA-require grad\n","l6.gcn1.DecoupleA-require grad\n","l7.gcn1.DecoupleA-require grad\n","l8.gcn1.DecoupleA-require grad\n","l9.gcn1.DecoupleA-require grad\n","l10.gcn1.DecoupleA-require grad\n"],"name":"stdout"},{"output_type":"stream","text":["  4%|▍         | 20/508 [00:20<07:32,  1.08it/s]"],"name":"stderr"},{"output_type":"stream","text":["[ Sat Aug 14 17:29:51 2021 ] \tBatch(19/508) done. Loss: 0.0010  lr:0.010000\n"],"name":"stdout"},{"output_type":"stream","text":[" 24%|██▎       | 120/508 [01:52<05:58,  1.08it/s]"],"name":"stderr"},{"output_type":"stream","text":["[ Sat Aug 14 17:31:23 2021 ] \tBatch(119/508) done. Loss: 0.0019  lr:0.010000\n"],"name":"stdout"},{"output_type":"stream","text":[" 43%|████▎     | 220/508 [03:25<04:26,  1.08it/s]"],"name":"stderr"},{"output_type":"stream","text":["[ Sat Aug 14 17:32:56 2021 ] \tBatch(219/508) done. Loss: 0.0048  lr:0.010000\n"],"name":"stdout"},{"output_type":"stream","text":[" 63%|██████▎   | 320/508 [04:58<02:53,  1.08it/s]"],"name":"stderr"},{"output_type":"stream","text":["[ Sat Aug 14 17:34:28 2021 ] \tBatch(319/508) done. Loss: 0.0025  lr:0.010000\n"],"name":"stdout"},{"output_type":"stream","text":[" 83%|████████▎ | 420/508 [06:30<01:21,  1.08it/s]"],"name":"stderr"},{"output_type":"stream","text":["[ Sat Aug 14 17:36:01 2021 ] \tBatch(419/508) done. Loss: 0.0020  lr:0.010000\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 508/508 [07:52<00:00,  1.07it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["[ Sat Aug 14 17:37:23 2021 ] Eval epoch: 11\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 59/59 [00:27<00:00,  2.14it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["Eval Accuracy:  0.8872260823089257  model:  /content/drive/MyDrive/Colab Notebooks/CVPR21-Bh/Final_train/finetune/joint_motion/save_models/joint_motion_27_2_finetune\n","[ Sat Aug 14 17:37:51 2021 ] \tMean test loss of 59 batches: 0.5834132432937622.\n","[ Sat Aug 14 17:37:51 2021 ] \tTop1: 88.72%\n","[ Sat Aug 14 17:37:51 2021 ] \tTop5: 97.70%\n","[ Sat Aug 14 17:37:51 2021 ] Training epoch: 12\n"],"name":"stdout"},{"output_type":"stream","text":["\r  0%|          | 0/508 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["only train part, require grad\n","l1.gcn1.DecoupleA-require grad\n","l2.gcn1.DecoupleA-require grad\n","l3.gcn1.DecoupleA-require grad\n","l4.gcn1.DecoupleA-require grad\n","l5.gcn1.DecoupleA-require grad\n","l6.gcn1.DecoupleA-require grad\n","l7.gcn1.DecoupleA-require grad\n","l8.gcn1.DecoupleA-require grad\n","l9.gcn1.DecoupleA-require grad\n","l10.gcn1.DecoupleA-require grad\n"],"name":"stdout"},{"output_type":"stream","text":["  2%|▏         | 12/508 [00:13<07:45,  1.06it/s]"],"name":"stderr"},{"output_type":"stream","text":["[ Sat Aug 14 17:38:04 2021 ] \tBatch(11/508) done. Loss: 0.0034  lr:0.010000\n"],"name":"stdout"},{"output_type":"stream","text":[" 22%|██▏       | 112/508 [01:45<06:07,  1.08it/s]"],"name":"stderr"},{"output_type":"stream","text":["[ Sat Aug 14 17:39:37 2021 ] \tBatch(111/508) done. Loss: 0.0187  lr:0.010000\n"],"name":"stdout"},{"output_type":"stream","text":[" 42%|████▏     | 212/508 [03:18<04:34,  1.08it/s]"],"name":"stderr"},{"output_type":"stream","text":["[ Sat Aug 14 17:41:09 2021 ] \tBatch(211/508) done. Loss: 0.0088  lr:0.010000\n"],"name":"stdout"},{"output_type":"stream","text":[" 61%|██████▏   | 312/508 [04:50<03:01,  1.08it/s]"],"name":"stderr"},{"output_type":"stream","text":["[ Sat Aug 14 17:42:42 2021 ] \tBatch(311/508) done. Loss: 0.0014  lr:0.010000\n"],"name":"stdout"},{"output_type":"stream","text":[" 81%|████████  | 412/508 [06:23<01:29,  1.08it/s]"],"name":"stderr"},{"output_type":"stream","text":["[ Sat Aug 14 17:44:14 2021 ] \tBatch(411/508) done. Loss: 0.0051  lr:0.010000\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 508/508 [07:53<00:00,  1.07it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["[ Sat Aug 14 17:45:44 2021 ] Eval epoch: 12\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 59/59 [00:27<00:00,  2.14it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["Eval Accuracy:  0.8866916087653661  model:  /content/drive/MyDrive/Colab Notebooks/CVPR21-Bh/Final_train/finetune/joint_motion/save_models/joint_motion_27_2_finetune\n","[ Sat Aug 14 17:46:12 2021 ] \tMean test loss of 59 batches: 0.5683164596557617.\n","[ Sat Aug 14 17:46:12 2021 ] \tTop1: 88.67%\n","[ Sat Aug 14 17:46:12 2021 ] \tTop5: 97.78%\n","[ Sat Aug 14 17:46:12 2021 ] Training epoch: 13\n"],"name":"stdout"},{"output_type":"stream","text":["\r  0%|          | 0/508 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["only train part, require grad\n","l1.gcn1.DecoupleA-require grad\n","l2.gcn1.DecoupleA-require grad\n","l3.gcn1.DecoupleA-require grad\n","l4.gcn1.DecoupleA-require grad\n","l5.gcn1.DecoupleA-require grad\n","l6.gcn1.DecoupleA-require grad\n","l7.gcn1.DecoupleA-require grad\n","l8.gcn1.DecoupleA-require grad\n","l9.gcn1.DecoupleA-require grad\n","l10.gcn1.DecoupleA-require grad\n"],"name":"stdout"},{"output_type":"stream","text":["  1%|          | 4/508 [00:05<10:00,  1.19s/it]"],"name":"stderr"},{"output_type":"stream","text":["[ Sat Aug 14 17:46:18 2021 ] \tBatch(3/508) done. Loss: 0.0028  lr:0.010000\n"],"name":"stdout"},{"output_type":"stream","text":[" 20%|██        | 104/508 [01:38<06:14,  1.08it/s]"],"name":"stderr"},{"output_type":"stream","text":["[ Sat Aug 14 17:47:50 2021 ] \tBatch(103/508) done. Loss: 0.0105  lr:0.010000\n"],"name":"stdout"},{"output_type":"stream","text":[" 40%|████      | 204/508 [03:10<04:42,  1.08it/s]"],"name":"stderr"},{"output_type":"stream","text":["[ Sat Aug 14 17:49:23 2021 ] \tBatch(203/508) done. Loss: 0.0039  lr:0.010000\n"],"name":"stdout"},{"output_type":"stream","text":[" 60%|█████▉    | 304/508 [04:43<03:09,  1.08it/s]"],"name":"stderr"},{"output_type":"stream","text":["[ Sat Aug 14 17:50:55 2021 ] \tBatch(303/508) done. Loss: 0.0005  lr:0.010000\n"],"name":"stdout"},{"output_type":"stream","text":[" 80%|███████▉  | 404/508 [06:15<01:36,  1.08it/s]"],"name":"stderr"},{"output_type":"stream","text":["[ Sat Aug 14 17:52:28 2021 ] \tBatch(403/508) done. Loss: 0.0817  lr:0.010000\n"],"name":"stdout"},{"output_type":"stream","text":[" 99%|█████████▉| 504/508 [07:48<00:03,  1.08it/s]"],"name":"stderr"},{"output_type":"stream","text":["[ Sat Aug 14 17:54:01 2021 ] \tBatch(503/508) done. Loss: 0.0016  lr:0.010000\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 508/508 [07:53<00:00,  1.07it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["[ Sat Aug 14 17:54:05 2021 ] Eval epoch: 13\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 59/59 [00:27<00:00,  2.14it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["Eval Accuracy:  0.8872260823089257  model:  /content/drive/MyDrive/Colab Notebooks/CVPR21-Bh/Final_train/finetune/joint_motion/save_models/joint_motion_27_2_finetune\n","[ Sat Aug 14 17:54:33 2021 ] \tMean test loss of 59 batches: 0.563316822052002.\n","[ Sat Aug 14 17:54:33 2021 ] \tTop1: 88.72%\n","[ Sat Aug 14 17:54:33 2021 ] \tTop5: 97.78%\n","[ Sat Aug 14 17:54:33 2021 ] Training epoch: 14\n"],"name":"stdout"},{"output_type":"stream","text":["\r  0%|          | 0/508 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["only train part, require grad\n","l1.gcn1.DecoupleA-require grad\n","l2.gcn1.DecoupleA-require grad\n","l3.gcn1.DecoupleA-require grad\n","l4.gcn1.DecoupleA-require grad\n","l5.gcn1.DecoupleA-require grad\n","l6.gcn1.DecoupleA-require grad\n","l7.gcn1.DecoupleA-require grad\n","l8.gcn1.DecoupleA-require grad\n","l9.gcn1.DecoupleA-require grad\n","l10.gcn1.DecoupleA-require grad\n"],"name":"stdout"},{"output_type":"stream","text":[" 19%|█▉        | 96/508 [01:31<06:20,  1.08it/s]"],"name":"stderr"},{"output_type":"stream","text":["[ Sat Aug 14 17:56:04 2021 ] \tBatch(95/508) done. Loss: 0.0010  lr:0.010000\n"],"name":"stdout"},{"output_type":"stream","text":[" 39%|███▊      | 196/508 [03:03<04:49,  1.08it/s]"],"name":"stderr"},{"output_type":"stream","text":["[ Sat Aug 14 17:57:37 2021 ] \tBatch(195/508) done. Loss: 0.0085  lr:0.010000\n"],"name":"stdout"},{"output_type":"stream","text":[" 58%|█████▊    | 296/508 [04:36<03:16,  1.08it/s]"],"name":"stderr"},{"output_type":"stream","text":["[ Sat Aug 14 17:59:09 2021 ] \tBatch(295/508) done. Loss: 0.0009  lr:0.010000\n"],"name":"stdout"},{"output_type":"stream","text":[" 78%|███████▊  | 396/508 [06:08<01:43,  1.08it/s]"],"name":"stderr"},{"output_type":"stream","text":["[ Sat Aug 14 18:00:42 2021 ] \tBatch(395/508) done. Loss: 0.0022  lr:0.010000\n"],"name":"stdout"},{"output_type":"stream","text":[" 98%|█████████▊| 496/508 [07:41<00:11,  1.08it/s]"],"name":"stderr"},{"output_type":"stream","text":["[ Sat Aug 14 18:02:14 2021 ] \tBatch(495/508) done. Loss: 0.0070  lr:0.010000\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 508/508 [07:53<00:00,  1.07it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["[ Sat Aug 14 18:02:26 2021 ] Eval epoch: 14\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 59/59 [00:27<00:00,  2.13it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["Eval Accuracy:  0.8880277926242651  model:  /content/drive/MyDrive/Colab Notebooks/CVPR21-Bh/Final_train/finetune/joint_motion/save_models/joint_motion_27_2_finetune\n","[ Sat Aug 14 18:02:54 2021 ] \tMean test loss of 59 batches: 0.5609498023986816.\n","[ Sat Aug 14 18:02:54 2021 ] \tTop1: 88.80%\n","[ Sat Aug 14 18:02:54 2021 ] \tTop5: 97.81%\n","[ Sat Aug 14 18:02:54 2021 ] Training epoch: 15\n"],"name":"stdout"},{"output_type":"stream","text":["\r  0%|          | 0/508 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["only train part, require grad\n","l1.gcn1.DecoupleA-require grad\n","l2.gcn1.DecoupleA-require grad\n","l3.gcn1.DecoupleA-require grad\n","l4.gcn1.DecoupleA-require grad\n","l5.gcn1.DecoupleA-require grad\n","l6.gcn1.DecoupleA-require grad\n","l7.gcn1.DecoupleA-require grad\n","l8.gcn1.DecoupleA-require grad\n","l9.gcn1.DecoupleA-require grad\n","l10.gcn1.DecoupleA-require grad\n"],"name":"stdout"},{"output_type":"stream","text":[" 17%|█▋        | 88/508 [01:23<06:27,  1.08it/s]"],"name":"stderr"},{"output_type":"stream","text":["[ Sat Aug 14 18:04:18 2021 ] \tBatch(87/508) done. Loss: 0.0031  lr:0.010000\n"],"name":"stdout"},{"output_type":"stream","text":[" 37%|███▋      | 188/508 [02:55<04:56,  1.08it/s]"],"name":"stderr"},{"output_type":"stream","text":["[ Sat Aug 14 18:05:50 2021 ] \tBatch(187/508) done. Loss: 0.0012  lr:0.010000\n"],"name":"stdout"},{"output_type":"stream","text":[" 57%|█████▋    | 288/508 [04:28<03:24,  1.08it/s]"],"name":"stderr"},{"output_type":"stream","text":["[ Sat Aug 14 18:07:23 2021 ] \tBatch(287/508) done. Loss: 0.0074  lr:0.010000\n"],"name":"stdout"},{"output_type":"stream","text":[" 76%|███████▋  | 388/508 [06:01<01:51,  1.08it/s]"],"name":"stderr"},{"output_type":"stream","text":["[ Sat Aug 14 18:08:55 2021 ] \tBatch(387/508) done. Loss: 0.0029  lr:0.010000\n"],"name":"stdout"},{"output_type":"stream","text":[" 96%|█████████▌| 488/508 [07:33<00:18,  1.08it/s]"],"name":"stderr"},{"output_type":"stream","text":["[ Sat Aug 14 18:10:28 2021 ] \tBatch(487/508) done. Loss: 0.0120  lr:0.010000\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 508/508 [07:52<00:00,  1.07it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["[ Sat Aug 14 18:10:47 2021 ] Eval epoch: 15\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 59/59 [00:27<00:00,  2.15it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["Eval Accuracy:  0.8848209513629075  model:  /content/drive/MyDrive/Colab Notebooks/CVPR21-Bh/Final_train/finetune/joint_motion/save_models/joint_motion_27_2_finetune\n","[ Sat Aug 14 18:11:15 2021 ] \tMean test loss of 59 batches: 0.5679386854171753.\n","[ Sat Aug 14 18:11:15 2021 ] \tTop1: 88.48%\n","[ Sat Aug 14 18:11:15 2021 ] \tTop5: 97.84%\n","[ Sat Aug 14 18:11:15 2021 ] Training epoch: 16\n"],"name":"stdout"},{"output_type":"stream","text":["\r  0%|          | 0/508 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["only train part, require grad\n","l1.gcn1.DecoupleA-require grad\n","l2.gcn1.DecoupleA-require grad\n","l3.gcn1.DecoupleA-require grad\n","l4.gcn1.DecoupleA-require grad\n","l5.gcn1.DecoupleA-require grad\n","l6.gcn1.DecoupleA-require grad\n","l7.gcn1.DecoupleA-require grad\n","l8.gcn1.DecoupleA-require grad\n","l9.gcn1.DecoupleA-require grad\n","l10.gcn1.DecoupleA-require grad\n"],"name":"stdout"},{"output_type":"stream","text":[" 16%|█▌        | 80/508 [01:16<06:36,  1.08it/s]"],"name":"stderr"},{"output_type":"stream","text":["[ Sat Aug 14 18:12:31 2021 ] \tBatch(79/508) done. Loss: 0.0029  lr:0.010000\n"],"name":"stdout"},{"output_type":"stream","text":[" 35%|███▌      | 180/508 [02:48<05:04,  1.08it/s]"],"name":"stderr"},{"output_type":"stream","text":["[ Sat Aug 14 18:14:03 2021 ] \tBatch(179/508) done. Loss: 0.0828  lr:0.010000\n"],"name":"stdout"},{"output_type":"stream","text":[" 55%|█████▌    | 280/508 [04:21<03:31,  1.08it/s]"],"name":"stderr"},{"output_type":"stream","text":["[ Sat Aug 14 18:15:36 2021 ] \tBatch(279/508) done. Loss: 0.0010  lr:0.010000\n"],"name":"stdout"},{"output_type":"stream","text":[" 75%|███████▍  | 380/508 [05:53<01:58,  1.08it/s]"],"name":"stderr"},{"output_type":"stream","text":["[ Sat Aug 14 18:17:09 2021 ] \tBatch(379/508) done. Loss: 0.0142  lr:0.010000\n"],"name":"stdout"},{"output_type":"stream","text":[" 94%|█████████▍| 480/508 [07:26<00:25,  1.08it/s]"],"name":"stderr"},{"output_type":"stream","text":["[ Sat Aug 14 18:18:41 2021 ] \tBatch(479/508) done. Loss: 0.0031  lr:0.010000\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 508/508 [07:52<00:00,  1.07it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["[ Sat Aug 14 18:19:08 2021 ] Eval epoch: 16\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 59/59 [00:27<00:00,  2.14it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["Eval Accuracy:  0.8869588455371459  model:  /content/drive/MyDrive/Colab Notebooks/CVPR21-Bh/Final_train/finetune/joint_motion/save_models/joint_motion_27_2_finetune\n","[ Sat Aug 14 18:19:36 2021 ] \tMean test loss of 59 batches: 0.5517228245735168.\n","[ Sat Aug 14 18:19:36 2021 ] \tTop1: 88.70%\n","[ Sat Aug 14 18:19:36 2021 ] \tTop5: 97.86%\n","[ Sat Aug 14 18:19:36 2021 ] Training epoch: 17\n"],"name":"stdout"},{"output_type":"stream","text":["\r  0%|          | 0/508 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["only train part, require grad\n","l1.gcn1.DecoupleA-require grad\n","l2.gcn1.DecoupleA-require grad\n","l3.gcn1.DecoupleA-require grad\n","l4.gcn1.DecoupleA-require grad\n","l5.gcn1.DecoupleA-require grad\n","l6.gcn1.DecoupleA-require grad\n","l7.gcn1.DecoupleA-require grad\n","l8.gcn1.DecoupleA-require grad\n","l9.gcn1.DecoupleA-require grad\n","l10.gcn1.DecoupleA-require grad\n"],"name":"stdout"},{"output_type":"stream","text":[" 14%|█▍        | 72/508 [01:08<06:43,  1.08it/s]"],"name":"stderr"},{"output_type":"stream","text":["[ Sat Aug 14 18:20:44 2021 ] \tBatch(71/508) done. Loss: 0.0010  lr:0.010000\n"],"name":"stdout"},{"output_type":"stream","text":[" 34%|███▍      | 172/508 [02:41<05:11,  1.08it/s]"],"name":"stderr"},{"output_type":"stream","text":["[ Sat Aug 14 18:22:17 2021 ] \tBatch(171/508) done. Loss: 0.0115  lr:0.010000\n"],"name":"stdout"},{"output_type":"stream","text":[" 54%|█████▎    | 272/508 [04:13<03:38,  1.08it/s]"],"name":"stderr"},{"output_type":"stream","text":["[ Sat Aug 14 18:23:49 2021 ] \tBatch(271/508) done. Loss: 0.0084  lr:0.010000\n"],"name":"stdout"},{"output_type":"stream","text":[" 73%|███████▎  | 372/508 [05:46<02:05,  1.08it/s]"],"name":"stderr"},{"output_type":"stream","text":["[ Sat Aug 14 18:25:22 2021 ] \tBatch(371/508) done. Loss: 0.0026  lr:0.010000\n"],"name":"stdout"},{"output_type":"stream","text":[" 93%|█████████▎| 472/508 [07:18<00:33,  1.08it/s]"],"name":"stderr"},{"output_type":"stream","text":["[ Sat Aug 14 18:26:54 2021 ] \tBatch(471/508) done. Loss: 0.0012  lr:0.010000\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 508/508 [07:52<00:00,  1.08it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["[ Sat Aug 14 18:27:29 2021 ] Eval epoch: 17\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 59/59 [00:27<00:00,  2.13it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["Eval Accuracy:  0.8869588455371459  model:  /content/drive/MyDrive/Colab Notebooks/CVPR21-Bh/Final_train/finetune/joint_motion/save_models/joint_motion_27_2_finetune\n","[ Sat Aug 14 18:27:56 2021 ] \tMean test loss of 59 batches: 0.5536172389984131.\n","[ Sat Aug 14 18:27:56 2021 ] \tTop1: 88.70%\n","[ Sat Aug 14 18:27:56 2021 ] \tTop5: 97.59%\n","[ Sat Aug 14 18:27:56 2021 ] Training epoch: 18\n"],"name":"stdout"},{"output_type":"stream","text":["\r  0%|          | 0/508 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["only train part, require grad\n","l1.gcn1.DecoupleA-require grad\n","l2.gcn1.DecoupleA-require grad\n","l3.gcn1.DecoupleA-require grad\n","l4.gcn1.DecoupleA-require grad\n","l5.gcn1.DecoupleA-require grad\n","l6.gcn1.DecoupleA-require grad\n","l7.gcn1.DecoupleA-require grad\n","l8.gcn1.DecoupleA-require grad\n","l9.gcn1.DecoupleA-require grad\n","l10.gcn1.DecoupleA-require grad\n"],"name":"stdout"},{"output_type":"stream","text":[" 13%|█▎        | 64/508 [01:01<06:50,  1.08it/s]"],"name":"stderr"},{"output_type":"stream","text":["[ Sat Aug 14 18:28:58 2021 ] \tBatch(63/508) done. Loss: 0.0045  lr:0.010000\n"],"name":"stdout"},{"output_type":"stream","text":[" 32%|███▏      | 164/508 [02:33<05:18,  1.08it/s]"],"name":"stderr"},{"output_type":"stream","text":["[ Sat Aug 14 18:30:30 2021 ] \tBatch(163/508) done. Loss: 0.0030  lr:0.010000\n"],"name":"stdout"},{"output_type":"stream","text":[" 52%|█████▏    | 264/508 [04:05<03:46,  1.08it/s]"],"name":"stderr"},{"output_type":"stream","text":["[ Sat Aug 14 18:32:02 2021 ] \tBatch(263/508) done. Loss: 0.0014  lr:0.010000\n"],"name":"stdout"},{"output_type":"stream","text":[" 72%|███████▏  | 364/508 [05:38<02:13,  1.08it/s]"],"name":"stderr"},{"output_type":"stream","text":["[ Sat Aug 14 18:33:35 2021 ] \tBatch(363/508) done. Loss: 0.0003  lr:0.010000\n"],"name":"stdout"},{"output_type":"stream","text":[" 91%|█████████▏| 464/508 [07:10<00:40,  1.08it/s]"],"name":"stderr"},{"output_type":"stream","text":["[ Sat Aug 14 18:35:07 2021 ] \tBatch(463/508) done. Loss: 0.0018  lr:0.010000\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 508/508 [07:52<00:00,  1.08it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["[ Sat Aug 14 18:35:49 2021 ] Eval epoch: 18\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 59/59 [00:27<00:00,  2.12it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["Eval Accuracy:  0.8877605558524853  model:  /content/drive/MyDrive/Colab Notebooks/CVPR21-Bh/Final_train/finetune/joint_motion/save_models/joint_motion_27_2_finetune\n","[ Sat Aug 14 18:36:17 2021 ] \tMean test loss of 59 batches: 0.5525308847427368.\n","[ Sat Aug 14 18:36:17 2021 ] \tTop1: 88.78%\n","[ Sat Aug 14 18:36:17 2021 ] \tTop5: 97.86%\n","[ Sat Aug 14 18:36:17 2021 ] Training epoch: 19\n"],"name":"stdout"},{"output_type":"stream","text":["\r  0%|          | 0/508 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["only train part, require grad\n","l1.gcn1.DecoupleA-require grad\n","l2.gcn1.DecoupleA-require grad\n","l3.gcn1.DecoupleA-require grad\n","l4.gcn1.DecoupleA-require grad\n","l5.gcn1.DecoupleA-require grad\n","l6.gcn1.DecoupleA-require grad\n","l7.gcn1.DecoupleA-require grad\n","l8.gcn1.DecoupleA-require grad\n","l9.gcn1.DecoupleA-require grad\n","l10.gcn1.DecoupleA-require grad\n"],"name":"stdout"},{"output_type":"stream","text":[" 11%|█         | 56/508 [00:53<06:58,  1.08it/s]"],"name":"stderr"},{"output_type":"stream","text":["[ Sat Aug 14 18:37:11 2021 ] \tBatch(55/508) done. Loss: 0.0037  lr:0.010000\n"],"name":"stdout"},{"output_type":"stream","text":[" 31%|███       | 156/508 [02:26<05:25,  1.08it/s]"],"name":"stderr"},{"output_type":"stream","text":["[ Sat Aug 14 18:38:43 2021 ] \tBatch(155/508) done. Loss: 0.0020  lr:0.010000\n"],"name":"stdout"},{"output_type":"stream","text":[" 50%|█████     | 256/508 [03:58<03:53,  1.08it/s]"],"name":"stderr"},{"output_type":"stream","text":["[ Sat Aug 14 18:40:16 2021 ] \tBatch(255/508) done. Loss: 0.0020  lr:0.010000\n"],"name":"stdout"},{"output_type":"stream","text":[" 70%|███████   | 356/508 [05:31<02:20,  1.08it/s]"],"name":"stderr"},{"output_type":"stream","text":["[ Sat Aug 14 18:41:48 2021 ] \tBatch(355/508) done. Loss: 0.0020  lr:0.010000\n"],"name":"stdout"},{"output_type":"stream","text":[" 90%|████████▉ | 456/508 [07:03<00:48,  1.08it/s]"],"name":"stderr"},{"output_type":"stream","text":["[ Sat Aug 14 18:43:21 2021 ] \tBatch(455/508) done. Loss: 0.0017  lr:0.010000\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 508/508 [07:52<00:00,  1.08it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["[ Sat Aug 14 18:44:10 2021 ] Eval epoch: 19\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 59/59 [00:27<00:00,  2.14it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["Eval Accuracy:  0.8917691074291823  model:  /content/drive/MyDrive/Colab Notebooks/CVPR21-Bh/Final_train/finetune/joint_motion/save_models/joint_motion_27_2_finetune\n","[ Sat Aug 14 18:44:37 2021 ] \tMean test loss of 59 batches: 0.5470690131187439.\n","[ Sat Aug 14 18:44:37 2021 ] \tTop1: 89.18%\n","[ Sat Aug 14 18:44:37 2021 ] \tTop5: 97.76%\n","[ Sat Aug 14 18:44:38 2021 ] Training epoch: 20\n"],"name":"stdout"},{"output_type":"stream","text":["\r  0%|          | 0/508 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["only train part, require grad\n","l1.gcn1.DecoupleA-require grad\n","l2.gcn1.DecoupleA-require grad\n","l3.gcn1.DecoupleA-require grad\n","l4.gcn1.DecoupleA-require grad\n","l5.gcn1.DecoupleA-require grad\n","l6.gcn1.DecoupleA-require grad\n","l7.gcn1.DecoupleA-require grad\n","l8.gcn1.DecoupleA-require grad\n","l9.gcn1.DecoupleA-require grad\n","l10.gcn1.DecoupleA-require grad\n"],"name":"stdout"},{"output_type":"stream","text":["  9%|▉         | 48/508 [00:46<07:05,  1.08it/s]"],"name":"stderr"},{"output_type":"stream","text":["[ Sat Aug 14 18:45:24 2021 ] \tBatch(47/508) done. Loss: 0.0059  lr:0.010000\n"],"name":"stdout"},{"output_type":"stream","text":[" 29%|██▉       | 148/508 [02:18<05:33,  1.08it/s]"],"name":"stderr"},{"output_type":"stream","text":["[ Sat Aug 14 18:46:56 2021 ] \tBatch(147/508) done. Loss: 0.0050  lr:0.010000\n"],"name":"stdout"},{"output_type":"stream","text":[" 49%|████▉     | 248/508 [03:51<04:01,  1.08it/s]"],"name":"stderr"},{"output_type":"stream","text":["[ Sat Aug 14 18:48:29 2021 ] \tBatch(247/508) done. Loss: 0.0025  lr:0.010000\n"],"name":"stdout"},{"output_type":"stream","text":[" 69%|██████▊   | 348/508 [05:23<02:28,  1.08it/s]"],"name":"stderr"},{"output_type":"stream","text":["[ Sat Aug 14 18:50:01 2021 ] \tBatch(347/508) done. Loss: 0.0011  lr:0.010000\n"],"name":"stdout"},{"output_type":"stream","text":[" 88%|████████▊ | 448/508 [06:56<00:55,  1.08it/s]"],"name":"stderr"},{"output_type":"stream","text":["[ Sat Aug 14 18:51:34 2021 ] \tBatch(447/508) done. Loss: 0.0036  lr:0.010000\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 508/508 [07:52<00:00,  1.07it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["[ Sat Aug 14 18:52:30 2021 ] Eval epoch: 20\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 59/59 [00:27<00:00,  2.14it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["Eval Accuracy:  0.8917691074291823  model:  /content/drive/MyDrive/Colab Notebooks/CVPR21-Bh/Final_train/finetune/joint_motion/save_models/joint_motion_27_2_finetune\n","[ Sat Aug 14 18:52:58 2021 ] \tMean test loss of 59 batches: 0.5415543913841248.\n","[ Sat Aug 14 18:52:58 2021 ] \tTop1: 89.18%\n","[ Sat Aug 14 18:52:58 2021 ] \tTop5: 97.68%\n","[ Sat Aug 14 18:52:58 2021 ] Training epoch: 21\n"],"name":"stdout"},{"output_type":"stream","text":["\r  0%|          | 0/508 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["only train part, require grad\n","l1.gcn1.DecoupleA-require grad\n","l2.gcn1.DecoupleA-require grad\n","l3.gcn1.DecoupleA-require grad\n","l4.gcn1.DecoupleA-require grad\n","l5.gcn1.DecoupleA-require grad\n","l6.gcn1.DecoupleA-require grad\n","l7.gcn1.DecoupleA-require grad\n","l8.gcn1.DecoupleA-require grad\n","l9.gcn1.DecoupleA-require grad\n","l10.gcn1.DecoupleA-require grad\n"],"name":"stdout"},{"output_type":"stream","text":["  8%|▊         | 40/508 [00:38<07:13,  1.08it/s]"],"name":"stderr"},{"output_type":"stream","text":["[ Sat Aug 14 18:53:37 2021 ] \tBatch(39/508) done. Loss: 0.0016  lr:0.010000\n"],"name":"stdout"},{"output_type":"stream","text":[" 28%|██▊       | 140/508 [02:11<05:40,  1.08it/s]"],"name":"stderr"},{"output_type":"stream","text":["[ Sat Aug 14 18:55:10 2021 ] \tBatch(139/508) done. Loss: 0.0069  lr:0.010000\n"],"name":"stdout"},{"output_type":"stream","text":[" 47%|████▋     | 240/508 [03:43<04:08,  1.08it/s]"],"name":"stderr"},{"output_type":"stream","text":["[ Sat Aug 14 18:56:42 2021 ] \tBatch(239/508) done. Loss: 0.0081  lr:0.010000\n"],"name":"stdout"},{"output_type":"stream","text":[" 67%|██████▋   | 340/508 [05:16<02:35,  1.08it/s]"],"name":"stderr"},{"output_type":"stream","text":["[ Sat Aug 14 18:58:15 2021 ] \tBatch(339/508) done. Loss: 0.0006  lr:0.010000\n"],"name":"stdout"},{"output_type":"stream","text":[" 87%|████████▋ | 440/508 [06:48<01:02,  1.08it/s]"],"name":"stderr"},{"output_type":"stream","text":["[ Sat Aug 14 18:59:47 2021 ] \tBatch(439/508) done. Loss: 0.0042  lr:0.010000\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 508/508 [07:52<00:00,  1.08it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["[ Sat Aug 14 19:00:51 2021 ] Eval epoch: 21\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 59/59 [00:27<00:00,  2.15it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["Eval Accuracy:  0.8888295029396045  model:  /content/drive/MyDrive/Colab Notebooks/CVPR21-Bh/Final_train/finetune/joint_motion/save_models/joint_motion_27_2_finetune\n","[ Sat Aug 14 19:01:18 2021 ] \tMean test loss of 59 batches: 0.5491750240325928.\n","[ Sat Aug 14 19:01:18 2021 ] \tTop1: 88.88%\n","[ Sat Aug 14 19:01:18 2021 ] \tTop5: 97.76%\n","[ Sat Aug 14 19:01:18 2021 ] Training epoch: 22\n"],"name":"stdout"},{"output_type":"stream","text":["\r  0%|          | 0/508 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["only train part, require grad\n","l1.gcn1.DecoupleA-require grad\n","l2.gcn1.DecoupleA-require grad\n","l3.gcn1.DecoupleA-require grad\n","l4.gcn1.DecoupleA-require grad\n","l5.gcn1.DecoupleA-require grad\n","l6.gcn1.DecoupleA-require grad\n","l7.gcn1.DecoupleA-require grad\n","l8.gcn1.DecoupleA-require grad\n","l9.gcn1.DecoupleA-require grad\n","l10.gcn1.DecoupleA-require grad\n"],"name":"stdout"},{"output_type":"stream","text":["  6%|▋         | 32/508 [00:31<07:22,  1.08it/s]"],"name":"stderr"},{"output_type":"stream","text":["[ Sat Aug 14 19:01:50 2021 ] \tBatch(31/508) done. Loss: 0.0061  lr:0.010000\n"],"name":"stdout"},{"output_type":"stream","text":[" 26%|██▌       | 132/508 [02:04<05:47,  1.08it/s]"],"name":"stderr"},{"output_type":"stream","text":["[ Sat Aug 14 19:03:23 2021 ] \tBatch(131/508) done. Loss: 0.0066  lr:0.010000\n"],"name":"stdout"},{"output_type":"stream","text":[" 46%|████▌     | 232/508 [03:36<04:15,  1.08it/s]"],"name":"stderr"},{"output_type":"stream","text":["[ Sat Aug 14 19:04:55 2021 ] \tBatch(231/508) done. Loss: 0.0033  lr:0.010000\n"],"name":"stdout"},{"output_type":"stream","text":[" 65%|██████▌   | 332/508 [05:09<02:43,  1.08it/s]"],"name":"stderr"},{"output_type":"stream","text":["[ Sat Aug 14 19:06:28 2021 ] \tBatch(331/508) done. Loss: 0.0058  lr:0.010000\n"],"name":"stdout"},{"output_type":"stream","text":[" 85%|████████▌ | 432/508 [06:42<01:10,  1.08it/s]"],"name":"stderr"},{"output_type":"stream","text":["[ Sat Aug 14 19:08:00 2021 ] \tBatch(431/508) done. Loss: 0.0033  lr:0.010000\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 508/508 [07:52<00:00,  1.07it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["[ Sat Aug 14 19:09:12 2021 ] Eval epoch: 22\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 59/59 [00:27<00:00,  2.15it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["Eval Accuracy:  0.8925708177445216  model:  /content/drive/MyDrive/Colab Notebooks/CVPR21-Bh/Final_train/finetune/joint_motion/save_models/joint_motion_27_2_finetune\n","[ Sat Aug 14 19:09:39 2021 ] \tMean test loss of 59 batches: 0.5351611375808716.\n","[ Sat Aug 14 19:09:39 2021 ] \tTop1: 89.26%\n","[ Sat Aug 14 19:09:39 2021 ] \tTop5: 97.73%\n","[ Sat Aug 14 19:09:39 2021 ] Training epoch: 23\n"],"name":"stdout"},{"output_type":"stream","text":["\r  0%|          | 0/508 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["only train part, require grad\n","l1.gcn1.DecoupleA-require grad\n","l2.gcn1.DecoupleA-require grad\n","l3.gcn1.DecoupleA-require grad\n","l4.gcn1.DecoupleA-require grad\n","l5.gcn1.DecoupleA-require grad\n","l6.gcn1.DecoupleA-require grad\n","l7.gcn1.DecoupleA-require grad\n","l8.gcn1.DecoupleA-require grad\n","l9.gcn1.DecoupleA-require grad\n","l10.gcn1.DecoupleA-require grad\n"],"name":"stdout"},{"output_type":"stream","text":["  5%|▍         | 24/508 [00:24<07:26,  1.08it/s]"],"name":"stderr"},{"output_type":"stream","text":["[ Sat Aug 14 19:10:03 2021 ] \tBatch(23/508) done. Loss: 0.0075  lr:0.010000\n"],"name":"stdout"},{"output_type":"stream","text":[" 24%|██▍       | 124/508 [01:56<05:55,  1.08it/s]"],"name":"stderr"},{"output_type":"stream","text":["[ Sat Aug 14 19:11:36 2021 ] \tBatch(123/508) done. Loss: 0.0042  lr:0.010000\n"],"name":"stdout"},{"output_type":"stream","text":[" 44%|████▍     | 224/508 [03:29<04:23,  1.08it/s]"],"name":"stderr"},{"output_type":"stream","text":["[ Sat Aug 14 19:13:08 2021 ] \tBatch(223/508) done. Loss: 0.0101  lr:0.010000\n"],"name":"stdout"},{"output_type":"stream","text":[" 64%|██████▍   | 324/508 [05:01<02:50,  1.08it/s]"],"name":"stderr"},{"output_type":"stream","text":["[ Sat Aug 14 19:14:41 2021 ] \tBatch(323/508) done. Loss: 0.0026  lr:0.010000\n"],"name":"stdout"},{"output_type":"stream","text":[" 83%|████████▎ | 424/508 [06:34<01:17,  1.08it/s]"],"name":"stderr"},{"output_type":"stream","text":["[ Sat Aug 14 19:16:14 2021 ] \tBatch(423/508) done. Loss: 0.0047  lr:0.010000\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 508/508 [07:52<00:00,  1.07it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["[ Sat Aug 14 19:17:32 2021 ] Eval epoch: 23\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 59/59 [00:27<00:00,  2.14it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["Eval Accuracy:  0.8907001603420631  model:  /content/drive/MyDrive/Colab Notebooks/CVPR21-Bh/Final_train/finetune/joint_motion/save_models/joint_motion_27_2_finetune\n","[ Sat Aug 14 19:18:00 2021 ] \tMean test loss of 59 batches: 0.535522997379303.\n","[ Sat Aug 14 19:18:00 2021 ] \tTop1: 89.07%\n","[ Sat Aug 14 19:18:00 2021 ] \tTop5: 97.59%\n","[ Sat Aug 14 19:18:00 2021 ] Training epoch: 24\n"],"name":"stdout"},{"output_type":"stream","text":["\r  0%|          | 0/508 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["only train part, require grad\n","l1.gcn1.DecoupleA-require grad\n","l2.gcn1.DecoupleA-require grad\n","l3.gcn1.DecoupleA-require grad\n","l4.gcn1.DecoupleA-require grad\n","l5.gcn1.DecoupleA-require grad\n","l6.gcn1.DecoupleA-require grad\n","l7.gcn1.DecoupleA-require grad\n","l8.gcn1.DecoupleA-require grad\n","l9.gcn1.DecoupleA-require grad\n","l10.gcn1.DecoupleA-require grad\n"],"name":"stdout"},{"output_type":"stream","text":["  3%|▎         | 16/508 [00:16<07:37,  1.08it/s]"],"name":"stderr"},{"output_type":"stream","text":["[ Sat Aug 14 19:18:17 2021 ] \tBatch(15/508) done. Loss: 0.0025  lr:0.010000\n"],"name":"stdout"},{"output_type":"stream","text":[" 23%|██▎       | 116/508 [01:49<06:02,  1.08it/s]"],"name":"stderr"},{"output_type":"stream","text":["[ Sat Aug 14 19:19:49 2021 ] \tBatch(115/508) done. Loss: 0.0029  lr:0.010000\n"],"name":"stdout"},{"output_type":"stream","text":[" 43%|████▎     | 216/508 [03:21<04:32,  1.07it/s]"],"name":"stderr"},{"output_type":"stream","text":["[ Sat Aug 14 19:21:22 2021 ] \tBatch(215/508) done. Loss: 0.0038  lr:0.010000\n"],"name":"stdout"},{"output_type":"stream","text":[" 62%|██████▏   | 316/508 [04:54<02:58,  1.08it/s]"],"name":"stderr"},{"output_type":"stream","text":["[ Sat Aug 14 19:22:54 2021 ] \tBatch(315/508) done. Loss: 0.0107  lr:0.010000\n"],"name":"stdout"},{"output_type":"stream","text":[" 82%|████████▏ | 416/508 [06:26<01:25,  1.08it/s]"],"name":"stderr"},{"output_type":"stream","text":["[ Sat Aug 14 19:24:27 2021 ] \tBatch(415/508) done. Loss: 0.0036  lr:0.010000\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 508/508 [07:52<00:00,  1.07it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["[ Sat Aug 14 19:25:53 2021 ] Eval epoch: 24\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 59/59 [00:27<00:00,  2.13it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["Eval Accuracy:  0.8893639764831641  model:  /content/drive/MyDrive/Colab Notebooks/CVPR21-Bh/Final_train/finetune/joint_motion/save_models/joint_motion_27_2_finetune\n","[ Sat Aug 14 19:26:21 2021 ] \tMean test loss of 59 batches: 0.5402069091796875.\n","[ Sat Aug 14 19:26:21 2021 ] \tTop1: 88.94%\n","[ Sat Aug 14 19:26:21 2021 ] \tTop5: 97.84%\n","[ Sat Aug 14 19:26:21 2021 ] Training epoch: 25\n"],"name":"stdout"},{"output_type":"stream","text":["\r  0%|          | 0/508 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["only train part, require grad\n","l1.gcn1.DecoupleA-require grad\n","l2.gcn1.DecoupleA-require grad\n","l3.gcn1.DecoupleA-require grad\n","l4.gcn1.DecoupleA-require grad\n","l5.gcn1.DecoupleA-require grad\n","l6.gcn1.DecoupleA-require grad\n","l7.gcn1.DecoupleA-require grad\n","l8.gcn1.DecoupleA-require grad\n","l9.gcn1.DecoupleA-require grad\n","l10.gcn1.DecoupleA-require grad\n"],"name":"stdout"},{"output_type":"stream","text":["  2%|▏         | 8/508 [00:09<08:07,  1.02it/s]"],"name":"stderr"},{"output_type":"stream","text":["[ Sat Aug 14 19:26:30 2021 ] \tBatch(7/508) done. Loss: 0.0080  lr:0.010000\n"],"name":"stdout"},{"output_type":"stream","text":[" 21%|██▏       | 108/508 [01:41<06:09,  1.08it/s]"],"name":"stderr"},{"output_type":"stream","text":["[ Sat Aug 14 19:28:03 2021 ] \tBatch(107/508) done. Loss: 0.0021  lr:0.010000\n"],"name":"stdout"},{"output_type":"stream","text":[" 41%|████      | 208/508 [03:14<04:38,  1.08it/s]"],"name":"stderr"},{"output_type":"stream","text":["[ Sat Aug 14 19:29:35 2021 ] \tBatch(207/508) done. Loss: 0.0023  lr:0.010000\n"],"name":"stdout"},{"output_type":"stream","text":[" 61%|██████    | 308/508 [04:47<03:06,  1.07it/s]"],"name":"stderr"},{"output_type":"stream","text":["[ Sat Aug 14 19:31:08 2021 ] \tBatch(307/508) done. Loss: 0.0051  lr:0.010000\n"],"name":"stdout"},{"output_type":"stream","text":[" 80%|████████  | 408/508 [06:19<01:32,  1.08it/s]"],"name":"stderr"},{"output_type":"stream","text":["[ Sat Aug 14 19:32:41 2021 ] \tBatch(407/508) done. Loss: 0.0056  lr:0.010000\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 508/508 [07:52<00:00,  1.08it/s]"],"name":"stderr"},{"output_type":"stream","text":["[ Sat Aug 14 19:34:13 2021 ] \tBatch(507/508) done. Loss: 0.0025  lr:0.010000\n"],"name":"stdout"},{"output_type":"stream","text":["\r100%|██████████| 508/508 [07:53<00:00,  1.07it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["[ Sat Aug 14 19:34:14 2021 ] Eval epoch: 25\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 59/59 [00:27<00:00,  2.14it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["Eval Accuracy:  0.8917691074291823  model:  /content/drive/MyDrive/Colab Notebooks/CVPR21-Bh/Final_train/finetune/joint_motion/save_models/joint_motion_27_2_finetune\n","[ Sat Aug 14 19:34:42 2021 ] \tMean test loss of 59 batches: 0.531013548374176.\n","[ Sat Aug 14 19:34:42 2021 ] \tTop1: 89.18%\n","[ Sat Aug 14 19:34:42 2021 ] \tTop5: 97.76%\n","[ Sat Aug 14 19:34:42 2021 ] Training epoch: 26\n"],"name":"stdout"},{"output_type":"stream","text":["\r  0%|          | 0/508 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["only train part, require grad\n","l1.gcn1.DecoupleA-require grad\n","l2.gcn1.DecoupleA-require grad\n","l3.gcn1.DecoupleA-require grad\n","l4.gcn1.DecoupleA-require grad\n","l5.gcn1.DecoupleA-require grad\n","l6.gcn1.DecoupleA-require grad\n","l7.gcn1.DecoupleA-require grad\n","l8.gcn1.DecoupleA-require grad\n","l9.gcn1.DecoupleA-require grad\n","l10.gcn1.DecoupleA-require grad\n"],"name":"stdout"},{"output_type":"stream","text":[" 20%|█▉        | 100/508 [01:34<06:17,  1.08it/s]"],"name":"stderr"},{"output_type":"stream","text":["[ Sat Aug 14 19:36:17 2021 ] \tBatch(99/508) done. Loss: 0.0066  lr:0.010000\n"],"name":"stdout"},{"output_type":"stream","text":[" 39%|███▉      | 200/508 [03:07<04:46,  1.08it/s]"],"name":"stderr"},{"output_type":"stream","text":["[ Sat Aug 14 19:37:49 2021 ] \tBatch(199/508) done. Loss: 0.0009  lr:0.010000\n"],"name":"stdout"},{"output_type":"stream","text":[" 42%|████▏     | 214/508 [03:20<04:32,  1.08it/s]"],"name":"stderr"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"-T4VEC-zf-ov","executionInfo":{"status":"error","timestamp":1628176880188,"user_tz":-360,"elapsed":6785322,"user":{"displayName":"Md.safirur Rashid, 170041020","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj4vsxiS6hdwcIxlWkCOlOKX6Yb9qvDnhTv0OE=s64","userId":"07083869211232678860"}},"outputId":"75e2c36c-c045-4fa1-e72a-9209419aaff2"},"source":["%cd /content/CVPR21Chal-SLR/SL-GCN\n","init_seed(0)\n","processor = Processor(arg)\n","processor.start()\n","%cd /content"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/content/CVPR21Chal-SLR/SL-GCN\n"],"name":"stdout"},{"output_type":"stream","text":["/content/CVPR21Chal-SLR/SL-GCN/model/decouple_gcn_attn.py:29: UserWarning: nn.init.kaiming_normal is now deprecated in favor of nn.init.kaiming_normal_.\n","  nn.init.kaiming_normal(conv.weight, mode='fan_out')\n","/content/CVPR21Chal-SLR/SL-GCN/model/decouple_gcn_attn.py:30: UserWarning: nn.init.constant is now deprecated in favor of nn.init.constant_.\n","  nn.init.constant(conv.bias, 0)\n","/content/CVPR21Chal-SLR/SL-GCN/model/decouple_gcn_attn.py:34: UserWarning: nn.init.constant is now deprecated in favor of nn.init.constant_.\n","  nn.init.constant(bn.weight, scale)\n","/content/CVPR21Chal-SLR/SL-GCN/model/decouple_gcn_attn.py:35: UserWarning: nn.init.constant is now deprecated in favor of nn.init.constant_.\n","  nn.init.constant(bn.bias, 0)\n","/content/CVPR21Chal-SLR/SL-GCN/model/decouple_gcn_attn.py:113: UserWarning: nn.init.constant is now deprecated in favor of nn.init.constant_.\n","  nn.init.constant(self.Linear_bias, 1e-6)\n","/content/CVPR21Chal-SLR/SL-GCN/model/decouple_gcn_attn.py:119: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  eye_array), requires_grad=False, device='cuda'), requires_grad=False)  # [c,25,25]\n","/content/CVPR21Chal-SLR/SL-GCN/model/decouple_gcn_attn.py:252: UserWarning: nn.init.normal is now deprecated in favor of nn.init.normal_.\n","  nn.init.normal(self.fc.weight, 0, math.sqrt(2. / num_class))\n"],"name":"stderr"},{"output_type":"stream","text":["Attention Enabled!\n","Attention Enabled!\n","Attention Enabled!\n","Attention Enabled!\n","Attention Enabled!\n","Attention Enabled!\n","Attention Enabled!\n","Attention Enabled!\n","Attention Enabled!\n","Attention Enabled!\n","[ Thu Aug  5 13:28:24 2021 ] Load weights from /content/drive/MyDrive/Colab Notebooks/CVPR21-Bh/train2/idk/sign_joint_final-30.pt.\n","28142\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 32 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n","  0%|          | 0/439 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["28142\n","[ Thu Aug  5 13:28:31 2021 ] Parameters:\n","{'Experiment_name': 'sign_joint_final', 'base_lr': 0.1, 'batch_size': 64, 'config': '/content/CVPR21Chal-SLR/SL-GCN/config/sign/train/train_joint.yaml', 'device': [0], 'eval_interval': 5, 'feeder': 'feeders.feeder.Feeder', 'groups': 8, 'ignore_weights': [], 'keep_rate': 0.9, 'log_interval': 100, 'model': 'model.decouple_gcn_attn.Model', 'model_args': {'num_class': 226, 'num_point': 27, 'num_person': 1, 'graph': 'graph.sign_27.Graph', 'groups': 16, 'block_size': 41, 'graph_args': {'labeling_mode': 'spatial'}}, 'model_saved_name': './save_models/sign_joint_final', 'nesterov': True, 'num_epoch': 250, 'num_worker': 32, 'only_train_epoch': 1, 'only_train_part': True, 'optimizer': 'SGD', 'phase': 'train', 'print_log': True, 'save_interval': 2, 'save_score': False, 'seed': 1, 'show_topk': [1, 5], 'start_epoch': 0, 'step': [150, 200], 'test_batch_size': 64, 'test_feeder_args': {'data_path': '/content/data/sign/27_2/train_data_joint.npy', 'label_path': '/content/data/sign/27_2/train_label.pkl', 'random_mirror': False, 'normalization': True}, 'train_feeder_args': {'data_path': '/content/data/sign/27_2/train_data_joint.npy', 'label_path': '/content/data/sign/27_2/train_label.pkl', 'debug': False, 'random_choose': True, 'window_size': 100, 'random_shift': True, 'normalization': True, 'random_mirror': True, 'random_mirror_p': 0.5, 'is_vector': False}, 'warm_up_epoch': 20, 'weight_decay': 0.0001, 'weights': '/content/drive/MyDrive/Colab Notebooks/CVPR21-Bh/train2/idk/sign_joint_final-30.pt', 'work_dir': './work_dir/sign_joint_final'}\n","\n","[ Thu Aug  5 13:28:31 2021 ] Training epoch: 1\n","only train part, do not require grad\n","l1.gcn1.DecoupleA-not require grad\n","l2.gcn1.DecoupleA-not require grad\n","l3.gcn1.DecoupleA-not require grad\n","l4.gcn1.DecoupleA-not require grad\n","l5.gcn1.DecoupleA-not require grad\n","l6.gcn1.DecoupleA-not require grad\n","l7.gcn1.DecoupleA-not require grad\n","l8.gcn1.DecoupleA-not require grad\n","l9.gcn1.DecoupleA-not require grad\n","l10.gcn1.DecoupleA-not require grad\n"],"name":"stdout"},{"output_type":"stream","text":[" 23%|██▎       | 100/439 [03:13<10:54,  1.93s/it]"],"name":"stderr"},{"output_type":"stream","text":["[ Thu Aug  5 13:31:44 2021 ] \tBatch(99/439) done. Loss: 0.0818  lr:0.005000\n"],"name":"stdout"},{"output_type":"stream","text":[" 46%|████▌     | 200/439 [06:26<07:41,  1.93s/it]"],"name":"stderr"},{"output_type":"stream","text":["[ Thu Aug  5 13:34:57 2021 ] \tBatch(199/439) done. Loss: 0.0563  lr:0.005000\n"],"name":"stdout"},{"output_type":"stream","text":[" 68%|██████▊   | 300/439 [09:38<04:27,  1.92s/it]"],"name":"stderr"},{"output_type":"stream","text":["[ Thu Aug  5 13:38:10 2021 ] \tBatch(299/439) done. Loss: 0.0554  lr:0.005000\n"],"name":"stdout"},{"output_type":"stream","text":[" 91%|█████████ | 400/439 [12:50<01:14,  1.92s/it]"],"name":"stderr"},{"output_type":"stream","text":["[ Thu Aug  5 13:41:22 2021 ] \tBatch(399/439) done. Loss: 0.0319  lr:0.005000\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 439/439 [14:06<00:00,  1.93s/it]\n","  0%|          | 0/440 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["[ Thu Aug  5 13:42:37 2021 ] Eval epoch: 1\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 440/440 [07:45<00:00,  1.06s/it]\n"],"name":"stderr"},{"output_type":"stream","text":["Eval Accuracy:  0.9941013431881174  model:  ./save_models/sign_joint_final\n","[ Thu Aug  5 13:50:24 2021 ] \tMean test loss of 440 batches: 0.02263963781297207.\n","[ Thu Aug  5 13:50:24 2021 ] \tTop1: 99.41%\n","[ Thu Aug  5 13:50:25 2021 ] \tTop5: 100.00%\n"],"name":"stdout"},{"output_type":"stream","text":["\r  0%|          | 0/439 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["[ Thu Aug  5 13:50:25 2021 ] Training epoch: 2\n","only train part, require grad\n","l1.gcn1.DecoupleA-require grad\n","l2.gcn1.DecoupleA-require grad\n","l3.gcn1.DecoupleA-require grad\n","l4.gcn1.DecoupleA-require grad\n","l5.gcn1.DecoupleA-require grad\n","l6.gcn1.DecoupleA-require grad\n","l7.gcn1.DecoupleA-require grad\n","l8.gcn1.DecoupleA-require grad\n","l9.gcn1.DecoupleA-require grad\n","l10.gcn1.DecoupleA-require grad\n"],"name":"stdout"},{"output_type":"stream","text":["/content/CVPR21Chal-SLR/SL-GCN/model/dropSke.py:29: UserWarning: undefined skeleton graph\n","  warnings.warn('undefined skeleton graph')\n","/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:652: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)\n","  return torch.max_pool1d(input, kernel_size, stride, padding, dilation, ceil_mode)\n"," 14%|█▍        | 61/439 [02:15<13:47,  2.19s/it]"],"name":"stderr"},{"output_type":"stream","text":["[ Thu Aug  5 13:52:40 2021 ] \tBatch(60/439) done. Loss: 0.0116  lr:0.010000\n"],"name":"stdout"},{"output_type":"stream","text":[" 37%|███▋      | 161/439 [05:54<10:09,  2.19s/it]"],"name":"stderr"},{"output_type":"stream","text":["[ Thu Aug  5 13:56:19 2021 ] \tBatch(160/439) done. Loss: 0.0302  lr:0.010000\n"],"name":"stdout"},{"output_type":"stream","text":[" 59%|█████▉    | 261/439 [09:33<06:31,  2.20s/it]"],"name":"stderr"},{"output_type":"stream","text":["[ Thu Aug  5 13:59:58 2021 ] \tBatch(260/439) done. Loss: 0.0100  lr:0.010000\n"],"name":"stdout"},{"output_type":"stream","text":[" 82%|████████▏ | 361/439 [13:13<02:51,  2.20s/it]"],"name":"stderr"},{"output_type":"stream","text":["[ Thu Aug  5 14:03:38 2021 ] \tBatch(360/439) done. Loss: 0.0181  lr:0.010000\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 439/439 [16:04<00:00,  2.20s/it]\n","  0%|          | 0/440 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["[ Thu Aug  5 14:06:30 2021 ] Eval epoch: 2\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 440/440 [07:43<00:00,  1.05s/it]\n"],"name":"stderr"},{"output_type":"stream","text":["Eval Accuracy:  0.9962333878189183  model:  ./save_models/sign_joint_final\n","[ Thu Aug  5 14:14:14 2021 ] \tMean test loss of 440 batches: 0.014988066628575325.\n","[ Thu Aug  5 14:14:15 2021 ] \tTop1: 99.62%\n","[ Thu Aug  5 14:14:15 2021 ] \tTop5: 100.00%\n"],"name":"stdout"},{"output_type":"stream","text":["\r  0%|          | 0/439 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["[ Thu Aug  5 14:14:15 2021 ] Training epoch: 3\n","only train part, require grad\n","l1.gcn1.DecoupleA-require grad\n","l2.gcn1.DecoupleA-require grad\n","l3.gcn1.DecoupleA-require grad\n","l4.gcn1.DecoupleA-require grad\n","l5.gcn1.DecoupleA-require grad\n","l6.gcn1.DecoupleA-require grad\n","l7.gcn1.DecoupleA-require grad\n","l8.gcn1.DecoupleA-require grad\n","l9.gcn1.DecoupleA-require grad\n","l10.gcn1.DecoupleA-require grad\n"],"name":"stdout"},{"output_type":"stream","text":["  5%|▌         | 22/439 [00:49<15:11,  2.19s/it]"],"name":"stderr"},{"output_type":"stream","text":["[ Thu Aug  5 14:15:05 2021 ] \tBatch(21/439) done. Loss: 0.0617  lr:0.015000\n"],"name":"stdout"},{"output_type":"stream","text":[" 28%|██▊       | 122/439 [04:27<11:31,  2.18s/it]"],"name":"stderr"},{"output_type":"stream","text":["[ Thu Aug  5 14:18:43 2021 ] \tBatch(121/439) done. Loss: 0.0282  lr:0.015000\n"],"name":"stdout"},{"output_type":"stream","text":[" 51%|█████     | 222/439 [08:05<07:52,  2.18s/it]"],"name":"stderr"},{"output_type":"stream","text":["[ Thu Aug  5 14:22:21 2021 ] \tBatch(221/439) done. Loss: 0.0070  lr:0.015000\n"],"name":"stdout"},{"output_type":"stream","text":[" 73%|███████▎  | 322/439 [11:43<04:15,  2.18s/it]"],"name":"stderr"},{"output_type":"stream","text":["[ Thu Aug  5 14:25:59 2021 ] \tBatch(321/439) done. Loss: 0.0107  lr:0.015000\n"],"name":"stdout"},{"output_type":"stream","text":[" 96%|█████████▌| 422/439 [15:21<00:37,  2.18s/it]"],"name":"stderr"},{"output_type":"stream","text":["[ Thu Aug  5 14:29:37 2021 ] \tBatch(421/439) done. Loss: 0.0058  lr:0.015000\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 439/439 [15:59<00:00,  2.19s/it]\n","  0%|          | 0/440 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["[ Thu Aug  5 14:30:15 2021 ] Eval epoch: 3\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 440/440 [07:44<00:00,  1.06s/it]\n"],"name":"stderr"},{"output_type":"stream","text":["Eval Accuracy:  0.9971572738255987  model:  ./save_models/sign_joint_final\n","[ Thu Aug  5 14:38:00 2021 ] \tMean test loss of 440 batches: 0.011403367854654789.\n","[ Thu Aug  5 14:38:01 2021 ] \tTop1: 99.72%\n","[ Thu Aug  5 14:38:01 2021 ] \tTop5: 100.00%\n"],"name":"stdout"},{"output_type":"stream","text":["\r  0%|          | 0/439 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["[ Thu Aug  5 14:38:01 2021 ] Training epoch: 4\n","only train part, require grad\n","l1.gcn1.DecoupleA-require grad\n","l2.gcn1.DecoupleA-require grad\n","l3.gcn1.DecoupleA-require grad\n","l4.gcn1.DecoupleA-require grad\n","l5.gcn1.DecoupleA-require grad\n","l6.gcn1.DecoupleA-require grad\n","l7.gcn1.DecoupleA-require grad\n","l8.gcn1.DecoupleA-require grad\n","l9.gcn1.DecoupleA-require grad\n","l10.gcn1.DecoupleA-require grad\n"],"name":"stdout"},{"output_type":"stream","text":[" 19%|█▉        | 83/439 [03:02<12:55,  2.18s/it]"],"name":"stderr"},{"output_type":"stream","text":["[ Thu Aug  5 14:41:04 2021 ] \tBatch(82/439) done. Loss: 0.0555  lr:0.020000\n"],"name":"stdout"},{"output_type":"stream","text":[" 42%|████▏     | 183/439 [06:41<09:19,  2.19s/it]"],"name":"stderr"},{"output_type":"stream","text":["[ Thu Aug  5 14:44:42 2021 ] \tBatch(182/439) done. Loss: 0.0292  lr:0.020000\n"],"name":"stdout"},{"output_type":"stream","text":[" 64%|██████▍   | 283/439 [10:19<05:40,  2.18s/it]"],"name":"stderr"},{"output_type":"stream","text":["[ Thu Aug  5 14:48:20 2021 ] \tBatch(282/439) done. Loss: 0.0826  lr:0.020000\n"],"name":"stdout"},{"output_type":"stream","text":[" 87%|████████▋ | 383/439 [13:57<02:02,  2.18s/it]"],"name":"stderr"},{"output_type":"stream","text":["[ Thu Aug  5 14:51:58 2021 ] \tBatch(382/439) done. Loss: 0.0255  lr:0.020000\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 439/439 [15:59<00:00,  2.19s/it]\n","  0%|          | 0/440 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["[ Thu Aug  5 14:54:01 2021 ] Eval epoch: 4\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 440/440 [07:44<00:00,  1.05s/it]\n"],"name":"stderr"},{"output_type":"stream","text":["Eval Accuracy:  0.9985786369127994  model:  ./save_models/sign_joint_final\n","[ Thu Aug  5 15:01:46 2021 ] \tMean test loss of 440 batches: 0.008795651607215405.\n","[ Thu Aug  5 15:01:46 2021 ] \tTop1: 99.86%\n","[ Thu Aug  5 15:01:47 2021 ] \tTop5: 100.00%\n"],"name":"stdout"},{"output_type":"stream","text":["\r  0%|          | 0/439 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["[ Thu Aug  5 15:01:47 2021 ] Training epoch: 5\n","only train part, require grad\n","l1.gcn1.DecoupleA-require grad\n","l2.gcn1.DecoupleA-require grad\n","l3.gcn1.DecoupleA-require grad\n","l4.gcn1.DecoupleA-require grad\n","l5.gcn1.DecoupleA-require grad\n","l6.gcn1.DecoupleA-require grad\n","l7.gcn1.DecoupleA-require grad\n","l8.gcn1.DecoupleA-require grad\n","l9.gcn1.DecoupleA-require grad\n","l10.gcn1.DecoupleA-require grad\n"],"name":"stdout"},{"output_type":"stream","text":[" 10%|█         | 44/439 [01:37<14:22,  2.18s/it]"],"name":"stderr"},{"output_type":"stream","text":["[ Thu Aug  5 15:03:25 2021 ] \tBatch(43/439) done. Loss: 0.0093  lr:0.025000\n"],"name":"stdout"},{"output_type":"stream","text":[" 33%|███▎      | 144/439 [05:15<10:44,  2.18s/it]"],"name":"stderr"},{"output_type":"stream","text":["[ Thu Aug  5 15:07:03 2021 ] \tBatch(143/439) done. Loss: 0.0245  lr:0.025000\n"],"name":"stdout"},{"output_type":"stream","text":[" 56%|█████▌    | 244/439 [08:53<07:05,  2.18s/it]"],"name":"stderr"},{"output_type":"stream","text":["[ Thu Aug  5 15:10:41 2021 ] \tBatch(243/439) done. Loss: 0.0616  lr:0.025000\n"],"name":"stdout"},{"output_type":"stream","text":[" 78%|███████▊  | 344/439 [12:31<03:27,  2.18s/it]"],"name":"stderr"},{"output_type":"stream","text":["[ Thu Aug  5 15:14:19 2021 ] \tBatch(343/439) done. Loss: 0.0079  lr:0.025000\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 439/439 [15:59<00:00,  2.19s/it]\n","  0%|          | 0/440 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["[ Thu Aug  5 15:17:47 2021 ] Eval epoch: 5\n"],"name":"stdout"},{"output_type":"stream","text":[" 45%|████▌     | 199/440 [03:30<04:13,  1.05s/it]"],"name":"stderr"},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-11-69f8114b0d65>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0minit_seed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprocessor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mProcessor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mprocessor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmagic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cd /content'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-7-1d77e7829680>\u001b[0m in \u001b[0;36mstart\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    342\u001b[0m                     \u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    343\u001b[0m                     \u001b[0msave_score\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_score\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 344\u001b[0;31m                     loader_name=['test'])\n\u001b[0m\u001b[1;32m    345\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    346\u001b[0m                 \u001b[0;31m# self.lr_scheduler.step(val_loss)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-7-1d77e7829680>\u001b[0m in \u001b[0;36meval\u001b[0;34m(self, epoch, save_score, loader_name, wrong_file, result_file)\u001b[0m\n\u001b[1;32m    283\u001b[0m                         \u001b[0ml1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    284\u001b[0m                     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 285\u001b[0;31m                     \u001b[0mscore_frag\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    286\u001b[0m                     \u001b[0mloss_value\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    287\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"markdown","metadata":{"id":"zPjAh6GBZIbE"},"source":["# To copy all the output files in /content/CVPR21Chal-SLR/SL-GCN/save_models"]},{"cell_type":"code","metadata":{"id":"RcmO5tC4l8Um"},"source":["import os, shutil\n","def copytree(src, dst, symlinks=False, ignore=None):\n","    for item in os.listdir(src):\n","        s = os.path.join(src, item)\n","        d = os.path.join(dst, item)\n","        if os.path.isdir(s):\n","            shutil.copytree(s, d, symlinks, ignore)\n","        else:\n","            shutil.copy2(s, d)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"EbVx4cA7mB6o"},"source":["copytree('/content/CVPR21Chal-SLR/SL-GCN/save_models','/content/drive/MyDrive/Colab Notebooks/CVPR21-Bh/train2/irdk')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Bv54___SZbuj"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"6yG9LjIiZbsH"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"_mSgvex9ZbpT"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"wCDh1Jf_ZcJJ"},"source":["# personal debugging"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":371},"id":"yMKfV6iLffRu","executionInfo":{"status":"error","timestamp":1627281887303,"user_tz":-360,"elapsed":474,"user":{"displayName":"Md.safirur Rashid, 170041020","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj4vsxiS6hdwcIxlWkCOlOKX6Yb9qvDnhTv0OE=s64","userId":"07083869211232678860"}},"outputId":"a40dcd18-4fda-4f02-9311-997d707d9c78"},"source":["parser = get_parser()\n","if p.config is not None:\n","    with open(p.config, 'r') as f:\n","        default_arg = yaml.load(f)\n","    key = vars(p).keys()\n","    for k in default_arg.keys():\n","        if k not in key:\n","            print('WRONG ARG: {}'.format(k))\n","            assert (k in key)\n","    parser.set_defaults(**default_arg)"],"execution_count":null,"outputs":[{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-19-872d6c31d352>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_parser\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0mdefault_arg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0myaml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvars\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-14-f5dd850b61c5>\u001b[0m in \u001b[0;36mget_parser\u001b[0;34m()\u001b[0m\n\u001b[1;32m     20\u001b[0m     parser.add_argument(\n\u001b[1;32m     21\u001b[0m         \u001b[0;34m'--save-score'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m         \u001b[0mtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstr2bool\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m         \u001b[0mdefault\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m         help='if ture, the classification score will be stored')\n","\u001b[0;31mNameError\u001b[0m: name 'str2bool' is not defined"]}]},{"cell_type":"code","metadata":{"id":"lCRaSluhffJA"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"15d7jyxaffBv"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"FxUs6Vxqfe-m"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"6WM2Lg6mrFoB"},"source":["p = Namespace(\n","    Experiment_name='', \n","    base_lr=0.01, \n","    batch_size=256, \n","    config='/content/CVPR21Chal-SLR/SL-GCN/config/sign/train/train_joint.yaml', \n","    device=0, \n","    eval_interval=5, \n","    feeder='feeder.feeder', \n","    groups=8, \n","    ignore_weights=[], \n","    keep_rate=0.9, \n","    log_interval=100, \n","    model=None, \n","    model_args={}, \n","    model_saved_name='', \n","    nesterov=False, \n","    num_epoch=80, \n","    num_worker=32, \n","    only_train_epoch=0, \n","    only_train_part=True, \n","    optimizer='SGD', \n","    phase='train', \n","    print_log=True, \n","    save_interval=2, \n","    save_score=False, \n","    seed=1, \n","    show_topk=[1, 5], \n","    start_epoch=0, \n","    step=[20, 40, 60], \n","    test_batch_size=256, \n","    test_feeder_args={}, \n","    train_feeder_args={}, \n","    warm_up_epoch=0, \n","    weight_decay=0.0005, \n","    weights=None, \n","    work_dir='./work_dir/temp')\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"q1VWvgZhOt_m"},"source":["Namespace(\n","    Experiment_name='sign_joint_final', \n","    base_lr=0.1, \n","    batch_size=64, \n","    config='/content/CVPR21Chal-SLR/SL-GCN/config/sign/train/train_joint.yaml', \n","    device=[0, 1, 2, 3], \n","    eval_interval=5, \n","    feeder='feeders.feeder.Feeder', \n","    groups=8, \n","    ignore_weights=[], \n","    keep_rate=0.9, \n","    log_interval=100, \n","    model='model.decouple_gcn_attn.Model', \n","    model_args={\n","        'num_class': 226, \n","        'num_point': 27, \n","        'num_person': 1, \n","        'graph': 'graph.sign_27.Graph', \n","        'groups': 16, \n","        'block_size': 41, \n","        'graph_args': {'labeling_mode': 'spatial'}\n","    }, \n","    model_saved_name='', \n","    nesterov=True, \n","    num_epoch=250, \n","    num_worker=32, \n","    only_train_epoch=1, \n","    only_train_part=True, \n","    optimizer='SGD', \n","    phase='train', \n","    print_log=True, \n","    save_interval=2, \n","    save_score=False, \n","    seed=1, \n","    show_topk=[1, 5], \n","    start_epoch=0, \n","    step=[150, 200], \n","    test_batch_size=64, \n","    test_feeder_args={\n","        'data_path': './data/sign/27_2/val_data_joint.npy', \n","        'label_path': './data/sign/27_2/val_gt.pkl', \n","        'random_mirror': False, \n","        'normalization': True\n","    }, \n","    train_feeder_args={\n","        'data_path': './data/sign/27_2/train_data_joint.npy', \n","        'label_path': './data/sign/27_2/train_label.pkl', \n","        'debug': False, \n","        'random_choose': True, \n","        'window_size': 100, \n","        'random_shift': True, \n","        'normalization': True, \n","        'random_mirror': True, \n","        'random_mirror_p': 0.5, \n","        'is_vector': False\n","    }, \n","    warm_up_epoch=20, \n","    weight_decay=0.0001, \n","    weights=None, \n","    work_dir='./work_dir/temp'\n",")\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"976xN7LflsHG"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"1Ge3F9MblsEH","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1627413338236,"user_tz":-360,"elapsed":8,"user":{"displayName":"Md.safirur Rashid, 170041020","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj4vsxiS6hdwcIxlWkCOlOKX6Yb9qvDnhTv0OE=s64","userId":"07083869211232678860"}},"outputId":"2a0e269b-be2b-4679-d473-b5166233c061"},"source":["!pwd"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/content/CVPR21Chal-SLR/SL-GCN\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pp1RNY2hls9q","executionInfo":{"status":"ok","timestamp":1627285719897,"user_tz":-360,"elapsed":393,"user":{"displayName":"Md.safirur Rashid, 170041020","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj4vsxiS6hdwcIxlWkCOlOKX6Yb9qvDnhTv0OE=s64","userId":"07083869211232678860"}},"outputId":"5254697f-994c-4822-b281-b0acaa0c3b51"},"source":["%cd /content/data/sign/27_2\n","!ls"],"execution_count":null,"outputs":[{"output_type":"stream","text":["[Errno 20] Not a directory: '/content/data/sign/27_2'\n","/content/drive/.shortcut-targets-by-id/1GhEIIcgxzMyFdfLihYOKuui9LUxm_E7T/copy_test_123\n","test_data_bone_motion.npy   test_label.pkl\t\t train_data_joint.npy\n","test_data_bone.npy\t    train_data_bone_motion.npy\t train_label.pkl\n","test_data_joint_motion.npy  train_data_bone.npy\n","test_data_joint.npy\t    train_data_joint_motion.npy\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"QCIi2P5vZzVl"},"source":[""],"execution_count":null,"outputs":[]}]}