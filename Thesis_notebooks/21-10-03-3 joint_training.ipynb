{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"21-10-03-3 training.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","metadata":{"id":"HdWZctCnRBKG"},"source":["# GPU Check"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"h3Wbn3yeIxD2","executionInfo":{"status":"ok","timestamp":1633254847077,"user_tz":-360,"elapsed":8,"user":{"displayName":"Eryth Brown","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjIz-NCzZfe1XlbcALsOgtnSkfWDHmAvoBVC2qS=s64","userId":"01967948615460729965"}},"outputId":"acc25f5e-8a88-4494-91cc-f521f45e2dfc"},"source":["!nvidia-smi -L"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["GPU 0: Tesla K80 (UUID: GPU-b7ea21f9-e8d9-e39d-ec75-122d7f8a56f8)\n"]}]},{"cell_type":"markdown","metadata":{"id":"LoE1A_vsRFVJ"},"source":["# Git Clone"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"sQ0GLBd0RuKZ","executionInfo":{"status":"ok","timestamp":1633254865096,"user_tz":-360,"elapsed":6952,"user":{"displayName":"Eryth Brown","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjIz-NCzZfe1XlbcALsOgtnSkfWDHmAvoBVC2qS=s64","userId":"01967948615460729965"}},"outputId":"6cf9c34a-f6cf-4762-fcd9-07d4eb4dc2c1"},"source":["!git clone https://github.com/jackyjsy/CVPR21Chal-SLR.git"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Cloning into 'CVPR21Chal-SLR'...\n","remote: Enumerating objects: 704, done.\u001b[K\n","remote: Counting objects: 100% (704/704), done.\u001b[K\n","remote: Compressing objects: 100% (555/555), done.\u001b[K\n","remote: Total 704 (delta 234), reused 605 (delta 137), pack-reused 0\u001b[K\n","Receiving objects: 100% (704/704), 53.19 MiB | 20.59 MiB/s, done.\n","Resolving deltas: 100% (234/234), done.\n"]}]},{"cell_type":"markdown","metadata":{"id":"2YOoaHAVRHZY"},"source":["# Drive Mount"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fzXNBkoCtSiv","executionInfo":{"status":"ok","timestamp":1633254904453,"user_tz":-360,"elapsed":39363,"user":{"displayName":"Eryth Brown","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjIz-NCzZfe1XlbcALsOgtnSkfWDHmAvoBVC2qS=s64","userId":"01967948615460729965"}},"outputId":"5e3b4344-9f97-4723-9f76-55dc57d3b0ce"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"markdown","metadata":{"id":"Gf8YICWbSXfv"},"source":["# Preprocessed data copying"]},{"cell_type":"code","metadata":{"id":"mGliByqwtmWF"},"source":["import shutil\n","import os"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"PkUYDm3LSnTX"},"source":["data_type = 'joint'\n","#data_type = 'joint_motion'\n","#data_type = 'bone'\n","#data_type = 'bone_motion'"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"gv9reaifC4hd"},"source":["# Train Data"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":36},"id":"X0p28MSftb9F","executionInfo":{"status":"ok","timestamp":1633254957533,"user_tz":-360,"elapsed":38524,"user":{"displayName":"Eryth Brown","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjIz-NCzZfe1XlbcALsOgtnSkfWDHmAvoBVC2qS=s64","userId":"01967948615460729965"}},"outputId":"d51b08f0-9913-4fe8-dfaa-633d0087ff39"},"source":["original = f'/content/drive/.shortcut-targets-by-id/1MwfX64WpeVyGAW0MhcasmbihkfgJwbtY/Darkpose_outputs/train_data_{data_type}.npy'\n","target = f'/content/data/sign/27_2/'\n","os.makedirs(os.path.dirname(target), exist_ok=True)\n","shutil.copy(original, target)\n","\n","original = f'/content/drive/.shortcut-targets-by-id/1MwfX64WpeVyGAW0MhcasmbihkfgJwbtY/Darkpose_outputs/train_label.pkl'\n","target = f'/content/data/sign/27_2/'\n","os.makedirs(os.path.dirname(target), exist_ok=True)\n","shutil.copy(original, target)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'/content/data/sign/27_2/train_label.pkl'"]},"metadata":{},"execution_count":6}]},{"cell_type":"markdown","metadata":{"id":"pkW104q6DYbf"},"source":["# Valid Data"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":36},"id":"m4rY1IvFKNCa","executionInfo":{"status":"ok","timestamp":1633254966211,"user_tz":-360,"elapsed":8687,"user":{"displayName":"Eryth Brown","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjIz-NCzZfe1XlbcALsOgtnSkfWDHmAvoBVC2qS=s64","userId":"01967948615460729965"}},"outputId":"84807a41-e908-4f5a-b9a3-c2de861ed2ab"},"source":["original = f'/content/drive/.shortcut-targets-by-id/1MwfX64WpeVyGAW0MhcasmbihkfgJwbtY/Darkpose_outputs/val_data_{data_type}.npy'\n","target = r'/content/data/sign/27_2/'\n","os.makedirs(os.path.dirname(target), exist_ok=True)\n","shutil.copy(original, target)\n","\n","original = r'/content/drive/.shortcut-targets-by-id/1MwfX64WpeVyGAW0MhcasmbihkfgJwbtY/Darkpose_outputs/val_label.pkl'\n","target = r'/content/data/sign/27_2/'\n","os.makedirs(os.path.dirname(target), exist_ok=True)\n","shutil.copy(original, target)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'/content/data/sign/27_2/val_label.pkl'"]},"metadata":{},"execution_count":7}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9Vv1_VHelqQv","executionInfo":{"elapsed":752,"status":"ok","timestamp":1633177723696,"user":{"displayName":"Md.safirur Rashid, 170041020","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj4vsxiS6hdwcIxlWkCOlOKX6Yb9qvDnhTv0OE=s64","userId":"07083869211232678860"},"user_tz":-360},"outputId":"08e2aba4-040e-4972-e582-6ae5c145cc43"},"source":["Namespace(\n","    Experiment_name='joint_27_2_finetune', \n","    base_lr=0.01, \n","    batch_size=64, \n","    config='config/sign/finetune/train_joint.yaml', \n","    device=[0, 1], \n","    eval_interval=5, \n","    feeder='feeders.feeder.Feeder', \n","    groups=8, \n","    ignore_weights=[], \n","    keep_rate=0.9, \n","    log_interval=100, \n","    model='model.decouple_gcn_attn.Model', \n","    model_args={\n","        'num_class': 226, \n","        'num_point': 27, \n","        'num_person': 1, \n","        'graph': 'graph.sign_27.Graph', \n","        'groups': 16, \n","        'block_size': 41, \n","        'graph_args': {'labeling_mode': 'spatial'}\n","    }, \n","    model_saved_name='', \n","    nesterov=True, \n","    num_epoch=100, \n","    num_worker=32, \n","    only_train_epoch=1, \n","    only_train_part=True, \n","    optimizer='SGD', \n","    phase='train', \n","    print_log=True, \n","    save_interval=2, \n","    save_score=False, \n","    seed=1, \n","    show_topk=[1, 5], \n","    start_epoch=0, \n","    step=[50], \n","    test_batch_size=64, \n","    test_feeder_args={\n","        'data_path': './data/sign/27_2/test_data_joint.npy', \n","        'label_path': './data/sign/27_2/test_labels_pseudo.pkl', \n","        'random_mirror': False, \n","        'normalization': True\n","        }, \n","    train_feeder_args={\n","        'data_path': './data/sign/27_2/train_val_data_joint.npy', \n","        'label_path': './data/sign/27_2/train_val_labels.pkl', \n","        'debug': False, \n","        'random_choose': True, \n","        'window_size': 100, \n","        'random_shift': True, \n","        'normalization': True, \n","        'random_mirror': True, \n","        'random_mirror_p': 0.5, \n","        'is_vector': False\n","        }, \n","    warm_up_epoch=0, \n","    weight_decay=0.0001, \n","    weights='final_models/27_2/joint_epoch_226_9468.pt', \n","    work_dir='./work_dir/temp'\n",")"],"execution_count":null,"outputs":[{"data":{"text/plain":["Namespace(Experiment_name='joint_27_2_finetune', base_lr=0.01, batch_size=64, config='config/sign/finetune/train_joint.yaml', device=[0, 1], eval_interval=5, feeder='feeders.feeder.Feeder', groups=8, ignore_weights=[], keep_rate=0.9, log_interval=100, model='model.decouple_gcn_attn.Model', model_args={'num_class': 226, 'num_point': 27, 'num_person': 1, 'graph': 'graph.sign_27.Graph', 'groups': 16, 'block_size': 41, 'graph_args': {'labeling_mode': 'spatial'}}, model_saved_name='', nesterov=True, num_epoch=100, num_worker=32, only_train_epoch=1, only_train_part=True, optimizer='SGD', phase='train', print_log=True, save_interval=2, save_score=False, seed=1, show_topk=[1, 5], start_epoch=0, step=[50], test_batch_size=64, test_feeder_args={'data_path': './data/sign/27_2/test_data_joint.npy', 'label_path': './data/sign/27_2/test_labels_pseudo.pkl', 'random_mirror': False, 'normalization': True}, train_feeder_args={'data_path': './data/sign/27_2/train_val_data_joint.npy', 'label_path': './data/sign/27_2/train_val_labels.pkl', 'debug': False, 'random_choose': True, 'window_size': 100, 'random_shift': True, 'normalization': True, 'random_mirror': True, 'random_mirror_p': 0.5, 'is_vector': False}, warm_up_epoch=0, weight_decay=0.0001, weights='final_models/27_2/joint_epoch_226_9468.pt', work_dir='./work_dir/temp')"]},"execution_count":10,"metadata":{},"output_type":"execute_result"}]},{"cell_type":"code","metadata":{"id":"V-etF4pqki_C"},"source":["%cd /content/CVPR21Chal-SLR/SL-GCN\n","!python main.py --config config/sign/finetune/train_joint.yaml"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"LN0FuKDIUHwa"},"source":["# Imports"]},{"cell_type":"code","metadata":{"id":"h2TSGeynmzMd"},"source":["from __future__ import print_function\n","import argparse\n","from argparse import ArgumentParser,Namespace\n","import os\n","import time\n","import numpy as np\n","import yaml\n","import pickle\n","from collections import OrderedDict\n","# torch\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from torch.autograd import Variable\n","from tqdm import tqdm\n","import shutil\n","from torch.optim.lr_scheduler import ReduceLROnPlateau, MultiStepLR\n","import random\n","import inspect\n","import torch.backends.cudnn as cudnn\n","import torch.nn.functional as F"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"PHdDisu1ULYu"},"source":["# Seed fixing"]},{"cell_type":"code","metadata":{"id":"YJaTr2dCRypd"},"source":["def init_seed(_):\n","    torch.cuda.manual_seed_all(1)\n","    torch.manual_seed(1)\n","    np.random.seed(1)\n","    random.seed(1)\n","    # torch.backends.cudnn.enabled = False\n","    torch.backends.cudnn.deterministic = True\n","    torch.backends.cudnn.benchmark = False"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"lajR7EowV5J2"},"source":["# To import the data or model in load_data and load_model"]},{"cell_type":"code","metadata":{"id":"gdmXjH2zfaZf"},"source":["def import_class(name):\n","    components = name.split('.')\n","    mod = __import__(components[0])  # import return model\n","    for comp in components[1:]:\n","        mod = getattr(mod, comp)\n","    return mod"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"-UEE1YcuVWZF"},"source":["# Main Class\n","\n","Ami only line 247 nije nije disi\n","\n","to create the saving directory"]},{"cell_type":"code","metadata":{"id":"t-1dCIbpeJQK"},"source":["class Processor():\n","    \"\"\" \n","        Processor for Skeleton-based Action Recgnition\n","    \"\"\"\n","\n","    def __init__(self, arg):\n","\n","        arg.model_saved_name = f\"/content/drive/MyDrive/Colab Notebooks/CVPR21-Dh/finetune/{data_type}/save_models/\"+ arg.Experiment_name\n","        arg.work_dir = f\"/content/drive/MyDrive/Colab Notebooks/CVPR21-Dh/finetune/{data_type}/work_dir/\" + arg.Experiment_name\n","        arg.save_dir = f'/content/drive/MyDrive/Colab Notebooks/CVPR21-Dh/finetune/{data_type}/save_models/'\n","        self.arg = arg\n","        self.save_arg()\n","        if arg.phase == 'train':\n","            if not arg.train_feeder_args['debug']:\n","                if os.path.isdir(arg.model_saved_name):\n","                    print('log_dir: ', arg.model_saved_name, 'already exist')\n","                    answer = input('delete it? y/n:')\n","                    if answer == 'y':\n","                        shutil.rmtree(arg.model_saved_name)\n","                        print('Dir removed: ', arg.model_saved_name)\n","                        input(\n","                            'Refresh the website of tensorboard by pressing any keys')\n","                    else:\n","                        print('Dir not removed: ', arg.model_saved_name)\n","\n","        self.global_step = 0\n","        self.load_model()\n","        self.load_optimizer()\n","        self.load_data()\n","        self.lr = self.arg.base_lr\n","        self.best_acc = 0\n","\n","    def load_data(self):\n","        Feeder = import_class(self.arg.feeder)\n","        self.data_loader = dict()\n","        if self.arg.phase == 'train':\n","            self.data_loader['train'] = torch.utils.data.DataLoader(\n","                dataset=Feeder(**self.arg.train_feeder_args),\n","                batch_size=self.arg.batch_size,\n","                shuffle=True,\n","                num_workers=self.arg.num_worker,\n","                drop_last=True,\n","                worker_init_fn=init_seed)\n","        self.data_loader['test'] = torch.utils.data.DataLoader(\n","            dataset=Feeder(**self.arg.test_feeder_args),\n","            batch_size=self.arg.test_batch_size,\n","            shuffle=False,\n","            num_workers=self.arg.num_worker,\n","            drop_last=False,\n","            worker_init_fn=init_seed)\n","\n","    def load_model(self):\n","        output_device = self.arg.device[0] if type(\n","            self.arg.device) is list else self.arg.device\n","        self.output_device = output_device\n","        Model = import_class(self.arg.model)\n","        shutil.copy2(inspect.getfile(Model), self.arg.work_dir)\n","        self.model = Model(**self.arg.model_args).cuda(output_device)\n","        # print(self.model)\n","        self.loss = nn.CrossEntropyLoss().cuda(output_device)\n","        # self.loss = LabelSmoothingCrossEntropy().cuda(output_device)\n","\n","        if self.arg.weights:\n","            self.print_log('Load weights from {}.'.format(self.arg.weights))\n","            if '.pkl' in self.arg.weights:\n","                with open(self.arg.weights, 'r') as f:\n","                    weights = pickle.load(f)\n","            else:\n","                weights = torch.load(self.arg.weights)\n","\n","            weights = OrderedDict(\n","                [[k.split('module.')[-1],\n","                  v.cuda(output_device)] for k, v in weights.items()])\n","\n","            for w in self.arg.ignore_weights:\n","                if weights.pop(w, None) is not None:\n","                    self.print_log('Sucessfully Remove Weights: {}.'.format(w))\n","                else:\n","                    self.print_log('Can Not Remove Weights: {}.'.format(w))\n","\n","            try:\n","                self.model.load_state_dict(weights)\n","            except:\n","                state = self.model.state_dict()\n","                diff = list(set(state.keys()).difference(set(weights.keys())))\n","                print('Can not find these weights:')\n","                for d in diff:\n","                    print('  ' + d)\n","                state.update(weights)\n","                self.model.load_state_dict(state)\n","\n","        if type(self.arg.device) is list:\n","            if len(self.arg.device) > 1:\n","                self.model = nn.DataParallel(\n","                    self.model,\n","                    device_ids=self.arg.device,\n","                    output_device=output_device)\n","\n","    def load_optimizer(self):\n","        if self.arg.optimizer == 'SGD':\n","\n","            params_dict = dict(self.model.named_parameters())\n","            params = []\n","\n","            for key, value in params_dict.items():\n","                decay_mult = 0.0 if 'bias' in key else 1.0\n","\n","                lr_mult = 1.0\n","                weight_decay = 1e-4\n","\n","                params += [{'params': value, 'lr': self.arg.base_lr, 'lr_mult': lr_mult,\n","                            'decay_mult': decay_mult, 'weight_decay': weight_decay}]\n","\n","            self.optimizer = optim.SGD(\n","                params,\n","                momentum=0.9,\n","                nesterov=self.arg.nesterov)\n","        elif self.arg.optimizer == 'Adam':\n","            self.optimizer = optim.Adam(\n","                self.model.parameters(),\n","                lr=self.arg.base_lr,\n","                weight_decay=self.arg.weight_decay)\n","        else:\n","            raise ValueError()\n","\n","        self.lr_scheduler = ReduceLROnPlateau(self.optimizer, mode='min', factor=0.1,\n","                                              patience=10, verbose=True,\n","                                              threshold=1e-4, threshold_mode='rel',\n","                                              cooldown=0)\n","\n","    def save_arg(self):\n","        # save arg\n","        arg_dict = vars(self.arg)\n","\n","        if not os.path.exists(self.arg.work_dir):\n","            os.makedirs(self.arg.work_dir)\n","            os.makedirs(self.arg.work_dir + '/eval_results')\n","\n","        with open('{}/config.yaml'.format(self.arg.work_dir), 'w') as f:\n","            yaml.dump(arg_dict, f)\n","\n","    def adjust_learning_rate(self, epoch):\n","        if self.arg.optimizer == 'SGD' or self.arg.optimizer == 'Adam':\n","            if epoch < self.arg.warm_up_epoch:\n","                lr = self.arg.base_lr * (epoch + 1) / self.arg.warm_up_epoch\n","            else:\n","                lr = self.arg.base_lr * (\n","                    0.1 ** np.sum(epoch >= np.array(self.arg.step)))\n","            for param_group in self.optimizer.param_groups:\n","                param_group['lr'] = lr\n","            return lr\n","        else:\n","            raise ValueError()\n","\n","    def print_time(self):\n","        localtime = time.asctime(time.localtime(time.time()))\n","        self.print_log(\"Local current time :  \" + localtime)\n","\n","    def print_log(self, str, print_time=True):\n","        if print_time:\n","            localtime = time.asctime(time.localtime(time.time()))\n","            str = \"[ \" + localtime + ' ] ' + str\n","        print(str)\n","        if self.arg.print_log:\n","            with open('{}/log.txt'.format(self.arg.work_dir), 'a') as f:\n","                print(str, file=f)\n","\n","    def record_time(self):\n","        self.cur_time = time.time()\n","        return self.cur_time\n","\n","    def split_time(self):\n","        split_time = time.time() - self.cur_time\n","        self.record_time()\n","        return split_time\n","\n","    def train(self, epoch, save_model=False):\n","        self.model.train()\n","        self.print_log('Training epoch: {}'.format(epoch + 1))\n","        loader = self.data_loader['train']\n","        self.adjust_learning_rate(epoch)\n","        loss_value = []\n","        self.record_time()\n","        timer = dict(dataloader=0.001, model=0.001, statistics=0.001)\n","        process = tqdm(loader)\n","        if epoch >= self.arg.only_train_epoch:\n","            print('only train part, require grad')\n","            for key, value in self.model.named_parameters():\n","                if 'DecoupleA' in key:\n","                    value.requires_grad = True\n","                    print(key + '-require grad')\n","        else:\n","            print('only train part, do not require grad')\n","            for key, value in self.model.named_parameters():\n","                if 'DecoupleA' in key:\n","                    value.requires_grad = False\n","                    print(key + '-not require grad')\n","        for batch_idx, (data, label, index) in enumerate(process):\n","            self.global_step += 1\n","            # get data\n","            data = Variable(data.float().cuda(\n","                self.output_device), requires_grad=False)\n","            label = Variable(label.long().cuda(\n","                self.output_device), requires_grad=False)\n","            timer['dataloader'] += self.split_time()\n","\n","            # forward\n","            if epoch < 100:\n","                keep_prob = -(1 - self.arg.keep_rate) / 100 * epoch + 1.0\n","            else:\n","                keep_prob = self.arg.keep_rate\n","            output = self.model(data, keep_prob)\n","\n","            if isinstance(output, tuple):\n","                output, l1 = output\n","                l1 = l1.mean()\n","            else:\n","                l1 = 0\n","            loss = self.loss(output, label) + l1\n","\n","            self.optimizer.zero_grad()\n","            loss.backward()\n","            self.optimizer.step()\n","            loss_value.append(loss.data)\n","            timer['model'] += self.split_time()\n","\n","            value, predict_label = torch.max(output.data, 1)\n","            acc = torch.mean((predict_label == label.data).float())\n","\n","            self.lr = self.optimizer.param_groups[0]['lr']\n","\n","            if self.global_step % self.arg.log_interval == 0:\n","                self.print_log(\n","                    '\\tBatch({}/{}) done. Loss: {:.4f}  lr:{:.6f}'.format(\n","                        batch_idx, len(loader), loss.data, self.lr))\n","            timer['statistics'] += self.split_time()\n","\n","        # statistics of time consumption and loss\n","        proportion = {\n","            k: '{:02d}%'.format(int(round(v * 100 / sum(timer.values()))))\n","            for k, v in timer.items()\n","        }\n","\n","        state_dict = self.model.state_dict()\n","        weights = OrderedDict([[k.split('module.')[-1],\n","                                v.cpu()] for k, v in state_dict.items()])\n","\n","        os.makedirs(os.path.dirname(arg.save_dir), exist_ok=True)\n","        torch.save(weights, self.arg.model_saved_name +\n","                   '-' + str(epoch) + '.pt')\n","\n","    def eval(self, epoch, save_score=False, loader_name=['test'], wrong_file=None, result_file=None):\n","        if wrong_file is not None:\n","            f_w = open(wrong_file, 'w')\n","        if result_file is not None:\n","            f_r = open(result_file, 'w')\n","        self.model.eval()\n","        with torch.no_grad():\n","            self.print_log('Eval epoch: {}'.format(epoch + 1))\n","            for ln in loader_name:\n","                loss_value = []\n","                score_frag = []\n","                right_num_total = 0\n","                total_num = 0\n","                loss_total = 0\n","                step = 0\n","                process = tqdm(self.data_loader[ln])\n","\n","                for batch_idx, (data, label, index) in enumerate(process):\n","                    data = Variable(\n","                        data.float().cuda(self.output_device),\n","                        requires_grad=False)\n","                    label = Variable(\n","                        label.long().cuda(self.output_device),\n","                        requires_grad=False)\n","\n","                    with torch.no_grad():\n","                        output = self.model(data)\n","\n","                    if isinstance(output, tuple):\n","                        output, l1 = output\n","                        l1 = l1.mean()\n","                    else:\n","                        l1 = 0\n","                    loss = self.loss(output, label)\n","                    score_frag.append(output.data.cpu().numpy())\n","                    loss_value.append(loss.data.cpu().numpy())\n","\n","                    _, predict_label = torch.max(output.data, 1)\n","                    step += 1\n","\n","                    if wrong_file is not None or result_file is not None:\n","                        predict = list(predict_label.cpu().numpy())\n","                        true = list(label.data.cpu().numpy())\n","                        for i, x in enumerate(predict):\n","                            if result_file is not None:\n","                                f_r.write(str(x) + ',' + str(true[i]) + '\\n')\n","                            if x != true[i] and wrong_file is not None:\n","                                f_w.write(str(index[i]) + ',' +\n","                                        str(x) + ',' + str(true[i]) + '\\n')\n","                score = np.concatenate(score_frag)\n","\n","                if 'UCLA' in arg.Experiment_name:\n","                    self.data_loader[ln].dataset.sample_name = np.arange(\n","                        len(score))\n","\n","                accuracy = self.data_loader[ln].dataset.top_k(score, 1)\n","                if accuracy > self.best_acc:\n","                    self.best_acc = accuracy\n","                    score_dict = dict(\n","                        zip(self.data_loader[ln].dataset.sample_name, score))\n","\n","                    with open(arg.work_dir  + '/eval_results/best_acc' + '.pkl'.format(epoch, accuracy), 'wb') as f:\n","                        pickle.dump(score_dict, f)\n","\n","                print('Eval Accuracy: ', accuracy,\n","                    ' model: ', self.arg.model_saved_name)\n","\n","                score_dict = dict(\n","                    zip(self.data_loader[ln].dataset.sample_name, score))\n","                self.print_log('\\tMean {} loss of {} batches: {}.'.format(\n","                    ln, len(self.data_loader[ln]), np.mean(loss_value)))\n","                for k in self.arg.show_topk:\n","                    self.print_log('\\tTop{}: {:.2f}%'.format(\n","                        k, 100 * self.data_loader[ln].dataset.top_k(score, k)))\n","\n","                with open(arg.work_dir  + '/eval_results/epoch_' + str(epoch) + '_' + str(accuracy) + '.pkl'.format(epoch, accuracy), 'wb') as f:\n","                    pickle.dump(score_dict, f)\n","        return np.mean(loss_value)\n","    def start(self):\n","        if self.arg.phase == 'train':\n","            self.print_log('Parameters:\\n{}\\n'.format(str(vars(self.arg))))\n","            self.global_step = self.arg.start_epoch * \\\n","                len(self.data_loader['train']) / self.arg.batch_size\n","            for epoch in range(self.arg.start_epoch, self.arg.num_epoch):\n","                save_model = ((epoch + 1) % self.arg.save_interval == 0) or (\n","                    epoch + 1 == self.arg.num_epoch)\n","\n","                self.train(epoch, save_model=save_model)\n","\n","                val_loss = self.eval(\n","                    epoch,\n","                    save_score=self.arg.save_score,\n","                    loader_name=['test'])\n","\n","                # self.lr_scheduler.step(val_loss)\n","\n","            print('best accuracy: ', self.best_acc,\n","                  ' model_name: ', self.arg.model_saved_name)\n","\n","        elif self.arg.phase == 'test':\n","            if not self.arg.test_feeder_args['debug']:\n","                wf = self.arg.model_saved_name + '_wrong.txt'\n","                rf = self.arg.model_saved_name + '_right.txt'\n","            else:\n","                wf = rf = None\n","            if self.arg.weights is None:\n","                raise ValueError('Please appoint --weights.')\n","            self.arg.print_log = False\n","            self.print_log('Model:   {}.'.format(self.arg.model))\n","            self.print_log('Weights: {}.'.format(self.arg.weights))\n","            self.eval(epoch=self.arg.start_epoch, save_score=self.arg.save_score,\n","                      loader_name=['test'], wrong_file=wf, result_file=rf)\n","            self.print_log('Done.\\n')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"hS0r2JIOWpek"},"source":["# Passed Arguments"]},{"cell_type":"code","metadata":{"id":"TXiPE49QlCeQ"},"source":["last_pt_file = 32"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"066bp_UieZYs"},"source":["arg = Namespace(\n","    Experiment_name=f'{data_type}_27_2_finetune', \n","    base_lr=0.01, \n","    batch_size=64, \n","    config=f'/content/CVPR21Chal-SLR/SL-GCN/config/sign/finetune/train_{data_type}.yaml', \n","    device=[0], \n","    eval_interval=5, \n","    feeder='feeders.feeder.Feeder', \n","    groups=8, \n","    ignore_weights=[], \n","    keep_rate=0.9, \n","    log_interval=100, \n","    model='model.decouple_gcn_attn.Model', \n","    model_args={\n","        'num_class': 226, \n","        'num_point': 27, \n","        'num_person': 1, \n","        'graph': 'graph.sign_27.Graph', \n","        'groups': 16, \n","        'block_size': 41, \n","        'graph_args': {'labeling_mode': 'spatial'}\n","    }, \n","    model_saved_name='', \n","    nesterov=True, \n","    num_epoch=100, \n","    num_worker=32, \n","    only_train_epoch=1, \n","    only_train_part=True, \n","    optimizer='SGD', \n","    phase='train', \n","    print_log=True, \n","    save_interval=2, \n","    save_score=False, \n","    seed=1, \n","    show_topk=[1, 5], \n","    start_epoch=last_pt_file + 1, ###############################################################\n","    step=[50], \n","    test_batch_size=64, \n","    test_feeder_args={\n","        'data_path': f'/content/data/sign/27_2/val_data_{data_type}.npy', \n","        'label_path': f'/content/data/sign/27_2/val_label.pkl', \n","        'random_mirror': False, \n","        'normalization': True\n","    }, \n","    train_feeder_args={\n","        'data_path': f'/content/data/sign/27_2/train_data_{data_type}.npy', \n","        'label_path': f'/content/data/sign/27_2/train_label.pkl', \n","        'debug': False, \n","        'random_choose': True, \n","        'window_size': 100, \n","        'random_shift': True, \n","        'normalization': True, \n","        'random_mirror': True, \n","        'random_mirror_p': 0.5, \n","        'is_vector': False\n","    }, \n","    warm_up_epoch=0, \n","    weight_decay=0.0001, \n","    ##############################################\n","    # To continue use specific path else None    #\n","    ##############################################\n","    weights=f'/content/drive/MyDrive/Colab Notebooks/CVPR21-Dh/finetune/{data_type}/save_models/{data_type}_27_2_finetune-{last_pt_file}.pt', \n","    #weights=f'/content/drive/.shortcut-targets-by-id/17LsLcfh-7JBwoayKtZKY7bBloa0FL_iU/27_2/joint_epoch_226_9468.pt',\n","    work_dir='./work_dir/temp'\n",")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"6u0wbvo6X5h6"},"source":["# Main cell to run\n","Personal suggestion:\n","\n","Ei cell ta ekta copy koire run koris as amader onek baar e train korte hobe and re run korle prev output erase hoye jay.\n","\n","Also koy step por por latest .pt file ta nije nije download koire nis just in case."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"83NBgJX-WDwt","outputId":"72323766-f167-4d6f-d18f-c393df36082a"},"source":["%cd /content/CVPR21Chal-SLR/SL-GCN\n","init_seed(0)\n","processor = Processor(arg)\n","processor.start()\n","%cd /content"],"execution_count":null,"outputs":[{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["/content/CVPR21Chal-SLR/SL-GCN\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/content/CVPR21Chal-SLR/SL-GCN/model/decouple_gcn_attn.py:29: UserWarning: nn.init.kaiming_normal is now deprecated in favor of nn.init.kaiming_normal_.\n","  nn.init.kaiming_normal(conv.weight, mode='fan_out')\n","/content/CVPR21Chal-SLR/SL-GCN/model/decouple_gcn_attn.py:30: UserWarning: nn.init.constant is now deprecated in favor of nn.init.constant_.\n","  nn.init.constant(conv.bias, 0)\n","/content/CVPR21Chal-SLR/SL-GCN/model/decouple_gcn_attn.py:34: UserWarning: nn.init.constant is now deprecated in favor of nn.init.constant_.\n","  nn.init.constant(bn.weight, scale)\n","/content/CVPR21Chal-SLR/SL-GCN/model/decouple_gcn_attn.py:35: UserWarning: nn.init.constant is now deprecated in favor of nn.init.constant_.\n","  nn.init.constant(bn.bias, 0)\n","/content/CVPR21Chal-SLR/SL-GCN/model/decouple_gcn_attn.py:113: UserWarning: nn.init.constant is now deprecated in favor of nn.init.constant_.\n","  nn.init.constant(self.Linear_bias, 1e-6)\n","/content/CVPR21Chal-SLR/SL-GCN/model/decouple_gcn_attn.py:119: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  eye_array), requires_grad=False, device='cuda'), requires_grad=False)  # [c,25,25]\n","/content/CVPR21Chal-SLR/SL-GCN/model/decouple_gcn_attn.py:252: UserWarning: nn.init.normal is now deprecated in favor of nn.init.normal_.\n","  nn.init.normal(self.fc.weight, 0, math.sqrt(2. / num_class))\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Attention Enabled!\n","Attention Enabled!\n","Attention Enabled!\n","Attention Enabled!\n","Attention Enabled!\n","Attention Enabled!\n","Attention Enabled!\n","Attention Enabled!\n","Attention Enabled!\n","Attention Enabled!\n","[ Sun Oct  3 09:57:00 2021 ] Load weights from /content/drive/MyDrive/Colab Notebooks/CVPR21-Dh/finetune/joint/save_models/joint_27_2_finetune-32.pt.\n","28142\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 32 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["4418\n","[ Sun Oct  3 09:57:07 2021 ] Parameters:\n","{'Experiment_name': 'joint_27_2_finetune', 'base_lr': 0.01, 'batch_size': 64, 'config': '/content/CVPR21Chal-SLR/SL-GCN/config/sign/finetune/train_joint.yaml', 'device': [0], 'eval_interval': 5, 'feeder': 'feeders.feeder.Feeder', 'groups': 8, 'ignore_weights': [], 'keep_rate': 0.9, 'log_interval': 100, 'model': 'model.decouple_gcn_attn.Model', 'model_args': {'num_class': 226, 'num_point': 27, 'num_person': 1, 'graph': 'graph.sign_27.Graph', 'groups': 16, 'block_size': 41, 'graph_args': {'labeling_mode': 'spatial'}}, 'model_saved_name': '/content/drive/MyDrive/Colab Notebooks/CVPR21-Dh/finetune/joint/save_models/joint_27_2_finetune', 'nesterov': True, 'num_epoch': 100, 'num_worker': 32, 'only_train_epoch': 1, 'only_train_part': True, 'optimizer': 'SGD', 'phase': 'train', 'print_log': True, 'save_interval': 2, 'save_score': False, 'seed': 1, 'show_topk': [1, 5], 'start_epoch': 33, 'step': [50], 'test_batch_size': 64, 'test_feeder_args': {'data_path': '/content/data/sign/27_2/val_data_joint.npy', 'label_path': '/content/data/sign/27_2/val_label.pkl', 'random_mirror': False, 'normalization': True}, 'train_feeder_args': {'data_path': '/content/data/sign/27_2/train_data_joint.npy', 'label_path': '/content/data/sign/27_2/train_label.pkl', 'debug': False, 'random_choose': True, 'window_size': 100, 'random_shift': True, 'normalization': True, 'random_mirror': True, 'random_mirror_p': 0.5, 'is_vector': False}, 'warm_up_epoch': 0, 'weight_decay': 0.0001, 'weights': '/content/drive/MyDrive/Colab Notebooks/CVPR21-Dh/finetune/joint/save_models/joint_27_2_finetune-32.pt', 'work_dir': '/content/drive/MyDrive/Colab Notebooks/CVPR21-Dh/finetune/joint/work_dir/joint_27_2_finetune', 'save_dir': '/content/drive/MyDrive/Colab Notebooks/CVPR21-Dh/finetune/joint/save_models/'}\n","\n","[ Sun Oct  3 09:57:07 2021 ] Training epoch: 34\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["\r  0%|          | 0/439 [00:00<?, ?it/s]"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["only train part, require grad\n","l1.gcn1.DecoupleA-require grad\n","l2.gcn1.DecoupleA-require grad\n","l3.gcn1.DecoupleA-require grad\n","l4.gcn1.DecoupleA-require grad\n","l5.gcn1.DecoupleA-require grad\n","l6.gcn1.DecoupleA-require grad\n","l7.gcn1.DecoupleA-require grad\n","l8.gcn1.DecoupleA-require grad\n","l9.gcn1.DecoupleA-require grad\n","l10.gcn1.DecoupleA-require grad\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/content/CVPR21Chal-SLR/SL-GCN/model/dropSke.py:29: UserWarning: undefined skeleton graph\n","  warnings.warn('undefined skeleton graph')\n","/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:652: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)\n","  return torch.max_pool1d(input, kernel_size, stride, padding, dilation, ceil_mode)\n","100%|██████████| 439/439 [15:38<00:00,  2.14s/it]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["[ Sun Oct  3 10:12:46 2021 ] Eval epoch: 34\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["100%|██████████| 70/70 [01:12<00:00,  1.04s/it]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Eval Accuracy:  0.9173834314169307  model:  /content/drive/MyDrive/Colab Notebooks/CVPR21-Dh/finetune/joint/save_models/joint_27_2_finetune\n","[ Sun Oct  3 10:13:59 2021 ] \tMean test loss of 70 batches: 0.37571704387664795.\n","[ Sun Oct  3 10:14:00 2021 ] \tTop1: 91.74%\n","[ Sun Oct  3 10:14:00 2021 ] \tTop5: 98.87%\n","[ Sun Oct  3 10:14:00 2021 ] Training epoch: 35\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["\r  0%|          | 0/439 [00:00<?, ?it/s]"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["only train part, require grad\n","l1.gcn1.DecoupleA-require grad\n","l2.gcn1.DecoupleA-require grad\n","l3.gcn1.DecoupleA-require grad\n","l4.gcn1.DecoupleA-require grad\n","l5.gcn1.DecoupleA-require grad\n","l6.gcn1.DecoupleA-require grad\n","l7.gcn1.DecoupleA-require grad\n","l8.gcn1.DecoupleA-require grad\n","l9.gcn1.DecoupleA-require grad\n","l10.gcn1.DecoupleA-require grad\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["100%|██████████| 439/439 [15:39<00:00,  2.14s/it]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["[ Sun Oct  3 10:29:40 2021 ] Eval epoch: 35\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["100%|██████████| 70/70 [01:12<00:00,  1.04s/it]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Eval Accuracy:  0.9182888184698959  model:  /content/drive/MyDrive/Colab Notebooks/CVPR21-Dh/finetune/joint/save_models/joint_27_2_finetune\n","[ Sun Oct  3 10:30:53 2021 ] \tMean test loss of 70 batches: 0.3642330765724182.\n","[ Sun Oct  3 10:30:53 2021 ] \tTop1: 91.83%\n","[ Sun Oct  3 10:30:53 2021 ] \tTop5: 98.91%\n","[ Sun Oct  3 10:30:53 2021 ] Training epoch: 36\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["\r  0%|          | 0/439 [00:00<?, ?it/s]"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["only train part, require grad\n","l1.gcn1.DecoupleA-require grad\n","l2.gcn1.DecoupleA-require grad\n","l3.gcn1.DecoupleA-require grad\n","l4.gcn1.DecoupleA-require grad\n","l5.gcn1.DecoupleA-require grad\n","l6.gcn1.DecoupleA-require grad\n","l7.gcn1.DecoupleA-require grad\n","l8.gcn1.DecoupleA-require grad\n","l9.gcn1.DecoupleA-require grad\n","l10.gcn1.DecoupleA-require grad\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["100%|██████████| 439/439 [15:40<00:00,  2.14s/it]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["[ Sun Oct  3 10:46:33 2021 ] Eval epoch: 36\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["100%|██████████| 70/70 [01:12<00:00,  1.04s/it]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Eval Accuracy:  0.9210049796287914  model:  /content/drive/MyDrive/Colab Notebooks/CVPR21-Dh/finetune/joint/save_models/joint_27_2_finetune\n","[ Sun Oct  3 10:47:46 2021 ] \tMean test loss of 70 batches: 0.3598704934120178.\n","[ Sun Oct  3 10:47:46 2021 ] \tTop1: 92.10%\n","[ Sun Oct  3 10:47:46 2021 ] \tTop5: 98.78%\n","[ Sun Oct  3 10:47:46 2021 ] Training epoch: 37\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["\r  0%|          | 0/439 [00:00<?, ?it/s]"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["only train part, require grad\n","l1.gcn1.DecoupleA-require grad\n","l2.gcn1.DecoupleA-require grad\n","l3.gcn1.DecoupleA-require grad\n","l4.gcn1.DecoupleA-require grad\n","l5.gcn1.DecoupleA-require grad\n","l6.gcn1.DecoupleA-require grad\n","l7.gcn1.DecoupleA-require grad\n","l8.gcn1.DecoupleA-require grad\n","l9.gcn1.DecoupleA-require grad\n","l10.gcn1.DecoupleA-require grad\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["100%|██████████| 439/439 [15:39<00:00,  2.14s/it]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["[ Sun Oct  3 11:03:26 2021 ] Eval epoch: 37\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["100%|██████████| 70/70 [01:12<00:00,  1.04s/it]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Eval Accuracy:  0.9196468990493436  model:  /content/drive/MyDrive/Colab Notebooks/CVPR21-Dh/finetune/joint/save_models/joint_27_2_finetune\n","[ Sun Oct  3 11:04:39 2021 ] \tMean test loss of 70 batches: 0.36530932784080505.\n","[ Sun Oct  3 11:04:39 2021 ] \tTop1: 91.96%\n","[ Sun Oct  3 11:04:39 2021 ] \tTop5: 98.76%\n","[ Sun Oct  3 11:04:39 2021 ] Training epoch: 38\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["\r  0%|          | 0/439 [00:00<?, ?it/s]"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["only train part, require grad\n","l1.gcn1.DecoupleA-require grad\n","l2.gcn1.DecoupleA-require grad\n","l3.gcn1.DecoupleA-require grad\n","l4.gcn1.DecoupleA-require grad\n","l5.gcn1.DecoupleA-require grad\n","l6.gcn1.DecoupleA-require grad\n","l7.gcn1.DecoupleA-require grad\n","l8.gcn1.DecoupleA-require grad\n","l9.gcn1.DecoupleA-require grad\n","l10.gcn1.DecoupleA-require grad\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["100%|██████████| 439/439 [15:39<00:00,  2.14s/it]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["[ Sun Oct  3 11:20:19 2021 ] Eval epoch: 38\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["100%|██████████| 70/70 [01:12<00:00,  1.04s/it]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Eval Accuracy:  0.9187415119963784  model:  /content/drive/MyDrive/Colab Notebooks/CVPR21-Dh/finetune/joint/save_models/joint_27_2_finetune\n","[ Sun Oct  3 11:21:32 2021 ] \tMean test loss of 70 batches: 0.3653229773044586.\n","[ Sun Oct  3 11:21:32 2021 ] \tTop1: 91.87%\n","[ Sun Oct  3 11:21:32 2021 ] \tTop5: 98.87%\n","[ Sun Oct  3 11:21:32 2021 ] Training epoch: 39\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["\r  0%|          | 0/439 [00:00<?, ?it/s]"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["only train part, require grad\n","l1.gcn1.DecoupleA-require grad\n","l2.gcn1.DecoupleA-require grad\n","l3.gcn1.DecoupleA-require grad\n","l4.gcn1.DecoupleA-require grad\n","l5.gcn1.DecoupleA-require grad\n","l6.gcn1.DecoupleA-require grad\n","l7.gcn1.DecoupleA-require grad\n","l8.gcn1.DecoupleA-require grad\n","l9.gcn1.DecoupleA-require grad\n","l10.gcn1.DecoupleA-require grad\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["100%|██████████| 439/439 [15:38<00:00,  2.14s/it]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["[ Sun Oct  3 11:37:11 2021 ] Eval epoch: 39\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["100%|██████████| 70/70 [01:12<00:00,  1.04s/it]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Eval Accuracy:  0.9210049796287914  model:  /content/drive/MyDrive/Colab Notebooks/CVPR21-Dh/finetune/joint/save_models/joint_27_2_finetune\n","[ Sun Oct  3 11:38:24 2021 ] \tMean test loss of 70 batches: 0.364923357963562.\n","[ Sun Oct  3 11:38:24 2021 ] \tTop1: 92.10%\n","[ Sun Oct  3 11:38:24 2021 ] \tTop5: 98.87%\n","[ Sun Oct  3 11:38:24 2021 ] Training epoch: 40\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["\r  0%|          | 0/439 [00:00<?, ?it/s]"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["only train part, require grad\n","l1.gcn1.DecoupleA-require grad\n","l2.gcn1.DecoupleA-require grad\n","l3.gcn1.DecoupleA-require grad\n","l4.gcn1.DecoupleA-require grad\n","l5.gcn1.DecoupleA-require grad\n","l6.gcn1.DecoupleA-require grad\n","l7.gcn1.DecoupleA-require grad\n","l8.gcn1.DecoupleA-require grad\n","l9.gcn1.DecoupleA-require grad\n","l10.gcn1.DecoupleA-require grad\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["100%|██████████| 439/439 [15:40<00:00,  2.14s/it]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["[ Sun Oct  3 11:54:05 2021 ] Eval epoch: 40\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["100%|██████████| 70/70 [01:12<00:00,  1.04s/it]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Eval Accuracy:  0.9187415119963784  model:  /content/drive/MyDrive/Colab Notebooks/CVPR21-Dh/finetune/joint/save_models/joint_27_2_finetune\n","[ Sun Oct  3 11:55:18 2021 ] \tMean test loss of 70 batches: 0.36528390645980835.\n","[ Sun Oct  3 11:55:18 2021 ] \tTop1: 91.87%\n","[ Sun Oct  3 11:55:18 2021 ] \tTop5: 98.94%\n","[ Sun Oct  3 11:55:18 2021 ] Training epoch: 41\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["\r  0%|          | 0/439 [00:00<?, ?it/s]"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["only train part, require grad\n","l1.gcn1.DecoupleA-require grad\n","l2.gcn1.DecoupleA-require grad\n","l3.gcn1.DecoupleA-require grad\n","l4.gcn1.DecoupleA-require grad\n","l5.gcn1.DecoupleA-require grad\n","l6.gcn1.DecoupleA-require grad\n","l7.gcn1.DecoupleA-require grad\n","l8.gcn1.DecoupleA-require grad\n","l9.gcn1.DecoupleA-require grad\n","l10.gcn1.DecoupleA-require grad\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["100%|██████████| 439/439 [15:40<00:00,  2.14s/it]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["[ Sun Oct  3 12:10:58 2021 ] Eval epoch: 41\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["100%|██████████| 70/70 [01:12<00:00,  1.04s/it]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Eval Accuracy:  0.9178361249434133  model:  /content/drive/MyDrive/Colab Notebooks/CVPR21-Dh/finetune/joint/save_models/joint_27_2_finetune\n","[ Sun Oct  3 12:12:11 2021 ] \tMean test loss of 70 batches: 0.3668380677700043.\n","[ Sun Oct  3 12:12:11 2021 ] \tTop1: 91.78%\n","[ Sun Oct  3 12:12:11 2021 ] \tTop5: 98.78%\n","[ Sun Oct  3 12:12:11 2021 ] Training epoch: 42\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["\r  0%|          | 0/439 [00:00<?, ?it/s]"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["only train part, require grad\n","l1.gcn1.DecoupleA-require grad\n","l2.gcn1.DecoupleA-require grad\n","l3.gcn1.DecoupleA-require grad\n","l4.gcn1.DecoupleA-require grad\n","l5.gcn1.DecoupleA-require grad\n","l6.gcn1.DecoupleA-require grad\n","l7.gcn1.DecoupleA-require grad\n","l8.gcn1.DecoupleA-require grad\n","l9.gcn1.DecoupleA-require grad\n","l10.gcn1.DecoupleA-require grad\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 439/439 [15:39<00:00,  2.14s/it]\n"]},{"output_type":"stream","name":"stdout","text":["[ Sun Oct  3 12:27:51 2021 ] Eval epoch: 42\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 70/70 [01:13<00:00,  1.04s/it]\n"]},{"output_type":"stream","name":"stdout","text":["Eval Accuracy:  0.9214576731552738  model:  /content/drive/MyDrive/Colab Notebooks/CVPR21-Dh/finetune/joint/save_models/joint_27_2_finetune\n","[ Sun Oct  3 12:29:05 2021 ] \tMean test loss of 70 batches: 0.36255940794944763.\n","[ Sun Oct  3 12:29:05 2021 ] \tTop1: 92.15%\n","[ Sun Oct  3 12:29:05 2021 ] \tTop5: 98.85%\n","[ Sun Oct  3 12:29:05 2021 ] Training epoch: 43\n"]},{"output_type":"stream","name":"stderr","text":["\r  0%|          | 0/439 [00:00<?, ?it/s]"]},{"output_type":"stream","name":"stdout","text":["only train part, require grad\n","l1.gcn1.DecoupleA-require grad\n","l2.gcn1.DecoupleA-require grad\n","l3.gcn1.DecoupleA-require grad\n","l4.gcn1.DecoupleA-require grad\n","l5.gcn1.DecoupleA-require grad\n","l6.gcn1.DecoupleA-require grad\n","l7.gcn1.DecoupleA-require grad\n","l8.gcn1.DecoupleA-require grad\n","l9.gcn1.DecoupleA-require grad\n","l10.gcn1.DecoupleA-require grad\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 439/439 [15:40<00:00,  2.14s/it]\n"]},{"output_type":"stream","name":"stdout","text":["[ Sun Oct  3 12:44:46 2021 ] Eval epoch: 43\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 70/70 [01:12<00:00,  1.04s/it]\n"]},{"output_type":"stream","name":"stdout","text":["Eval Accuracy:  0.9187415119963784  model:  /content/drive/MyDrive/Colab Notebooks/CVPR21-Dh/finetune/joint/save_models/joint_27_2_finetune\n","[ Sun Oct  3 12:45:59 2021 ] \tMean test loss of 70 batches: 0.35406211018562317.\n","[ Sun Oct  3 12:45:59 2021 ] \tTop1: 91.87%\n","[ Sun Oct  3 12:45:59 2021 ] \tTop5: 98.82%\n","[ Sun Oct  3 12:45:59 2021 ] Training epoch: 44\n"]},{"output_type":"stream","name":"stderr","text":["\r  0%|          | 0/439 [00:00<?, ?it/s]"]},{"output_type":"stream","name":"stdout","text":["only train part, require grad\n","l1.gcn1.DecoupleA-require grad\n","l2.gcn1.DecoupleA-require grad\n","l3.gcn1.DecoupleA-require grad\n","l4.gcn1.DecoupleA-require grad\n","l5.gcn1.DecoupleA-require grad\n","l6.gcn1.DecoupleA-require grad\n","l7.gcn1.DecoupleA-require grad\n","l8.gcn1.DecoupleA-require grad\n","l9.gcn1.DecoupleA-require grad\n","l10.gcn1.DecoupleA-require grad\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 439/439 [15:40<00:00,  2.14s/it]\n"]},{"output_type":"stream","name":"stdout","text":["[ Sun Oct  3 13:01:39 2021 ] Eval epoch: 44\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 70/70 [01:13<00:00,  1.04s/it]\n"]},{"output_type":"stream","name":"stdout","text":["Eval Accuracy:  0.917609778180172  model:  /content/drive/MyDrive/Colab Notebooks/CVPR21-Dh/finetune/joint/save_models/joint_27_2_finetune\n","[ Sun Oct  3 13:02:53 2021 ] \tMean test loss of 70 batches: 0.3641577661037445.\n","[ Sun Oct  3 13:02:53 2021 ] \tTop1: 91.76%\n","[ Sun Oct  3 13:02:53 2021 ] \tTop5: 98.76%\n","[ Sun Oct  3 13:02:53 2021 ] Training epoch: 45\n"]},{"output_type":"stream","name":"stderr","text":["\r  0%|          | 0/439 [00:00<?, ?it/s]"]},{"output_type":"stream","name":"stdout","text":["only train part, require grad\n","l1.gcn1.DecoupleA-require grad\n","l2.gcn1.DecoupleA-require grad\n","l3.gcn1.DecoupleA-require grad\n","l4.gcn1.DecoupleA-require grad\n","l5.gcn1.DecoupleA-require grad\n","l6.gcn1.DecoupleA-require grad\n","l7.gcn1.DecoupleA-require grad\n","l8.gcn1.DecoupleA-require grad\n","l9.gcn1.DecoupleA-require grad\n","l10.gcn1.DecoupleA-require grad\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 439/439 [15:45<00:00,  2.15s/it]\n"]},{"output_type":"stream","name":"stdout","text":["[ Sun Oct  3 13:18:38 2021 ] Eval epoch: 45\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 70/70 [01:13<00:00,  1.05s/it]\n"]},{"output_type":"stream","name":"stdout","text":["Eval Accuracy:  0.9178361249434133  model:  /content/drive/MyDrive/Colab Notebooks/CVPR21-Dh/finetune/joint/save_models/joint_27_2_finetune\n","[ Sun Oct  3 13:19:52 2021 ] \tMean test loss of 70 batches: 0.36208677291870117.\n","[ Sun Oct  3 13:19:52 2021 ] \tTop1: 91.78%\n","[ Sun Oct  3 13:19:52 2021 ] \tTop5: 98.87%\n","[ Sun Oct  3 13:19:52 2021 ] Training epoch: 46\n"]},{"output_type":"stream","name":"stderr","text":["\r  0%|          | 0/439 [00:00<?, ?it/s]"]},{"output_type":"stream","name":"stdout","text":["only train part, require grad\n","l1.gcn1.DecoupleA-require grad\n","l2.gcn1.DecoupleA-require grad\n","l3.gcn1.DecoupleA-require grad\n","l4.gcn1.DecoupleA-require grad\n","l5.gcn1.DecoupleA-require grad\n","l6.gcn1.DecoupleA-require grad\n","l7.gcn1.DecoupleA-require grad\n","l8.gcn1.DecoupleA-require grad\n","l9.gcn1.DecoupleA-require grad\n","l10.gcn1.DecoupleA-require grad\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 439/439 [15:45<00:00,  2.15s/it]\n"]},{"output_type":"stream","name":"stdout","text":["[ Sun Oct  3 13:35:38 2021 ] Eval epoch: 46\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 70/70 [01:13<00:00,  1.05s/it]\n"]},{"output_type":"stream","name":"stdout","text":["Eval Accuracy:  0.9194205522861023  model:  /content/drive/MyDrive/Colab Notebooks/CVPR21-Dh/finetune/joint/save_models/joint_27_2_finetune\n","[ Sun Oct  3 13:36:51 2021 ] \tMean test loss of 70 batches: 0.3551604747772217.\n","[ Sun Oct  3 13:36:51 2021 ] \tTop1: 91.94%\n","[ Sun Oct  3 13:36:51 2021 ] \tTop5: 98.98%\n","[ Sun Oct  3 13:36:51 2021 ] Training epoch: 47\n"]},{"output_type":"stream","name":"stderr","text":["\r  0%|          | 0/439 [00:00<?, ?it/s]"]},{"output_type":"stream","name":"stdout","text":["only train part, require grad\n","l1.gcn1.DecoupleA-require grad\n","l2.gcn1.DecoupleA-require grad\n","l3.gcn1.DecoupleA-require grad\n","l4.gcn1.DecoupleA-require grad\n","l5.gcn1.DecoupleA-require grad\n","l6.gcn1.DecoupleA-require grad\n","l7.gcn1.DecoupleA-require grad\n","l8.gcn1.DecoupleA-require grad\n","l9.gcn1.DecoupleA-require grad\n","l10.gcn1.DecoupleA-require grad\n"]},{"output_type":"stream","name":"stderr","text":[" 69%|██████▉   | 305/439 [10:56<04:46,  2.14s/it]"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"-T4VEC-zf-ov","executionInfo":{"elapsed":6785322,"status":"error","timestamp":1628176880188,"user":{"displayName":"Md.safirur Rashid, 170041020","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj4vsxiS6hdwcIxlWkCOlOKX6Yb9qvDnhTv0OE=s64","userId":"07083869211232678860"},"user_tz":-360},"outputId":"75e2c36c-c045-4fa1-e72a-9209419aaff2"},"source":["%cd /content/CVPR21Chal-SLR/SL-GCN\n","init_seed(0)\n","processor = Processor(arg)\n","processor.start()\n","%cd /content"],"execution_count":null,"outputs":[{"name":"stdout","output_type":"stream","text":["/content/CVPR21Chal-SLR/SL-GCN\n"]},{"name":"stderr","output_type":"stream","text":["/content/CVPR21Chal-SLR/SL-GCN/model/decouple_gcn_attn.py:29: UserWarning: nn.init.kaiming_normal is now deprecated in favor of nn.init.kaiming_normal_.\n","  nn.init.kaiming_normal(conv.weight, mode='fan_out')\n","/content/CVPR21Chal-SLR/SL-GCN/model/decouple_gcn_attn.py:30: UserWarning: nn.init.constant is now deprecated in favor of nn.init.constant_.\n","  nn.init.constant(conv.bias, 0)\n","/content/CVPR21Chal-SLR/SL-GCN/model/decouple_gcn_attn.py:34: UserWarning: nn.init.constant is now deprecated in favor of nn.init.constant_.\n","  nn.init.constant(bn.weight, scale)\n","/content/CVPR21Chal-SLR/SL-GCN/model/decouple_gcn_attn.py:35: UserWarning: nn.init.constant is now deprecated in favor of nn.init.constant_.\n","  nn.init.constant(bn.bias, 0)\n","/content/CVPR21Chal-SLR/SL-GCN/model/decouple_gcn_attn.py:113: UserWarning: nn.init.constant is now deprecated in favor of nn.init.constant_.\n","  nn.init.constant(self.Linear_bias, 1e-6)\n","/content/CVPR21Chal-SLR/SL-GCN/model/decouple_gcn_attn.py:119: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  eye_array), requires_grad=False, device='cuda'), requires_grad=False)  # [c,25,25]\n","/content/CVPR21Chal-SLR/SL-GCN/model/decouple_gcn_attn.py:252: UserWarning: nn.init.normal is now deprecated in favor of nn.init.normal_.\n","  nn.init.normal(self.fc.weight, 0, math.sqrt(2. / num_class))\n"]},{"name":"stdout","output_type":"stream","text":["Attention Enabled!\n","Attention Enabled!\n","Attention Enabled!\n","Attention Enabled!\n","Attention Enabled!\n","Attention Enabled!\n","Attention Enabled!\n","Attention Enabled!\n","Attention Enabled!\n","Attention Enabled!\n","[ Thu Aug  5 13:28:24 2021 ] Load weights from /content/drive/MyDrive/Colab Notebooks/CVPR21-Bh/train2/idk/sign_joint_final-30.pt.\n","28142\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 32 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n","  0%|          | 0/439 [00:00<?, ?it/s]"]},{"name":"stdout","output_type":"stream","text":["28142\n","[ Thu Aug  5 13:28:31 2021 ] Parameters:\n","{'Experiment_name': 'sign_joint_final', 'base_lr': 0.1, 'batch_size': 64, 'config': '/content/CVPR21Chal-SLR/SL-GCN/config/sign/train/train_joint.yaml', 'device': [0], 'eval_interval': 5, 'feeder': 'feeders.feeder.Feeder', 'groups': 8, 'ignore_weights': [], 'keep_rate': 0.9, 'log_interval': 100, 'model': 'model.decouple_gcn_attn.Model', 'model_args': {'num_class': 226, 'num_point': 27, 'num_person': 1, 'graph': 'graph.sign_27.Graph', 'groups': 16, 'block_size': 41, 'graph_args': {'labeling_mode': 'spatial'}}, 'model_saved_name': './save_models/sign_joint_final', 'nesterov': True, 'num_epoch': 250, 'num_worker': 32, 'only_train_epoch': 1, 'only_train_part': True, 'optimizer': 'SGD', 'phase': 'train', 'print_log': True, 'save_interval': 2, 'save_score': False, 'seed': 1, 'show_topk': [1, 5], 'start_epoch': 0, 'step': [150, 200], 'test_batch_size': 64, 'test_feeder_args': {'data_path': '/content/data/sign/27_2/train_data_joint.npy', 'label_path': '/content/data/sign/27_2/train_label.pkl', 'random_mirror': False, 'normalization': True}, 'train_feeder_args': {'data_path': '/content/data/sign/27_2/train_data_joint.npy', 'label_path': '/content/data/sign/27_2/train_label.pkl', 'debug': False, 'random_choose': True, 'window_size': 100, 'random_shift': True, 'normalization': True, 'random_mirror': True, 'random_mirror_p': 0.5, 'is_vector': False}, 'warm_up_epoch': 20, 'weight_decay': 0.0001, 'weights': '/content/drive/MyDrive/Colab Notebooks/CVPR21-Bh/train2/idk/sign_joint_final-30.pt', 'work_dir': './work_dir/sign_joint_final'}\n","\n","[ Thu Aug  5 13:28:31 2021 ] Training epoch: 1\n","only train part, do not require grad\n","l1.gcn1.DecoupleA-not require grad\n","l2.gcn1.DecoupleA-not require grad\n","l3.gcn1.DecoupleA-not require grad\n","l4.gcn1.DecoupleA-not require grad\n","l5.gcn1.DecoupleA-not require grad\n","l6.gcn1.DecoupleA-not require grad\n","l7.gcn1.DecoupleA-not require grad\n","l8.gcn1.DecoupleA-not require grad\n","l9.gcn1.DecoupleA-not require grad\n","l10.gcn1.DecoupleA-not require grad\n"]},{"name":"stderr","output_type":"stream","text":[" 23%|██▎       | 100/439 [03:13<10:54,  1.93s/it]"]},{"name":"stdout","output_type":"stream","text":["[ Thu Aug  5 13:31:44 2021 ] \tBatch(99/439) done. Loss: 0.0818  lr:0.005000\n"]},{"name":"stderr","output_type":"stream","text":[" 46%|████▌     | 200/439 [06:26<07:41,  1.93s/it]"]},{"name":"stdout","output_type":"stream","text":["[ Thu Aug  5 13:34:57 2021 ] \tBatch(199/439) done. Loss: 0.0563  lr:0.005000\n"]},{"name":"stderr","output_type":"stream","text":[" 68%|██████▊   | 300/439 [09:38<04:27,  1.92s/it]"]},{"name":"stdout","output_type":"stream","text":["[ Thu Aug  5 13:38:10 2021 ] \tBatch(299/439) done. Loss: 0.0554  lr:0.005000\n"]},{"name":"stderr","output_type":"stream","text":[" 91%|█████████ | 400/439 [12:50<01:14,  1.92s/it]"]},{"name":"stdout","output_type":"stream","text":["[ Thu Aug  5 13:41:22 2021 ] \tBatch(399/439) done. Loss: 0.0319  lr:0.005000\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 439/439 [14:06<00:00,  1.93s/it]\n","  0%|          | 0/440 [00:00<?, ?it/s]"]},{"name":"stdout","output_type":"stream","text":["[ Thu Aug  5 13:42:37 2021 ] Eval epoch: 1\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 440/440 [07:45<00:00,  1.06s/it]\n"]},{"name":"stdout","output_type":"stream","text":["Eval Accuracy:  0.9941013431881174  model:  ./save_models/sign_joint_final\n","[ Thu Aug  5 13:50:24 2021 ] \tMean test loss of 440 batches: 0.02263963781297207.\n","[ Thu Aug  5 13:50:24 2021 ] \tTop1: 99.41%\n","[ Thu Aug  5 13:50:25 2021 ] \tTop5: 100.00%\n"]},{"name":"stderr","output_type":"stream","text":["\r  0%|          | 0/439 [00:00<?, ?it/s]"]},{"name":"stdout","output_type":"stream","text":["[ Thu Aug  5 13:50:25 2021 ] Training epoch: 2\n","only train part, require grad\n","l1.gcn1.DecoupleA-require grad\n","l2.gcn1.DecoupleA-require grad\n","l3.gcn1.DecoupleA-require grad\n","l4.gcn1.DecoupleA-require grad\n","l5.gcn1.DecoupleA-require grad\n","l6.gcn1.DecoupleA-require grad\n","l7.gcn1.DecoupleA-require grad\n","l8.gcn1.DecoupleA-require grad\n","l9.gcn1.DecoupleA-require grad\n","l10.gcn1.DecoupleA-require grad\n"]},{"name":"stderr","output_type":"stream","text":["/content/CVPR21Chal-SLR/SL-GCN/model/dropSke.py:29: UserWarning: undefined skeleton graph\n","  warnings.warn('undefined skeleton graph')\n","/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:652: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)\n","  return torch.max_pool1d(input, kernel_size, stride, padding, dilation, ceil_mode)\n"," 14%|█▍        | 61/439 [02:15<13:47,  2.19s/it]"]},{"name":"stdout","output_type":"stream","text":["[ Thu Aug  5 13:52:40 2021 ] \tBatch(60/439) done. Loss: 0.0116  lr:0.010000\n"]},{"name":"stderr","output_type":"stream","text":[" 37%|███▋      | 161/439 [05:54<10:09,  2.19s/it]"]},{"name":"stdout","output_type":"stream","text":["[ Thu Aug  5 13:56:19 2021 ] \tBatch(160/439) done. Loss: 0.0302  lr:0.010000\n"]},{"name":"stderr","output_type":"stream","text":[" 59%|█████▉    | 261/439 [09:33<06:31,  2.20s/it]"]},{"name":"stdout","output_type":"stream","text":["[ Thu Aug  5 13:59:58 2021 ] \tBatch(260/439) done. Loss: 0.0100  lr:0.010000\n"]},{"name":"stderr","output_type":"stream","text":[" 82%|████████▏ | 361/439 [13:13<02:51,  2.20s/it]"]},{"name":"stdout","output_type":"stream","text":["[ Thu Aug  5 14:03:38 2021 ] \tBatch(360/439) done. Loss: 0.0181  lr:0.010000\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 439/439 [16:04<00:00,  2.20s/it]\n","  0%|          | 0/440 [00:00<?, ?it/s]"]},{"name":"stdout","output_type":"stream","text":["[ Thu Aug  5 14:06:30 2021 ] Eval epoch: 2\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 440/440 [07:43<00:00,  1.05s/it]\n"]},{"name":"stdout","output_type":"stream","text":["Eval Accuracy:  0.9962333878189183  model:  ./save_models/sign_joint_final\n","[ Thu Aug  5 14:14:14 2021 ] \tMean test loss of 440 batches: 0.014988066628575325.\n","[ Thu Aug  5 14:14:15 2021 ] \tTop1: 99.62%\n","[ Thu Aug  5 14:14:15 2021 ] \tTop5: 100.00%\n"]},{"name":"stderr","output_type":"stream","text":["\r  0%|          | 0/439 [00:00<?, ?it/s]"]},{"name":"stdout","output_type":"stream","text":["[ Thu Aug  5 14:14:15 2021 ] Training epoch: 3\n","only train part, require grad\n","l1.gcn1.DecoupleA-require grad\n","l2.gcn1.DecoupleA-require grad\n","l3.gcn1.DecoupleA-require grad\n","l4.gcn1.DecoupleA-require grad\n","l5.gcn1.DecoupleA-require grad\n","l6.gcn1.DecoupleA-require grad\n","l7.gcn1.DecoupleA-require grad\n","l8.gcn1.DecoupleA-require grad\n","l9.gcn1.DecoupleA-require grad\n","l10.gcn1.DecoupleA-require grad\n"]},{"name":"stderr","output_type":"stream","text":["  5%|▌         | 22/439 [00:49<15:11,  2.19s/it]"]},{"name":"stdout","output_type":"stream","text":["[ Thu Aug  5 14:15:05 2021 ] \tBatch(21/439) done. Loss: 0.0617  lr:0.015000\n"]},{"name":"stderr","output_type":"stream","text":[" 28%|██▊       | 122/439 [04:27<11:31,  2.18s/it]"]},{"name":"stdout","output_type":"stream","text":["[ Thu Aug  5 14:18:43 2021 ] \tBatch(121/439) done. Loss: 0.0282  lr:0.015000\n"]},{"name":"stderr","output_type":"stream","text":[" 51%|█████     | 222/439 [08:05<07:52,  2.18s/it]"]},{"name":"stdout","output_type":"stream","text":["[ Thu Aug  5 14:22:21 2021 ] \tBatch(221/439) done. Loss: 0.0070  lr:0.015000\n"]},{"name":"stderr","output_type":"stream","text":[" 73%|███████▎  | 322/439 [11:43<04:15,  2.18s/it]"]},{"name":"stdout","output_type":"stream","text":["[ Thu Aug  5 14:25:59 2021 ] \tBatch(321/439) done. Loss: 0.0107  lr:0.015000\n"]},{"name":"stderr","output_type":"stream","text":[" 96%|█████████▌| 422/439 [15:21<00:37,  2.18s/it]"]},{"name":"stdout","output_type":"stream","text":["[ Thu Aug  5 14:29:37 2021 ] \tBatch(421/439) done. Loss: 0.0058  lr:0.015000\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 439/439 [15:59<00:00,  2.19s/it]\n","  0%|          | 0/440 [00:00<?, ?it/s]"]},{"name":"stdout","output_type":"stream","text":["[ Thu Aug  5 14:30:15 2021 ] Eval epoch: 3\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 440/440 [07:44<00:00,  1.06s/it]\n"]},{"name":"stdout","output_type":"stream","text":["Eval Accuracy:  0.9971572738255987  model:  ./save_models/sign_joint_final\n","[ Thu Aug  5 14:38:00 2021 ] \tMean test loss of 440 batches: 0.011403367854654789.\n","[ Thu Aug  5 14:38:01 2021 ] \tTop1: 99.72%\n","[ Thu Aug  5 14:38:01 2021 ] \tTop5: 100.00%\n"]},{"name":"stderr","output_type":"stream","text":["\r  0%|          | 0/439 [00:00<?, ?it/s]"]},{"name":"stdout","output_type":"stream","text":["[ Thu Aug  5 14:38:01 2021 ] Training epoch: 4\n","only train part, require grad\n","l1.gcn1.DecoupleA-require grad\n","l2.gcn1.DecoupleA-require grad\n","l3.gcn1.DecoupleA-require grad\n","l4.gcn1.DecoupleA-require grad\n","l5.gcn1.DecoupleA-require grad\n","l6.gcn1.DecoupleA-require grad\n","l7.gcn1.DecoupleA-require grad\n","l8.gcn1.DecoupleA-require grad\n","l9.gcn1.DecoupleA-require grad\n","l10.gcn1.DecoupleA-require grad\n"]},{"name":"stderr","output_type":"stream","text":[" 19%|█▉        | 83/439 [03:02<12:55,  2.18s/it]"]},{"name":"stdout","output_type":"stream","text":["[ Thu Aug  5 14:41:04 2021 ] \tBatch(82/439) done. Loss: 0.0555  lr:0.020000\n"]},{"name":"stderr","output_type":"stream","text":[" 42%|████▏     | 183/439 [06:41<09:19,  2.19s/it]"]},{"name":"stdout","output_type":"stream","text":["[ Thu Aug  5 14:44:42 2021 ] \tBatch(182/439) done. Loss: 0.0292  lr:0.020000\n"]},{"name":"stderr","output_type":"stream","text":[" 64%|██████▍   | 283/439 [10:19<05:40,  2.18s/it]"]},{"name":"stdout","output_type":"stream","text":["[ Thu Aug  5 14:48:20 2021 ] \tBatch(282/439) done. Loss: 0.0826  lr:0.020000\n"]},{"name":"stderr","output_type":"stream","text":[" 87%|████████▋ | 383/439 [13:57<02:02,  2.18s/it]"]},{"name":"stdout","output_type":"stream","text":["[ Thu Aug  5 14:51:58 2021 ] \tBatch(382/439) done. Loss: 0.0255  lr:0.020000\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 439/439 [15:59<00:00,  2.19s/it]\n","  0%|          | 0/440 [00:00<?, ?it/s]"]},{"name":"stdout","output_type":"stream","text":["[ Thu Aug  5 14:54:01 2021 ] Eval epoch: 4\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 440/440 [07:44<00:00,  1.05s/it]\n"]},{"name":"stdout","output_type":"stream","text":["Eval Accuracy:  0.9985786369127994  model:  ./save_models/sign_joint_final\n","[ Thu Aug  5 15:01:46 2021 ] \tMean test loss of 440 batches: 0.008795651607215405.\n","[ Thu Aug  5 15:01:46 2021 ] \tTop1: 99.86%\n","[ Thu Aug  5 15:01:47 2021 ] \tTop5: 100.00%\n"]},{"name":"stderr","output_type":"stream","text":["\r  0%|          | 0/439 [00:00<?, ?it/s]"]},{"name":"stdout","output_type":"stream","text":["[ Thu Aug  5 15:01:47 2021 ] Training epoch: 5\n","only train part, require grad\n","l1.gcn1.DecoupleA-require grad\n","l2.gcn1.DecoupleA-require grad\n","l3.gcn1.DecoupleA-require grad\n","l4.gcn1.DecoupleA-require grad\n","l5.gcn1.DecoupleA-require grad\n","l6.gcn1.DecoupleA-require grad\n","l7.gcn1.DecoupleA-require grad\n","l8.gcn1.DecoupleA-require grad\n","l9.gcn1.DecoupleA-require grad\n","l10.gcn1.DecoupleA-require grad\n"]},{"name":"stderr","output_type":"stream","text":[" 10%|█         | 44/439 [01:37<14:22,  2.18s/it]"]},{"name":"stdout","output_type":"stream","text":["[ Thu Aug  5 15:03:25 2021 ] \tBatch(43/439) done. Loss: 0.0093  lr:0.025000\n"]},{"name":"stderr","output_type":"stream","text":[" 33%|███▎      | 144/439 [05:15<10:44,  2.18s/it]"]},{"name":"stdout","output_type":"stream","text":["[ Thu Aug  5 15:07:03 2021 ] \tBatch(143/439) done. Loss: 0.0245  lr:0.025000\n"]},{"name":"stderr","output_type":"stream","text":[" 56%|█████▌    | 244/439 [08:53<07:05,  2.18s/it]"]},{"name":"stdout","output_type":"stream","text":["[ Thu Aug  5 15:10:41 2021 ] \tBatch(243/439) done. Loss: 0.0616  lr:0.025000\n"]},{"name":"stderr","output_type":"stream","text":[" 78%|███████▊  | 344/439 [12:31<03:27,  2.18s/it]"]},{"name":"stdout","output_type":"stream","text":["[ Thu Aug  5 15:14:19 2021 ] \tBatch(343/439) done. Loss: 0.0079  lr:0.025000\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 439/439 [15:59<00:00,  2.19s/it]\n","  0%|          | 0/440 [00:00<?, ?it/s]"]},{"name":"stdout","output_type":"stream","text":["[ Thu Aug  5 15:17:47 2021 ] Eval epoch: 5\n"]},{"name":"stderr","output_type":"stream","text":[" 45%|████▌     | 199/440 [03:30<04:13,  1.05s/it]"]},{"ename":"KeyboardInterrupt","evalue":"ignored","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-11-69f8114b0d65>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0minit_seed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprocessor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mProcessor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mprocessor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmagic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cd /content'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-7-1d77e7829680>\u001b[0m in \u001b[0;36mstart\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    342\u001b[0m                     \u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    343\u001b[0m                     \u001b[0msave_score\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_score\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 344\u001b[0;31m                     loader_name=['test'])\n\u001b[0m\u001b[1;32m    345\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    346\u001b[0m                 \u001b[0;31m# self.lr_scheduler.step(val_loss)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-7-1d77e7829680>\u001b[0m in \u001b[0;36meval\u001b[0;34m(self, epoch, save_score, loader_name, wrong_file, result_file)\u001b[0m\n\u001b[1;32m    283\u001b[0m                         \u001b[0ml1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    284\u001b[0m                     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 285\u001b[0;31m                     \u001b[0mscore_frag\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    286\u001b[0m                     \u001b[0mloss_value\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    287\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"markdown","metadata":{"id":"zPjAh6GBZIbE"},"source":["# To copy all the output files in /content/CVPR21Chal-SLR/SL-GCN/save_models"]},{"cell_type":"code","metadata":{"id":"RcmO5tC4l8Um"},"source":["import os, shutil\n","def copytree(src, dst, symlinks=False, ignore=None):\n","    for item in os.listdir(src):\n","        s = os.path.join(src, item)\n","        d = os.path.join(dst, item)\n","        if os.path.isdir(s):\n","            shutil.copytree(s, d, symlinks, ignore)\n","        else:\n","            shutil.copy2(s, d)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"EbVx4cA7mB6o"},"source":["copytree('/content/CVPR21Chal-SLR/SL-GCN/save_models','/content/drive/MyDrive/Colab Notebooks/CVPR21-Bh/train2/irdk')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Bv54___SZbuj"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"6yG9LjIiZbsH"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"_mSgvex9ZbpT"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"wCDh1Jf_ZcJJ"},"source":["# personal debugging"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":371},"id":"yMKfV6iLffRu","executionInfo":{"elapsed":474,"status":"error","timestamp":1627281887303,"user":{"displayName":"Md.safirur Rashid, 170041020","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj4vsxiS6hdwcIxlWkCOlOKX6Yb9qvDnhTv0OE=s64","userId":"07083869211232678860"},"user_tz":-360},"outputId":"a40dcd18-4fda-4f02-9311-997d707d9c78"},"source":["parser = get_parser()\n","if p.config is not None:\n","    with open(p.config, 'r') as f:\n","        default_arg = yaml.load(f)\n","    key = vars(p).keys()\n","    for k in default_arg.keys():\n","        if k not in key:\n","            print('WRONG ARG: {}'.format(k))\n","            assert (k in key)\n","    parser.set_defaults(**default_arg)"],"execution_count":null,"outputs":[{"ename":"NameError","evalue":"ignored","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-19-872d6c31d352>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_parser\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0mdefault_arg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0myaml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvars\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-14-f5dd850b61c5>\u001b[0m in \u001b[0;36mget_parser\u001b[0;34m()\u001b[0m\n\u001b[1;32m     20\u001b[0m     parser.add_argument(\n\u001b[1;32m     21\u001b[0m         \u001b[0;34m'--save-score'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m         \u001b[0mtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstr2bool\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m         \u001b[0mdefault\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m         help='if ture, the classification score will be stored')\n","\u001b[0;31mNameError\u001b[0m: name 'str2bool' is not defined"]}]},{"cell_type":"code","metadata":{"id":"lCRaSluhffJA"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"15d7jyxaffBv"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"FxUs6Vxqfe-m"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"6WM2Lg6mrFoB"},"source":["p = Namespace(\n","    Experiment_name='', \n","    base_lr=0.01, \n","    batch_size=256, \n","    config='/content/CVPR21Chal-SLR/SL-GCN/config/sign/train/train_joint.yaml', \n","    device=0, \n","    eval_interval=5, \n","    feeder='feeder.feeder', \n","    groups=8, \n","    ignore_weights=[], \n","    keep_rate=0.9, \n","    log_interval=100, \n","    model=None, \n","    model_args={}, \n","    model_saved_name='', \n","    nesterov=False, \n","    num_epoch=80, \n","    num_worker=32, \n","    only_train_epoch=0, \n","    only_train_part=True, \n","    optimizer='SGD', \n","    phase='train', \n","    print_log=True, \n","    save_interval=2, \n","    save_score=False, \n","    seed=1, \n","    show_topk=[1, 5], \n","    start_epoch=0, \n","    step=[20, 40, 60], \n","    test_batch_size=256, \n","    test_feeder_args={}, \n","    train_feeder_args={}, \n","    warm_up_epoch=0, \n","    weight_decay=0.0005, \n","    weights=None, \n","    work_dir='./work_dir/temp')\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"q1VWvgZhOt_m"},"source":["Namespace(\n","    Experiment_name='sign_joint_final', \n","    base_lr=0.1, \n","    batch_size=64, \n","    config='/content/CVPR21Chal-SLR/SL-GCN/config/sign/train/train_joint.yaml', \n","    device=[0, 1, 2, 3], \n","    eval_interval=5, \n","    feeder='feeders.feeder.Feeder', \n","    groups=8, \n","    ignore_weights=[], \n","    keep_rate=0.9, \n","    log_interval=100, \n","    model='model.decouple_gcn_attn.Model', \n","    model_args={\n","        'num_class': 226, \n","        'num_point': 27, \n","        'num_person': 1, \n","        'graph': 'graph.sign_27.Graph', \n","        'groups': 16, \n","        'block_size': 41, \n","        'graph_args': {'labeling_mode': 'spatial'}\n","    }, \n","    model_saved_name='', \n","    nesterov=True, \n","    num_epoch=250, \n","    num_worker=32, \n","    only_train_epoch=1, \n","    only_train_part=True, \n","    optimizer='SGD', \n","    phase='train', \n","    print_log=True, \n","    save_interval=2, \n","    save_score=False, \n","    seed=1, \n","    show_topk=[1, 5], \n","    start_epoch=0, \n","    step=[150, 200], \n","    test_batch_size=64, \n","    test_feeder_args={\n","        'data_path': './data/sign/27_2/val_data_joint.npy', \n","        'label_path': './data/sign/27_2/val_gt.pkl', \n","        'random_mirror': False, \n","        'normalization': True\n","    }, \n","    train_feeder_args={\n","        'data_path': './data/sign/27_2/train_data_joint.npy', \n","        'label_path': './data/sign/27_2/train_label.pkl', \n","        'debug': False, \n","        'random_choose': True, \n","        'window_size': 100, \n","        'random_shift': True, \n","        'normalization': True, \n","        'random_mirror': True, \n","        'random_mirror_p': 0.5, \n","        'is_vector': False\n","    }, \n","    warm_up_epoch=20, \n","    weight_decay=0.0001, \n","    weights=None, \n","    work_dir='./work_dir/temp'\n",")\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"976xN7LflsHG"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1Ge3F9MblsEH","executionInfo":{"elapsed":8,"status":"ok","timestamp":1627413338236,"user":{"displayName":"Md.safirur Rashid, 170041020","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj4vsxiS6hdwcIxlWkCOlOKX6Yb9qvDnhTv0OE=s64","userId":"07083869211232678860"},"user_tz":-360},"outputId":"2a0e269b-be2b-4679-d473-b5166233c061"},"source":["!pwd"],"execution_count":null,"outputs":[{"name":"stdout","output_type":"stream","text":["/content/CVPR21Chal-SLR/SL-GCN\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pp1RNY2hls9q","executionInfo":{"elapsed":393,"status":"ok","timestamp":1627285719897,"user":{"displayName":"Md.safirur Rashid, 170041020","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj4vsxiS6hdwcIxlWkCOlOKX6Yb9qvDnhTv0OE=s64","userId":"07083869211232678860"},"user_tz":-360},"outputId":"5254697f-994c-4822-b281-b0acaa0c3b51"},"source":["%cd /content/data/sign/27_2\n","!ls"],"execution_count":null,"outputs":[{"name":"stdout","output_type":"stream","text":["[Errno 20] Not a directory: '/content/data/sign/27_2'\n","/content/drive/.shortcut-targets-by-id/1GhEIIcgxzMyFdfLihYOKuui9LUxm_E7T/copy_test_123\n","test_data_bone_motion.npy   test_label.pkl\t\t train_data_joint.npy\n","test_data_bone.npy\t    train_data_bone_motion.npy\t train_label.pkl\n","test_data_joint_motion.npy  train_data_bone.npy\n","test_data_joint.npy\t    train_data_joint_motion.npy\n"]}]},{"cell_type":"code","metadata":{"id":"QCIi2P5vZzVl"},"source":[""],"execution_count":null,"outputs":[]}]}