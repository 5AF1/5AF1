{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"21-8-14-1 training.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"HdWZctCnRBKG"},"source":["# GPU Check"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"h3Wbn3yeIxD2","executionInfo":{"status":"ok","timestamp":1628952962943,"user_tz":-360,"elapsed":553,"user":{"displayName":"Eryth Brown","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjIz-NCzZfe1XlbcALsOgtnSkfWDHmAvoBVC2qS=s64","userId":"01967948615460729965"}},"outputId":"9532ffd1-8d52-4b34-b11d-b81a6e14f2b7"},"source":["!nvidia-smi -L"],"execution_count":1,"outputs":[{"output_type":"stream","text":["GPU 0: Tesla T4 (UUID: GPU-256b2290-36af-03cf-5a92-66ced509a847)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"LoE1A_vsRFVJ"},"source":["# Git Clone"]},{"cell_type":"code","metadata":{"id":"sQ0GLBd0RuKZ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1628952972639,"user_tz":-360,"elapsed":5949,"user":{"displayName":"Eryth Brown","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjIz-NCzZfe1XlbcALsOgtnSkfWDHmAvoBVC2qS=s64","userId":"01967948615460729965"}},"outputId":"ce323739-b36e-4476-a65b-21a4a84eb8d7"},"source":["!git clone https://github.com/jackyjsy/CVPR21Chal-SLR.git"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Cloning into 'CVPR21Chal-SLR'...\n","remote: Enumerating objects: 673, done.\u001b[K\n","remote: Counting objects: 100% (673/673), done.\u001b[K\n","remote: Compressing objects: 100% (531/531), done.\u001b[K\n","remote: Total 673 (delta 216), reused 585 (delta 130), pack-reused 0\u001b[K\n","Receiving objects: 100% (673/673), 51.71 MiB | 24.85 MiB/s, done.\n","Resolving deltas: 100% (216/216), done.\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"2YOoaHAVRHZY"},"source":["# Drive Mount"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fzXNBkoCtSiv","executionInfo":{"status":"ok","timestamp":1628953003864,"user_tz":-360,"elapsed":414,"user":{"displayName":"Eryth Brown","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjIz-NCzZfe1XlbcALsOgtnSkfWDHmAvoBVC2qS=s64","userId":"01967948615460729965"}},"outputId":"8da17103-0354-4ae7-dc27-a0dcb9e46798"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":4,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"Gf8YICWbSXfv"},"source":["# Preprocessed data copying"]},{"cell_type":"code","metadata":{"id":"mGliByqwtmWF","executionInfo":{"status":"ok","timestamp":1628953004555,"user_tz":-360,"elapsed":4,"user":{"displayName":"Eryth Brown","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjIz-NCzZfe1XlbcALsOgtnSkfWDHmAvoBVC2qS=s64","userId":"01967948615460729965"}}},"source":["import shutil\n","import os"],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"id":"PkUYDm3LSnTX","executionInfo":{"status":"ok","timestamp":1628953004944,"user_tz":-360,"elapsed":5,"user":{"displayName":"Eryth Brown","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjIz-NCzZfe1XlbcALsOgtnSkfWDHmAvoBVC2qS=s64","userId":"01967948615460729965"}}},"source":["data_type = 'joint'\n","#data_type = 'joint_motion'\n","#data_type = 'bone'\n","#data_type = 'bone_motion'"],"execution_count":6,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"gv9reaifC4hd"},"source":["# Train Data"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":36},"id":"X0p28MSftb9F","executionInfo":{"status":"ok","timestamp":1628953056279,"user_tz":-360,"elapsed":50439,"user":{"displayName":"Eryth Brown","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjIz-NCzZfe1XlbcALsOgtnSkfWDHmAvoBVC2qS=s64","userId":"01967948615460729965"}},"outputId":"aa874e02-e4b8-48c4-8c69-52e4c09f5994"},"source":["original = f'/content/drive/.shortcut-targets-by-id/1MwfX64WpeVyGAW0MhcasmbihkfgJwbtY/Darkpose_outputs/train_val/train_val_data_{data_type}.npy'\n","target = f'/content/data/sign/27_2/'\n","os.makedirs(os.path.dirname(target), exist_ok=True)\n","shutil.copy(original, target)\n","\n","original = f'/content/drive/.shortcut-targets-by-id/1MwfX64WpeVyGAW0MhcasmbihkfgJwbtY/Darkpose_outputs/train_val/train_val_labels.pkl'\n","target = f'/content/data/sign/27_2/'\n","os.makedirs(os.path.dirname(target), exist_ok=True)\n","shutil.copy(original, target)"],"execution_count":7,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'/content/data/sign/27_2/train_val_labels.pkl'"]},"metadata":{"tags":[]},"execution_count":7}]},{"cell_type":"markdown","metadata":{"id":"pkW104q6DYbf"},"source":["# Valid Data"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":36},"id":"m4rY1IvFKNCa","executionInfo":{"status":"ok","timestamp":1628953066367,"user_tz":-360,"elapsed":10103,"user":{"displayName":"Eryth Brown","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjIz-NCzZfe1XlbcALsOgtnSkfWDHmAvoBVC2qS=s64","userId":"01967948615460729965"}},"outputId":"897da78f-4f27-4cf5-b31f-8a60d8530def"},"source":["original = f'/content/drive/.shortcut-targets-by-id/1MwfX64WpeVyGAW0MhcasmbihkfgJwbtY/Darkpose_outputs/test_data_{data_type}.npy'\n","target = r'/content/data/sign/27_2/'\n","os.makedirs(os.path.dirname(target), exist_ok=True)\n","shutil.copy(original, target)\n","\n","original = r'/content/drive/.shortcut-targets-by-id/1MwfX64WpeVyGAW0MhcasmbihkfgJwbtY/Darkpose_outputs/test_label.pkl'\n","target = r'/content/data/sign/27_2/'\n","os.makedirs(os.path.dirname(target), exist_ok=True)\n","shutil.copy(original, target)"],"execution_count":8,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'/content/data/sign/27_2/test_label.pkl'"]},"metadata":{"tags":[]},"execution_count":8}]},{"cell_type":"markdown","metadata":{"id":"LN0FuKDIUHwa"},"source":["# Imports"]},{"cell_type":"code","metadata":{"id":"h2TSGeynmzMd","executionInfo":{"status":"ok","timestamp":1628953073770,"user_tz":-360,"elapsed":7408,"user":{"displayName":"Eryth Brown","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjIz-NCzZfe1XlbcALsOgtnSkfWDHmAvoBVC2qS=s64","userId":"01967948615460729965"}}},"source":["from __future__ import print_function\n","import argparse\n","from argparse import ArgumentParser,Namespace\n","import os\n","import time\n","import numpy as np\n","import yaml\n","import pickle\n","from collections import OrderedDict\n","# torch\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from torch.autograd import Variable\n","from tqdm import tqdm\n","import shutil\n","from torch.optim.lr_scheduler import ReduceLROnPlateau, MultiStepLR\n","import random\n","import inspect\n","import torch.backends.cudnn as cudnn\n","import torch.nn.functional as F"],"execution_count":9,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"PHdDisu1ULYu"},"source":["# Seed fixing"]},{"cell_type":"code","metadata":{"id":"YJaTr2dCRypd","executionInfo":{"status":"ok","timestamp":1628953073772,"user_tz":-360,"elapsed":16,"user":{"displayName":"Eryth Brown","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjIz-NCzZfe1XlbcALsOgtnSkfWDHmAvoBVC2qS=s64","userId":"01967948615460729965"}}},"source":["def init_seed(_):\n","    torch.cuda.manual_seed_all(1)\n","    torch.manual_seed(1)\n","    np.random.seed(1)\n","    random.seed(1)\n","    # torch.backends.cudnn.enabled = False\n","    torch.backends.cudnn.deterministic = True\n","    torch.backends.cudnn.benchmark = False"],"execution_count":10,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"lajR7EowV5J2"},"source":["# To import the data or model in load_data and load_model"]},{"cell_type":"code","metadata":{"id":"gdmXjH2zfaZf","executionInfo":{"status":"ok","timestamp":1628953073773,"user_tz":-360,"elapsed":13,"user":{"displayName":"Eryth Brown","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjIz-NCzZfe1XlbcALsOgtnSkfWDHmAvoBVC2qS=s64","userId":"01967948615460729965"}}},"source":["def import_class(name):\n","    components = name.split('.')\n","    mod = __import__(components[0])  # import return model\n","    for comp in components[1:]:\n","        mod = getattr(mod, comp)\n","    return mod"],"execution_count":11,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"-UEE1YcuVWZF"},"source":["# Main Class\n","\n","Ami only line 247 nije nije disi\n","\n","to create the saving directory"]},{"cell_type":"code","metadata":{"id":"t-1dCIbpeJQK","executionInfo":{"status":"ok","timestamp":1628953074907,"user_tz":-360,"elapsed":1144,"user":{"displayName":"Eryth Brown","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjIz-NCzZfe1XlbcALsOgtnSkfWDHmAvoBVC2qS=s64","userId":"01967948615460729965"}}},"source":["class Processor():\n","    \"\"\" \n","        Processor for Skeleton-based Action Recgnition\n","    \"\"\"\n","\n","    def __init__(self, arg):\n","\n","        arg.model_saved_name = f\"/content/drive/MyDrive/Colab Notebooks/CVPR21-Bh/Final_train/finetune/{data_type}/save_models/\"+ arg.Experiment_name\n","        arg.work_dir = f\"/content/drive/MyDrive/Colab Notebooks/CVPR21-Bh/Final_train/finetune/{data_type}/work_dir/\" + arg.Experiment_name\n","        self.arg = arg\n","        self.save_arg()\n","        if arg.phase == 'train':\n","            if not arg.train_feeder_args['debug']:\n","                if os.path.isdir(arg.model_saved_name):\n","                    print('log_dir: ', arg.model_saved_name, 'already exist')\n","                    answer = input('delete it? y/n:')\n","                    if answer == 'y':\n","                        shutil.rmtree(arg.model_saved_name)\n","                        print('Dir removed: ', arg.model_saved_name)\n","                        input(\n","                            'Refresh the website of tensorboard by pressing any keys')\n","                    else:\n","                        print('Dir not removed: ', arg.model_saved_name)\n","\n","        self.global_step = 0\n","        self.load_model()\n","        self.load_optimizer()\n","        self.load_data()\n","        self.lr = self.arg.base_lr\n","        self.best_acc = 0\n","\n","    def load_data(self):\n","        Feeder = import_class(self.arg.feeder)\n","        self.data_loader = dict()\n","        if self.arg.phase == 'train':\n","            self.data_loader['train'] = torch.utils.data.DataLoader(\n","                dataset=Feeder(**self.arg.train_feeder_args),\n","                batch_size=self.arg.batch_size,\n","                shuffle=True,\n","                num_workers=self.arg.num_worker,\n","                drop_last=True,\n","                worker_init_fn=init_seed)\n","        self.data_loader['test'] = torch.utils.data.DataLoader(\n","            dataset=Feeder(**self.arg.test_feeder_args),\n","            batch_size=self.arg.test_batch_size,\n","            shuffle=False,\n","            num_workers=self.arg.num_worker,\n","            drop_last=False,\n","            worker_init_fn=init_seed)\n","\n","    def load_model(self):\n","        output_device = self.arg.device[0] if type(\n","            self.arg.device) is list else self.arg.device\n","        self.output_device = output_device\n","        Model = import_class(self.arg.model)\n","        shutil.copy2(inspect.getfile(Model), self.arg.work_dir)\n","        self.model = Model(**self.arg.model_args).cuda(output_device)\n","        # print(self.model)\n","        self.loss = nn.CrossEntropyLoss().cuda(output_device)\n","        # self.loss = LabelSmoothingCrossEntropy().cuda(output_device)\n","\n","        if self.arg.weights:\n","            self.print_log('Load weights from {}.'.format(self.arg.weights))\n","            if '.pkl' in self.arg.weights:\n","                with open(self.arg.weights, 'r') as f:\n","                    weights = pickle.load(f)\n","            else:\n","                weights = torch.load(self.arg.weights)\n","\n","            weights = OrderedDict(\n","                [[k.split('module.')[-1],\n","                  v.cuda(output_device)] for k, v in weights.items()])\n","\n","            for w in self.arg.ignore_weights:\n","                if weights.pop(w, None) is not None:\n","                    self.print_log('Sucessfully Remove Weights: {}.'.format(w))\n","                else:\n","                    self.print_log('Can Not Remove Weights: {}.'.format(w))\n","\n","            try:\n","                self.model.load_state_dict(weights)\n","            except:\n","                state = self.model.state_dict()\n","                diff = list(set(state.keys()).difference(set(weights.keys())))\n","                print('Can not find these weights:')\n","                for d in diff:\n","                    print('  ' + d)\n","                state.update(weights)\n","                self.model.load_state_dict(state)\n","\n","        if type(self.arg.device) is list:\n","            if len(self.arg.device) > 1:\n","                self.model = nn.DataParallel(\n","                    self.model,\n","                    device_ids=self.arg.device,\n","                    output_device=output_device)\n","\n","    def load_optimizer(self):\n","        if self.arg.optimizer == 'SGD':\n","\n","            params_dict = dict(self.model.named_parameters())\n","            params = []\n","\n","            for key, value in params_dict.items():\n","                decay_mult = 0.0 if 'bias' in key else 1.0\n","\n","                lr_mult = 1.0\n","                weight_decay = 1e-4\n","\n","                params += [{'params': value, 'lr': self.arg.base_lr, 'lr_mult': lr_mult,\n","                            'decay_mult': decay_mult, 'weight_decay': weight_decay}]\n","\n","            self.optimizer = optim.SGD(\n","                params,\n","                momentum=0.9,\n","                nesterov=self.arg.nesterov)\n","        elif self.arg.optimizer == 'Adam':\n","            self.optimizer = optim.Adam(\n","                self.model.parameters(),\n","                lr=self.arg.base_lr,\n","                weight_decay=self.arg.weight_decay)\n","        else:\n","            raise ValueError()\n","\n","        self.lr_scheduler = ReduceLROnPlateau(self.optimizer, mode='min', factor=0.1,\n","                                              patience=10, verbose=True,\n","                                              threshold=1e-4, threshold_mode='rel',\n","                                              cooldown=0)\n","\n","    def save_arg(self):\n","        # save arg\n","        arg_dict = vars(self.arg)\n","\n","        if not os.path.exists(self.arg.work_dir):\n","            os.makedirs(self.arg.work_dir)\n","            os.makedirs(self.arg.work_dir + '/eval_results')\n","\n","        with open('{}/config.yaml'.format(self.arg.work_dir), 'w') as f:\n","            yaml.dump(arg_dict, f)\n","\n","    def adjust_learning_rate(self, epoch):\n","        if self.arg.optimizer == 'SGD' or self.arg.optimizer == 'Adam':\n","            if epoch < self.arg.warm_up_epoch:\n","                lr = self.arg.base_lr * (epoch + 1) / self.arg.warm_up_epoch\n","            else:\n","                lr = self.arg.base_lr * (\n","                    0.1 ** np.sum(epoch >= np.array(self.arg.step)))\n","            for param_group in self.optimizer.param_groups:\n","                param_group['lr'] = lr\n","            return lr\n","        else:\n","            raise ValueError()\n","\n","    def print_time(self):\n","        localtime = time.asctime(time.localtime(time.time()))\n","        self.print_log(\"Local current time :  \" + localtime)\n","\n","    def print_log(self, str, print_time=True):\n","        if print_time:\n","            localtime = time.asctime(time.localtime(time.time()))\n","            str = \"[ \" + localtime + ' ] ' + str\n","        print(str)\n","        if self.arg.print_log:\n","            with open('{}/log.txt'.format(self.arg.work_dir), 'a') as f:\n","                print(str, file=f)\n","\n","    def record_time(self):\n","        self.cur_time = time.time()\n","        return self.cur_time\n","\n","    def split_time(self):\n","        split_time = time.time() - self.cur_time\n","        self.record_time()\n","        return split_time\n","\n","    def train(self, epoch, save_model=False):\n","        self.model.train()\n","        self.print_log('Training epoch: {}'.format(epoch + 1))\n","        loader = self.data_loader['train']\n","        self.adjust_learning_rate(epoch)\n","        loss_value = []\n","        self.record_time()\n","        timer = dict(dataloader=0.001, model=0.001, statistics=0.001)\n","        process = tqdm(loader)\n","        if epoch >= self.arg.only_train_epoch:\n","            print('only train part, require grad')\n","            for key, value in self.model.named_parameters():\n","                if 'DecoupleA' in key:\n","                    value.requires_grad = True\n","                    print(key + '-require grad')\n","        else:\n","            print('only train part, do not require grad')\n","            for key, value in self.model.named_parameters():\n","                if 'DecoupleA' in key:\n","                    value.requires_grad = False\n","                    print(key + '-not require grad')\n","        for batch_idx, (data, label, index) in enumerate(process):\n","            self.global_step += 1\n","            # get data\n","            data = Variable(data.float().cuda(\n","                self.output_device), requires_grad=False)\n","            label = Variable(label.long().cuda(\n","                self.output_device), requires_grad=False)\n","            timer['dataloader'] += self.split_time()\n","\n","            # forward\n","            if epoch < 100:\n","                keep_prob = -(1 - self.arg.keep_rate) / 100 * epoch + 1.0\n","            else:\n","                keep_prob = self.arg.keep_rate\n","            output = self.model(data, keep_prob)\n","\n","            if isinstance(output, tuple):\n","                output, l1 = output\n","                l1 = l1.mean()\n","            else:\n","                l1 = 0\n","            loss = self.loss(output, label) + l1\n","\n","            self.optimizer.zero_grad()\n","            loss.backward()\n","            self.optimizer.step()\n","            loss_value.append(loss.data)\n","            timer['model'] += self.split_time()\n","\n","            value, predict_label = torch.max(output.data, 1)\n","            acc = torch.mean((predict_label == label.data).float())\n","\n","            self.lr = self.optimizer.param_groups[0]['lr']\n","\n","            if self.global_step % self.arg.log_interval == 0:\n","                self.print_log(\n","                    '\\tBatch({}/{}) done. Loss: {:.4f}  lr:{:.6f}'.format(\n","                        batch_idx, len(loader), loss.data, self.lr))\n","            timer['statistics'] += self.split_time()\n","\n","        # statistics of time consumption and loss\n","        proportion = {\n","            k: '{:02d}%'.format(int(round(v * 100 / sum(timer.values()))))\n","            for k, v in timer.items()\n","        }\n","\n","        state_dict = self.model.state_dict()\n","        weights = OrderedDict([[k.split('module.')[-1],\n","                                v.cpu()] for k, v in state_dict.items()])\n","\n","        os.makedirs(os.path.dirname(f'/content/drive/MyDrive/Colab Notebooks/CVPR21-Bh/Final_train/finetune/{data_type}/save_models/'), exist_ok=True)\n","        torch.save(weights, self.arg.model_saved_name +\n","                   '-' + str(epoch) + '.pt')\n","\n","    def eval(self, epoch, save_score=False, loader_name=['test'], wrong_file=None, result_file=None):\n","        if wrong_file is not None:\n","            f_w = open(wrong_file, 'w')\n","        if result_file is not None:\n","            f_r = open(result_file, 'w')\n","        self.model.eval()\n","        with torch.no_grad():\n","            self.print_log('Eval epoch: {}'.format(epoch + 1))\n","            for ln in loader_name:\n","                loss_value = []\n","                score_frag = []\n","                right_num_total = 0\n","                total_num = 0\n","                loss_total = 0\n","                step = 0\n","                process = tqdm(self.data_loader[ln])\n","\n","                for batch_idx, (data, label, index) in enumerate(process):\n","                    data = Variable(\n","                        data.float().cuda(self.output_device),\n","                        requires_grad=False)\n","                    label = Variable(\n","                        label.long().cuda(self.output_device),\n","                        requires_grad=False)\n","\n","                    with torch.no_grad():\n","                        output = self.model(data)\n","\n","                    if isinstance(output, tuple):\n","                        output, l1 = output\n","                        l1 = l1.mean()\n","                    else:\n","                        l1 = 0\n","                    loss = self.loss(output, label)\n","                    score_frag.append(output.data.cpu().numpy())\n","                    loss_value.append(loss.data.cpu().numpy())\n","\n","                    _, predict_label = torch.max(output.data, 1)\n","                    step += 1\n","\n","                    if wrong_file is not None or result_file is not None:\n","                        predict = list(predict_label.cpu().numpy())\n","                        true = list(label.data.cpu().numpy())\n","                        for i, x in enumerate(predict):\n","                            if result_file is not None:\n","                                f_r.write(str(x) + ',' + str(true[i]) + '\\n')\n","                            if x != true[i] and wrong_file is not None:\n","                                f_w.write(str(index[i]) + ',' +\n","                                        str(x) + ',' + str(true[i]) + '\\n')\n","                score = np.concatenate(score_frag)\n","\n","                if 'UCLA' in arg.Experiment_name:\n","                    self.data_loader[ln].dataset.sample_name = np.arange(\n","                        len(score))\n","\n","                accuracy = self.data_loader[ln].dataset.top_k(score, 1)\n","                if accuracy > self.best_acc:\n","                    self.best_acc = accuracy\n","                    score_dict = dict(\n","                        zip(self.data_loader[ln].dataset.sample_name, score))\n","\n","                    with open(f'/content/drive/MyDrive/Colab Notebooks/CVPR21-Bh/Final_train/finetune/{data_type}/work_dir/' + arg.Experiment_name + '/eval_results/best_acc' + '.pkl'.format(\n","                            epoch, accuracy), 'wb') as f:\n","                        pickle.dump(score_dict, f)\n","\n","                print('Eval Accuracy: ', accuracy,\n","                    ' model: ', self.arg.model_saved_name)\n","\n","                score_dict = dict(\n","                    zip(self.data_loader[ln].dataset.sample_name, score))\n","                self.print_log('\\tMean {} loss of {} batches: {}.'.format(\n","                    ln, len(self.data_loader[ln]), np.mean(loss_value)))\n","                for k in self.arg.show_topk:\n","                    self.print_log('\\tTop{}: {:.2f}%'.format(\n","                        k, 100 * self.data_loader[ln].dataset.top_k(score, k)))\n","\n","                with open(f'/content/drive/MyDrive/Colab Notebooks/CVPR21-Bh/Final_train/finetune/{data_type}/work_dir/' + arg.Experiment_name + '/eval_results/epoch_' + str(epoch) + '_' + str(accuracy) + '.pkl'.format(\n","                        epoch, accuracy), 'wb') as f:\n","                    pickle.dump(score_dict, f)\n","        return np.mean(loss_value)\n","    def start(self):\n","        if self.arg.phase == 'train':\n","            self.print_log('Parameters:\\n{}\\n'.format(str(vars(self.arg))))\n","            self.global_step = self.arg.start_epoch * \\\n","                len(self.data_loader['train']) / self.arg.batch_size\n","            for epoch in range(self.arg.start_epoch, self.arg.num_epoch):\n","                save_model = ((epoch + 1) % self.arg.save_interval == 0) or (\n","                    epoch + 1 == self.arg.num_epoch)\n","\n","                self.train(epoch, save_model=save_model)\n","\n","                val_loss = self.eval(\n","                    epoch,\n","                    save_score=self.arg.save_score,\n","                    loader_name=['test'])\n","\n","                # self.lr_scheduler.step(val_loss)\n","\n","            print('best accuracy: ', self.best_acc,\n","                  ' model_name: ', self.arg.model_saved_name)\n","\n","        elif self.arg.phase == 'test':\n","            if not self.arg.test_feeder_args['debug']:\n","                wf = self.arg.model_saved_name + '_wrong.txt'\n","                rf = self.arg.model_saved_name + '_right.txt'\n","            else:\n","                wf = rf = None\n","            if self.arg.weights is None:\n","                raise ValueError('Please appoint --weights.')\n","            self.arg.print_log = False\n","            self.print_log('Model:   {}.'.format(self.arg.model))\n","            self.print_log('Weights: {}.'.format(self.arg.weights))\n","            self.eval(epoch=self.arg.start_epoch, save_score=self.arg.save_score,\n","                      loader_name=['test'], wrong_file=wf, result_file=rf)\n","            self.print_log('Done.\\n')"],"execution_count":12,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"hS0r2JIOWpek"},"source":["# Passed Arguments"]},{"cell_type":"code","metadata":{"id":"066bp_UieZYs","executionInfo":{"status":"ok","timestamp":1628953770246,"user_tz":-360,"elapsed":402,"user":{"displayName":"Eryth Brown","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjIz-NCzZfe1XlbcALsOgtnSkfWDHmAvoBVC2qS=s64","userId":"01967948615460729965"}}},"source":["arg = Namespace(\n","    Experiment_name=f'{data_type}_27_2_finetune', \n","    base_lr=0.01, \n","    batch_size=64, \n","    config=f'/content/CVPR21Chal-SLR/SL-GCN/config/sign/finetune/train_{data_type}.yaml', \n","    device=[0], \n","    eval_interval=5, \n","    feeder='feeders.feeder.Feeder', \n","    groups=8, \n","    ignore_weights=[], \n","    keep_rate=0.9, \n","    log_interval=100, \n","    model='model.decouple_gcn_attn.Model', \n","    model_args={\n","        'num_class': 226, \n","        'num_point': 27, \n","        'num_person': 1, \n","        'graph': 'graph.sign_27.Graph', \n","        'groups': 16, \n","        'block_size': 41, \n","        'graph_args': {'labeling_mode': 'spatial'}\n","    }, \n","    model_saved_name='', \n","    nesterov=True, \n","    num_epoch=100, \n","    num_worker=32, \n","    only_train_epoch=1, \n","    only_train_part=True, \n","    optimizer='SGD', \n","    phase='train', \n","    print_log=True, \n","    save_interval=2, \n","    save_score=False, \n","    seed=1, \n","    show_topk=[1, 5], \n","    start_epoch=0, ###############################################################\n","    step=[50], \n","    test_batch_size=64, \n","    test_feeder_args={\n","        'data_path': f'/content/data/sign/27_2/test_data_{data_type}.npy', \n","        'label_path': f'/content/data/sign/27_2/test_label.pkl', \n","        'random_mirror': False, \n","        'normalization': True\n","    }, \n","    train_feeder_args={\n","        'data_path': f'/content/data/sign/27_2/train_val_data_{data_type}.npy', \n","        'label_path': f'/content/data/sign/27_2/train_val_labels.pkl', \n","        'debug': False, \n","        'random_choose': True, \n","        'window_size': 100, \n","        'random_shift': True, \n","        'normalization': True, \n","        'random_mirror': True, \n","        'random_mirror_p': 0.5, \n","        'is_vector': False\n","    }, \n","    warm_up_epoch=0, \n","    weight_decay=0.0001, \n","    ##############################################\n","    # To continue use specific path else None    #\n","    ##############################################\n","    weights=f'/content/drive/MyDrive/Colab Notebooks/CVPR21-Bh/Final_train/{data_type}/save_models/sign_{data_type}_final-196.pt', \n","    work_dir='./work_dir/temp'\n",")"],"execution_count":16,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"6u0wbvo6X5h6"},"source":["# Main cell to run\n","Personal suggestion:\n","\n","Ei cell ta ekta copy koire run koris as amader onek baar e train korte hobe and re run korle prev output erase hoye jay.\n","\n","Also koy step por por latest .pt file ta nije nije download koire nis just in case."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"83NBgJX-WDwt","outputId":"861b8fed-de05-4367-b174-438d19cbbff5"},"source":["%cd /content/CVPR21Chal-SLR/SL-GCN\n","init_seed(0)\n","processor = Processor(arg)\n","processor.start()\n","%cd /content"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/content/CVPR21Chal-SLR/SL-GCN\n","Attention Enabled!\n","Attention Enabled!\n","Attention Enabled!\n","Attention Enabled!\n","Attention Enabled!\n","Attention Enabled!\n","Attention Enabled!\n","Attention Enabled!\n","Attention Enabled!\n","Attention Enabled!\n","[ Sat Aug 14 15:09:33 2021 ] Load weights from /content/drive/MyDrive/Colab Notebooks/CVPR21-Bh/Final_train/joint/save_models/sign_joint_final-196.pt.\n"],"name":"stdout"},{"output_type":"stream","text":["/content/CVPR21Chal-SLR/SL-GCN/model/decouple_gcn_attn.py:29: UserWarning: nn.init.kaiming_normal is now deprecated in favor of nn.init.kaiming_normal_.\n","  nn.init.kaiming_normal(conv.weight, mode='fan_out')\n","/content/CVPR21Chal-SLR/SL-GCN/model/decouple_gcn_attn.py:30: UserWarning: nn.init.constant is now deprecated in favor of nn.init.constant_.\n","  nn.init.constant(conv.bias, 0)\n","/content/CVPR21Chal-SLR/SL-GCN/model/decouple_gcn_attn.py:34: UserWarning: nn.init.constant is now deprecated in favor of nn.init.constant_.\n","  nn.init.constant(bn.weight, scale)\n","/content/CVPR21Chal-SLR/SL-GCN/model/decouple_gcn_attn.py:35: UserWarning: nn.init.constant is now deprecated in favor of nn.init.constant_.\n","  nn.init.constant(bn.bias, 0)\n","/content/CVPR21Chal-SLR/SL-GCN/model/decouple_gcn_attn.py:113: UserWarning: nn.init.constant is now deprecated in favor of nn.init.constant_.\n","  nn.init.constant(self.Linear_bias, 1e-6)\n","/content/CVPR21Chal-SLR/SL-GCN/model/decouple_gcn_attn.py:119: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  eye_array), requires_grad=False, device='cuda'), requires_grad=False)  # [c,25,25]\n","/content/CVPR21Chal-SLR/SL-GCN/model/decouple_gcn_attn.py:252: UserWarning: nn.init.normal is now deprecated in favor of nn.init.normal_.\n","  nn.init.normal(self.fc.weight, 0, math.sqrt(2. / num_class))\n"],"name":"stderr"},{"output_type":"stream","text":["32560\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 32 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n"],"name":"stderr"},{"output_type":"stream","text":["3742\n","[ Sat Aug 14 15:09:44 2021 ] Parameters:\n","{'Experiment_name': 'joint_27_2_finetune', 'base_lr': 0.01, 'batch_size': 64, 'config': '/content/CVPR21Chal-SLR/SL-GCN/config/sign/finetune/train_joint.yaml', 'device': [0], 'eval_interval': 5, 'feeder': 'feeders.feeder.Feeder', 'groups': 8, 'ignore_weights': [], 'keep_rate': 0.9, 'log_interval': 100, 'model': 'model.decouple_gcn_attn.Model', 'model_args': {'num_class': 226, 'num_point': 27, 'num_person': 1, 'graph': 'graph.sign_27.Graph', 'groups': 16, 'block_size': 41, 'graph_args': {'labeling_mode': 'spatial'}}, 'model_saved_name': '/content/drive/MyDrive/Colab Notebooks/CVPR21-Bh/Final_train/finetune/joint/save_models/joint_27_2_finetune', 'nesterov': True, 'num_epoch': 100, 'num_worker': 32, 'only_train_epoch': 1, 'only_train_part': True, 'optimizer': 'SGD', 'phase': 'train', 'print_log': True, 'save_interval': 2, 'save_score': False, 'seed': 1, 'show_topk': [1, 5], 'start_epoch': 0, 'step': [50], 'test_batch_size': 64, 'test_feeder_args': {'data_path': '/content/data/sign/27_2/test_data_joint.npy', 'label_path': '/content/data/sign/27_2/test_label.pkl', 'random_mirror': False, 'normalization': True}, 'train_feeder_args': {'data_path': '/content/data/sign/27_2/train_val_data_joint.npy', 'label_path': '/content/data/sign/27_2/train_val_labels.pkl', 'debug': False, 'random_choose': True, 'window_size': 100, 'random_shift': True, 'normalization': True, 'random_mirror': True, 'random_mirror_p': 0.5, 'is_vector': False}, 'warm_up_epoch': 0, 'weight_decay': 0.0001, 'weights': '/content/drive/MyDrive/Colab Notebooks/CVPR21-Bh/Final_train/joint/save_models/sign_joint_final-196.pt', 'work_dir': '/content/drive/MyDrive/Colab Notebooks/CVPR21-Bh/Final_train/finetune/joint/work_dir/joint_27_2_finetune'}\n","\n","[ Sat Aug 14 15:09:44 2021 ] Training epoch: 1\n"],"name":"stdout"},{"output_type":"stream","text":["\r  0%|          | 0/508 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["only train part, do not require grad\n","l1.gcn1.DecoupleA-not require grad\n","l2.gcn1.DecoupleA-not require grad\n","l3.gcn1.DecoupleA-not require grad\n","l4.gcn1.DecoupleA-not require grad\n","l5.gcn1.DecoupleA-not require grad\n","l6.gcn1.DecoupleA-not require grad\n","l7.gcn1.DecoupleA-not require grad\n","l8.gcn1.DecoupleA-not require grad\n","l9.gcn1.DecoupleA-not require grad\n","l10.gcn1.DecoupleA-not require grad\n"],"name":"stdout"},{"output_type":"stream","text":[" 20%|█▉        | 100/508 [01:22<05:33,  1.22it/s]"],"name":"stderr"},{"output_type":"stream","text":["[ Sat Aug 14 15:11:07 2021 ] \tBatch(99/508) done. Loss: 0.0532  lr:0.010000\n"],"name":"stdout"},{"output_type":"stream","text":[" 39%|███▉      | 200/508 [02:43<04:10,  1.23it/s]"],"name":"stderr"},{"output_type":"stream","text":["[ Sat Aug 14 15:12:28 2021 ] \tBatch(199/508) done. Loss: 0.0640  lr:0.010000\n"],"name":"stdout"},{"output_type":"stream","text":[" 59%|█████▉    | 300/508 [04:04<02:49,  1.23it/s]"],"name":"stderr"},{"output_type":"stream","text":["[ Sat Aug 14 15:13:49 2021 ] \tBatch(299/508) done. Loss: 0.0101  lr:0.010000\n"],"name":"stdout"},{"output_type":"stream","text":[" 79%|███████▊  | 400/508 [05:25<01:28,  1.22it/s]"],"name":"stderr"},{"output_type":"stream","text":["[ Sat Aug 14 15:15:10 2021 ] \tBatch(399/508) done. Loss: 0.0044  lr:0.010000\n"],"name":"stdout"},{"output_type":"stream","text":[" 98%|█████████▊| 500/508 [06:46<00:06,  1.23it/s]"],"name":"stderr"},{"output_type":"stream","text":["[ Sat Aug 14 15:16:31 2021 ] \tBatch(499/508) done. Loss: 0.0271  lr:0.010000\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 508/508 [06:54<00:00,  1.23it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["[ Sat Aug 14 15:16:38 2021 ] Eval epoch: 1\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 59/59 [00:27<00:00,  2.13it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["Eval Accuracy:  0.9086050240513095  model:  /content/drive/MyDrive/Colab Notebooks/CVPR21-Bh/Final_train/finetune/joint/save_models/joint_27_2_finetune\n","[ Sat Aug 14 15:17:06 2021 ] \tMean test loss of 59 batches: 0.38736680150032043.\n","[ Sat Aug 14 15:17:06 2021 ] \tTop1: 90.86%\n","[ Sat Aug 14 15:17:07 2021 ] \tTop5: 98.80%\n","[ Sat Aug 14 15:17:07 2021 ] Training epoch: 2\n"],"name":"stdout"},{"output_type":"stream","text":["\r  0%|          | 0/508 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["only train part, require grad\n","l1.gcn1.DecoupleA-require grad\n","l2.gcn1.DecoupleA-require grad\n","l3.gcn1.DecoupleA-require grad\n","l4.gcn1.DecoupleA-require grad\n","l5.gcn1.DecoupleA-require grad\n","l6.gcn1.DecoupleA-require grad\n","l7.gcn1.DecoupleA-require grad\n","l8.gcn1.DecoupleA-require grad\n","l9.gcn1.DecoupleA-require grad\n","l10.gcn1.DecoupleA-require grad\n"],"name":"stdout"},{"output_type":"stream","text":["/content/CVPR21Chal-SLR/SL-GCN/model/dropSke.py:29: UserWarning: undefined skeleton graph\n","  warnings.warn('undefined skeleton graph')\n","/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:652: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)\n","  return torch.max_pool1d(input, kernel_size, stride, padding, dilation, ceil_mode)\n"," 18%|█▊        | 92/508 [01:26<06:23,  1.09it/s]"],"name":"stderr"},{"output_type":"stream","text":["[ Sat Aug 14 15:18:33 2021 ] \tBatch(91/508) done. Loss: 0.0041  lr:0.010000\n"],"name":"stdout"},{"output_type":"stream","text":[" 38%|███▊      | 192/508 [02:59<04:52,  1.08it/s]"],"name":"stderr"},{"output_type":"stream","text":["[ Sat Aug 14 15:20:06 2021 ] \tBatch(191/508) done. Loss: 0.0151  lr:0.010000\n"],"name":"stdout"},{"output_type":"stream","text":[" 57%|█████▋    | 292/508 [04:31<03:19,  1.08it/s]"],"name":"stderr"},{"output_type":"stream","text":["[ Sat Aug 14 15:21:38 2021 ] \tBatch(291/508) done. Loss: 0.0036  lr:0.010000\n"],"name":"stdout"},{"output_type":"stream","text":[" 77%|███████▋  | 392/508 [06:03<01:47,  1.08it/s]"],"name":"stderr"},{"output_type":"stream","text":["[ Sat Aug 14 15:23:10 2021 ] \tBatch(391/508) done. Loss: 0.0062  lr:0.010000\n"],"name":"stdout"},{"output_type":"stream","text":[" 97%|█████████▋| 492/508 [07:35<00:14,  1.08it/s]"],"name":"stderr"},{"output_type":"stream","text":["[ Sat Aug 14 15:24:42 2021 ] \tBatch(491/508) done. Loss: 0.0547  lr:0.010000\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 508/508 [07:51<00:00,  1.08it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["[ Sat Aug 14 15:24:58 2021 ] Eval epoch: 2\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 59/59 [00:27<00:00,  2.15it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["Eval Accuracy:  0.9160876536611438  model:  /content/drive/MyDrive/Colab Notebooks/CVPR21-Bh/Final_train/finetune/joint/save_models/joint_27_2_finetune\n","[ Sat Aug 14 15:25:26 2021 ] \tMean test loss of 59 batches: 0.37363848090171814.\n","[ Sat Aug 14 15:25:26 2021 ] \tTop1: 91.61%\n","[ Sat Aug 14 15:25:26 2021 ] \tTop5: 98.85%\n","[ Sat Aug 14 15:25:26 2021 ] Training epoch: 3\n"],"name":"stdout"},{"output_type":"stream","text":["\r  0%|          | 0/508 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["only train part, require grad\n","l1.gcn1.DecoupleA-require grad\n","l2.gcn1.DecoupleA-require grad\n","l3.gcn1.DecoupleA-require grad\n","l4.gcn1.DecoupleA-require grad\n","l5.gcn1.DecoupleA-require grad\n","l6.gcn1.DecoupleA-require grad\n","l7.gcn1.DecoupleA-require grad\n","l8.gcn1.DecoupleA-require grad\n","l9.gcn1.DecoupleA-require grad\n","l10.gcn1.DecoupleA-require grad\n"],"name":"stdout"},{"output_type":"stream","text":[" 17%|█▋        | 84/508 [01:19<06:30,  1.08it/s]"],"name":"stderr"},{"output_type":"stream","text":["[ Sat Aug 14 15:26:46 2021 ] \tBatch(83/508) done. Loss: 0.0206  lr:0.010000\n"],"name":"stdout"},{"output_type":"stream","text":[" 36%|███▌      | 184/508 [02:51<04:59,  1.08it/s]"],"name":"stderr"},{"output_type":"stream","text":["[ Sat Aug 14 15:28:18 2021 ] \tBatch(183/508) done. Loss: 0.0183  lr:0.010000\n"],"name":"stdout"},{"output_type":"stream","text":[" 56%|█████▌    | 284/508 [04:24<03:26,  1.08it/s]"],"name":"stderr"},{"output_type":"stream","text":["[ Sat Aug 14 15:29:50 2021 ] \tBatch(283/508) done. Loss: 0.0489  lr:0.010000\n"],"name":"stdout"},{"output_type":"stream","text":[" 76%|███████▌  | 384/508 [05:56<01:54,  1.08it/s]"],"name":"stderr"},{"output_type":"stream","text":["[ Sat Aug 14 15:31:22 2021 ] \tBatch(383/508) done. Loss: 0.0050  lr:0.010000\n"],"name":"stdout"},{"output_type":"stream","text":[" 95%|█████████▌| 484/508 [07:28<00:22,  1.08it/s]"],"name":"stderr"},{"output_type":"stream","text":["[ Sat Aug 14 15:32:55 2021 ] \tBatch(483/508) done. Loss: 0.0113  lr:0.010000\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 508/508 [07:51<00:00,  1.08it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["[ Sat Aug 14 15:33:18 2021 ] Eval epoch: 3\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 59/59 [00:27<00:00,  2.14it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["Eval Accuracy:  0.9155531801175841  model:  /content/drive/MyDrive/Colab Notebooks/CVPR21-Bh/Final_train/finetune/joint/save_models/joint_27_2_finetune\n","[ Sat Aug 14 15:33:45 2021 ] \tMean test loss of 59 batches: 0.364346444606781.\n","[ Sat Aug 14 15:33:46 2021 ] \tTop1: 91.56%\n","[ Sat Aug 14 15:33:46 2021 ] \tTop5: 98.98%\n","[ Sat Aug 14 15:33:46 2021 ] Training epoch: 4\n"],"name":"stdout"},{"output_type":"stream","text":["\r  0%|          | 0/508 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["only train part, require grad\n","l1.gcn1.DecoupleA-require grad\n","l2.gcn1.DecoupleA-require grad\n","l3.gcn1.DecoupleA-require grad\n","l4.gcn1.DecoupleA-require grad\n","l5.gcn1.DecoupleA-require grad\n","l6.gcn1.DecoupleA-require grad\n","l7.gcn1.DecoupleA-require grad\n","l8.gcn1.DecoupleA-require grad\n","l9.gcn1.DecoupleA-require grad\n","l10.gcn1.DecoupleA-require grad\n"],"name":"stdout"},{"output_type":"stream","text":[" 15%|█▍        | 76/508 [01:12<06:38,  1.09it/s]"],"name":"stderr"},{"output_type":"stream","text":["[ Sat Aug 14 15:34:58 2021 ] \tBatch(75/508) done. Loss: 0.0041  lr:0.010000\n"],"name":"stdout"},{"output_type":"stream","text":[" 35%|███▍      | 176/508 [02:44<05:05,  1.09it/s]"],"name":"stderr"},{"output_type":"stream","text":["[ Sat Aug 14 15:36:30 2021 ] \tBatch(175/508) done. Loss: 0.0016  lr:0.010000\n"],"name":"stdout"},{"output_type":"stream","text":[" 54%|█████▍    | 276/508 [04:16<03:34,  1.08it/s]"],"name":"stderr"},{"output_type":"stream","text":["[ Sat Aug 14 15:38:02 2021 ] \tBatch(275/508) done. Loss: 0.0045  lr:0.010000\n"],"name":"stdout"},{"output_type":"stream","text":[" 74%|███████▍  | 376/508 [05:49<02:01,  1.08it/s]"],"name":"stderr"},{"output_type":"stream","text":["[ Sat Aug 14 15:39:35 2021 ] \tBatch(375/508) done. Loss: 0.0014  lr:0.010000\n"],"name":"stdout"},{"output_type":"stream","text":[" 94%|█████████▎| 476/508 [07:21<00:29,  1.08it/s]"],"name":"stderr"},{"output_type":"stream","text":["[ Sat Aug 14 15:41:07 2021 ] \tBatch(475/508) done. Loss: 0.0080  lr:0.010000\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 508/508 [07:51<00:00,  1.08it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["[ Sat Aug 14 15:41:38 2021 ] Eval epoch: 4\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 59/59 [00:27<00:00,  2.14it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["Eval Accuracy:  0.9160876536611438  model:  /content/drive/MyDrive/Colab Notebooks/CVPR21-Bh/Final_train/finetune/joint/save_models/joint_27_2_finetune\n","[ Sat Aug 14 15:42:05 2021 ] \tMean test loss of 59 batches: 0.3704976737499237.\n","[ Sat Aug 14 15:42:05 2021 ] \tTop1: 91.61%\n","[ Sat Aug 14 15:42:05 2021 ] \tTop5: 98.98%\n","[ Sat Aug 14 15:42:05 2021 ] Training epoch: 5\n"],"name":"stdout"},{"output_type":"stream","text":["\r  0%|          | 0/508 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["only train part, require grad\n","l1.gcn1.DecoupleA-require grad\n","l2.gcn1.DecoupleA-require grad\n","l3.gcn1.DecoupleA-require grad\n","l4.gcn1.DecoupleA-require grad\n","l5.gcn1.DecoupleA-require grad\n","l6.gcn1.DecoupleA-require grad\n","l7.gcn1.DecoupleA-require grad\n","l8.gcn1.DecoupleA-require grad\n","l9.gcn1.DecoupleA-require grad\n","l10.gcn1.DecoupleA-require grad\n"],"name":"stdout"},{"output_type":"stream","text":[" 13%|█▎        | 68/508 [01:04<06:46,  1.08it/s]"],"name":"stderr"},{"output_type":"stream","text":["[ Sat Aug 14 15:43:10 2021 ] \tBatch(67/508) done. Loss: 0.0006  lr:0.010000\n"],"name":"stdout"},{"output_type":"stream","text":[" 33%|███▎      | 168/508 [02:37<05:14,  1.08it/s]"],"name":"stderr"},{"output_type":"stream","text":["[ Sat Aug 14 15:44:43 2021 ] \tBatch(167/508) done. Loss: 0.0047  lr:0.010000\n"],"name":"stdout"},{"output_type":"stream","text":[" 53%|█████▎    | 268/508 [04:09<03:41,  1.08it/s]"],"name":"stderr"},{"output_type":"stream","text":["[ Sat Aug 14 15:46:15 2021 ] \tBatch(267/508) done. Loss: 0.0091  lr:0.010000\n"],"name":"stdout"},{"output_type":"stream","text":[" 72%|███████▏  | 368/508 [05:41<02:09,  1.08it/s]"],"name":"stderr"},{"output_type":"stream","text":["[ Sat Aug 14 15:47:47 2021 ] \tBatch(367/508) done. Loss: 0.0033  lr:0.010000\n"],"name":"stdout"},{"output_type":"stream","text":[" 92%|█████████▏| 468/508 [07:13<00:36,  1.08it/s]"],"name":"stderr"},{"output_type":"stream","text":["[ Sat Aug 14 15:49:19 2021 ] \tBatch(467/508) done. Loss: 0.0005  lr:0.010000\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 508/508 [07:51<00:00,  1.08it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["[ Sat Aug 14 15:49:57 2021 ] Eval epoch: 5\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 59/59 [00:27<00:00,  2.12it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["Eval Accuracy:  0.9102084446819882  model:  /content/drive/MyDrive/Colab Notebooks/CVPR21-Bh/Final_train/finetune/joint/save_models/joint_27_2_finetune\n","[ Sat Aug 14 15:50:25 2021 ] \tMean test loss of 59 batches: 0.38820260763168335.\n","[ Sat Aug 14 15:50:25 2021 ] \tTop1: 91.02%\n","[ Sat Aug 14 15:50:25 2021 ] \tTop5: 98.80%\n","[ Sat Aug 14 15:50:25 2021 ] Training epoch: 6\n"],"name":"stdout"},{"output_type":"stream","text":["\r  0%|          | 0/508 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["only train part, require grad\n","l1.gcn1.DecoupleA-require grad\n","l2.gcn1.DecoupleA-require grad\n","l3.gcn1.DecoupleA-require grad\n","l4.gcn1.DecoupleA-require grad\n","l5.gcn1.DecoupleA-require grad\n","l6.gcn1.DecoupleA-require grad\n","l7.gcn1.DecoupleA-require grad\n","l8.gcn1.DecoupleA-require grad\n","l9.gcn1.DecoupleA-require grad\n","l10.gcn1.DecoupleA-require grad\n"],"name":"stdout"},{"output_type":"stream","text":[" 12%|█▏        | 60/508 [00:57<06:54,  1.08it/s]"],"name":"stderr"},{"output_type":"stream","text":["[ Sat Aug 14 15:51:23 2021 ] \tBatch(59/508) done. Loss: 0.0023  lr:0.010000\n"],"name":"stdout"},{"output_type":"stream","text":[" 31%|███▏      | 160/508 [02:29<05:21,  1.08it/s]"],"name":"stderr"},{"output_type":"stream","text":["[ Sat Aug 14 15:52:55 2021 ] \tBatch(159/508) done. Loss: 0.0024  lr:0.010000\n"],"name":"stdout"},{"output_type":"stream","text":[" 51%|█████     | 260/508 [04:02<03:49,  1.08it/s]"],"name":"stderr"},{"output_type":"stream","text":["[ Sat Aug 14 15:54:28 2021 ] \tBatch(259/508) done. Loss: 0.0014  lr:0.010000\n"],"name":"stdout"},{"output_type":"stream","text":[" 71%|███████   | 360/508 [05:34<02:16,  1.08it/s]"],"name":"stderr"},{"output_type":"stream","text":["[ Sat Aug 14 15:56:00 2021 ] \tBatch(359/508) done. Loss: 0.0050  lr:0.010000\n"],"name":"stdout"},{"output_type":"stream","text":[" 91%|█████████ | 460/508 [07:06<00:44,  1.08it/s]"],"name":"stderr"},{"output_type":"stream","text":["[ Sat Aug 14 15:57:32 2021 ] \tBatch(459/508) done. Loss: 0.0022  lr:0.010000\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 508/508 [07:51<00:00,  1.08it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["[ Sat Aug 14 15:58:17 2021 ] Eval epoch: 6\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 59/59 [00:27<00:00,  2.14it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["Eval Accuracy:  0.9152859433458044  model:  /content/drive/MyDrive/Colab Notebooks/CVPR21-Bh/Final_train/finetune/joint/save_models/joint_27_2_finetune\n","[ Sat Aug 14 15:58:45 2021 ] \tMean test loss of 59 batches: 0.3731621205806732.\n","[ Sat Aug 14 15:58:45 2021 ] \tTop1: 91.53%\n","[ Sat Aug 14 15:58:45 2021 ] \tTop5: 99.01%\n","[ Sat Aug 14 15:58:45 2021 ] Training epoch: 7\n"],"name":"stdout"},{"output_type":"stream","text":["\r  0%|          | 0/508 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["only train part, require grad\n","l1.gcn1.DecoupleA-require grad\n","l2.gcn1.DecoupleA-require grad\n","l3.gcn1.DecoupleA-require grad\n","l4.gcn1.DecoupleA-require grad\n","l5.gcn1.DecoupleA-require grad\n","l6.gcn1.DecoupleA-require grad\n","l7.gcn1.DecoupleA-require grad\n","l8.gcn1.DecoupleA-require grad\n","l9.gcn1.DecoupleA-require grad\n","l10.gcn1.DecoupleA-require grad\n"],"name":"stdout"},{"output_type":"stream","text":[" 10%|█         | 52/508 [00:50<07:01,  1.08it/s]"],"name":"stderr"},{"output_type":"stream","text":["[ Sat Aug 14 15:59:35 2021 ] \tBatch(51/508) done. Loss: 0.0049  lr:0.010000\n"],"name":"stdout"},{"output_type":"stream","text":[" 30%|██▉       | 152/508 [02:22<05:28,  1.08it/s]"],"name":"stderr"},{"output_type":"stream","text":["[ Sat Aug 14 16:01:07 2021 ] \tBatch(151/508) done. Loss: 0.0018  lr:0.010000\n"],"name":"stdout"},{"output_type":"stream","text":[" 50%|████▉     | 252/508 [03:54<03:56,  1.08it/s]"],"name":"stderr"},{"output_type":"stream","text":["[ Sat Aug 14 16:02:40 2021 ] \tBatch(251/508) done. Loss: 0.0096  lr:0.010000\n"],"name":"stdout"},{"output_type":"stream","text":[" 69%|██████▉   | 352/508 [05:26<02:23,  1.09it/s]"],"name":"stderr"},{"output_type":"stream","text":["[ Sat Aug 14 16:04:12 2021 ] \tBatch(351/508) done. Loss: 0.0191  lr:0.010000\n"],"name":"stdout"},{"output_type":"stream","text":[" 89%|████████▉ | 452/508 [06:58<00:51,  1.09it/s]"],"name":"stderr"},{"output_type":"stream","text":["[ Sat Aug 14 16:05:44 2021 ] \tBatch(451/508) done. Loss: 0.0053  lr:0.010000\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 508/508 [07:50<00:00,  1.08it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["[ Sat Aug 14 16:06:36 2021 ] Eval epoch: 7\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 59/59 [00:27<00:00,  2.15it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["Eval Accuracy:  0.9168893639764831  model:  /content/drive/MyDrive/Colab Notebooks/CVPR21-Bh/Final_train/finetune/joint/save_models/joint_27_2_finetune\n","[ Sat Aug 14 16:07:04 2021 ] \tMean test loss of 59 batches: 0.37447628378868103.\n","[ Sat Aug 14 16:07:04 2021 ] \tTop1: 91.69%\n","[ Sat Aug 14 16:07:04 2021 ] \tTop5: 98.85%\n","[ Sat Aug 14 16:07:04 2021 ] Training epoch: 8\n"],"name":"stdout"},{"output_type":"stream","text":["\r  0%|          | 0/508 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["only train part, require grad\n","l1.gcn1.DecoupleA-require grad\n","l2.gcn1.DecoupleA-require grad\n","l3.gcn1.DecoupleA-require grad\n","l4.gcn1.DecoupleA-require grad\n","l5.gcn1.DecoupleA-require grad\n","l6.gcn1.DecoupleA-require grad\n","l7.gcn1.DecoupleA-require grad\n","l8.gcn1.DecoupleA-require grad\n","l9.gcn1.DecoupleA-require grad\n","l10.gcn1.DecoupleA-require grad\n"],"name":"stdout"},{"output_type":"stream","text":["  9%|▊         | 44/508 [00:42<07:05,  1.09it/s]"],"name":"stderr"},{"output_type":"stream","text":["[ Sat Aug 14 16:07:46 2021 ] \tBatch(43/508) done. Loss: 0.0025  lr:0.010000\n"],"name":"stdout"},{"output_type":"stream","text":[" 28%|██▊       | 144/508 [02:14<05:34,  1.09it/s]"],"name":"stderr"},{"output_type":"stream","text":["[ Sat Aug 14 16:09:18 2021 ] \tBatch(143/508) done. Loss: 0.0082  lr:0.010000\n"],"name":"stdout"},{"output_type":"stream","text":[" 48%|████▊     | 244/508 [03:45<04:03,  1.08it/s]"],"name":"stderr"},{"output_type":"stream","text":["[ Sat Aug 14 16:10:50 2021 ] \tBatch(243/508) done. Loss: 0.0029  lr:0.010000\n"],"name":"stdout"},{"output_type":"stream","text":[" 68%|██████▊   | 344/508 [05:17<02:30,  1.09it/s]"],"name":"stderr"},{"output_type":"stream","text":["[ Sat Aug 14 16:12:22 2021 ] \tBatch(343/508) done. Loss: 0.0049  lr:0.010000\n"],"name":"stdout"},{"output_type":"stream","text":[" 87%|████████▋ | 444/508 [06:49<00:58,  1.09it/s]"],"name":"stderr"},{"output_type":"stream","text":["[ Sat Aug 14 16:13:54 2021 ] \tBatch(443/508) done. Loss: 0.0003  lr:0.010000\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 508/508 [07:49<00:00,  1.08it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["[ Sat Aug 14 16:14:54 2021 ] Eval epoch: 8\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 59/59 [00:27<00:00,  2.15it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["Eval Accuracy:  0.9152859433458044  model:  /content/drive/MyDrive/Colab Notebooks/CVPR21-Bh/Final_train/finetune/joint/save_models/joint_27_2_finetune\n","[ Sat Aug 14 16:15:21 2021 ] \tMean test loss of 59 batches: 0.38028159737586975.\n","[ Sat Aug 14 16:15:21 2021 ] \tTop1: 91.53%\n","[ Sat Aug 14 16:15:21 2021 ] \tTop5: 98.77%\n","[ Sat Aug 14 16:15:21 2021 ] Training epoch: 9\n"],"name":"stdout"},{"output_type":"stream","text":["\r  0%|          | 0/508 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["only train part, require grad\n","l1.gcn1.DecoupleA-require grad\n","l2.gcn1.DecoupleA-require grad\n","l3.gcn1.DecoupleA-require grad\n","l4.gcn1.DecoupleA-require grad\n","l5.gcn1.DecoupleA-require grad\n","l6.gcn1.DecoupleA-require grad\n","l7.gcn1.DecoupleA-require grad\n","l8.gcn1.DecoupleA-require grad\n","l9.gcn1.DecoupleA-require grad\n","l10.gcn1.DecoupleA-require grad\n"],"name":"stdout"},{"output_type":"stream","text":["  7%|▋         | 36/508 [00:35<07:13,  1.09it/s]"],"name":"stderr"},{"output_type":"stream","text":["[ Sat Aug 14 16:15:57 2021 ] \tBatch(35/508) done. Loss: 0.0061  lr:0.010000\n"],"name":"stdout"},{"output_type":"stream","text":[" 27%|██▋       | 136/508 [02:06<05:41,  1.09it/s]"],"name":"stderr"},{"output_type":"stream","text":["[ Sat Aug 14 16:17:28 2021 ] \tBatch(135/508) done. Loss: 0.0039  lr:0.010000\n"],"name":"stdout"},{"output_type":"stream","text":[" 46%|████▋     | 236/508 [03:38<04:10,  1.08it/s]"],"name":"stderr"},{"output_type":"stream","text":["[ Sat Aug 14 16:19:00 2021 ] \tBatch(235/508) done. Loss: 0.0007  lr:0.010000\n"],"name":"stdout"},{"output_type":"stream","text":[" 66%|██████▌   | 336/508 [05:11<02:39,  1.08it/s]"],"name":"stderr"},{"output_type":"stream","text":["[ Sat Aug 14 16:20:32 2021 ] \tBatch(335/508) done. Loss: 0.0017  lr:0.010000\n"],"name":"stdout"},{"output_type":"stream","text":[" 86%|████████▌ | 436/508 [06:43<01:06,  1.08it/s]"],"name":"stderr"},{"output_type":"stream","text":["[ Sat Aug 14 16:22:05 2021 ] \tBatch(435/508) done. Loss: 0.0201  lr:0.010000\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 508/508 [07:50<00:00,  1.08it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["[ Sat Aug 14 16:23:12 2021 ] Eval epoch: 9\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 59/59 [00:27<00:00,  2.14it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["Eval Accuracy:  0.9163548904329236  model:  /content/drive/MyDrive/Colab Notebooks/CVPR21-Bh/Final_train/finetune/joint/save_models/joint_27_2_finetune\n","[ Sat Aug 14 16:23:40 2021 ] \tMean test loss of 59 batches: 0.38958534598350525.\n","[ Sat Aug 14 16:23:40 2021 ] \tTop1: 91.64%\n","[ Sat Aug 14 16:23:40 2021 ] \tTop5: 98.74%\n","[ Sat Aug 14 16:23:40 2021 ] Training epoch: 10\n"],"name":"stdout"},{"output_type":"stream","text":["\r  0%|          | 0/508 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["only train part, require grad\n","l1.gcn1.DecoupleA-require grad\n","l2.gcn1.DecoupleA-require grad\n","l3.gcn1.DecoupleA-require grad\n","l4.gcn1.DecoupleA-require grad\n","l5.gcn1.DecoupleA-require grad\n","l6.gcn1.DecoupleA-require grad\n","l7.gcn1.DecoupleA-require grad\n","l8.gcn1.DecoupleA-require grad\n","l9.gcn1.DecoupleA-require grad\n","l10.gcn1.DecoupleA-require grad\n"],"name":"stdout"},{"output_type":"stream","text":["  6%|▌         | 28/508 [00:28<07:25,  1.08it/s]"],"name":"stderr"},{"output_type":"stream","text":["[ Sat Aug 14 16:24:08 2021 ] \tBatch(27/508) done. Loss: 0.0023  lr:0.010000\n"],"name":"stdout"},{"output_type":"stream","text":[" 25%|██▌       | 128/508 [02:00<05:51,  1.08it/s]"],"name":"stderr"},{"output_type":"stream","text":["[ Sat Aug 14 16:25:40 2021 ] \tBatch(127/508) done. Loss: 0.0011  lr:0.010000\n"],"name":"stdout"},{"output_type":"stream","text":[" 45%|████▍     | 228/508 [03:32<04:19,  1.08it/s]"],"name":"stderr"},{"output_type":"stream","text":["[ Sat Aug 14 16:27:13 2021 ] \tBatch(227/508) done. Loss: 0.0018  lr:0.010000\n"],"name":"stdout"},{"output_type":"stream","text":[" 65%|██████▍   | 328/508 [05:04<02:46,  1.08it/s]"],"name":"stderr"},{"output_type":"stream","text":["[ Sat Aug 14 16:28:45 2021 ] \tBatch(327/508) done. Loss: 0.0020  lr:0.010000\n"],"name":"stdout"},{"output_type":"stream","text":[" 84%|████████▍ | 428/508 [06:37<01:14,  1.08it/s]"],"name":"stderr"},{"output_type":"stream","text":["[ Sat Aug 14 16:30:17 2021 ] \tBatch(427/508) done. Loss: 0.0022  lr:0.010000\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 508/508 [07:52<00:00,  1.08it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["[ Sat Aug 14 16:31:32 2021 ] Eval epoch: 10\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 59/59 [00:27<00:00,  2.13it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["Eval Accuracy:  0.9142169962586852  model:  /content/drive/MyDrive/Colab Notebooks/CVPR21-Bh/Final_train/finetune/joint/save_models/joint_27_2_finetune\n","[ Sat Aug 14 16:32:00 2021 ] \tMean test loss of 59 batches: 0.37655654549598694.\n","[ Sat Aug 14 16:32:00 2021 ] \tTop1: 91.42%\n","[ Sat Aug 14 16:32:00 2021 ] \tTop5: 98.88%\n","[ Sat Aug 14 16:32:00 2021 ] Training epoch: 11\n"],"name":"stdout"},{"output_type":"stream","text":["\r  0%|          | 0/508 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["only train part, require grad\n","l1.gcn1.DecoupleA-require grad\n","l2.gcn1.DecoupleA-require grad\n","l3.gcn1.DecoupleA-require grad\n","l4.gcn1.DecoupleA-require grad\n","l5.gcn1.DecoupleA-require grad\n","l6.gcn1.DecoupleA-require grad\n","l7.gcn1.DecoupleA-require grad\n","l8.gcn1.DecoupleA-require grad\n","l9.gcn1.DecoupleA-require grad\n","l10.gcn1.DecoupleA-require grad\n"],"name":"stdout"},{"output_type":"stream","text":["  4%|▍         | 20/508 [00:20<07:35,  1.07it/s]"],"name":"stderr"},{"output_type":"stream","text":["[ Sat Aug 14 16:32:21 2021 ] \tBatch(19/508) done. Loss: 0.0007  lr:0.010000\n"],"name":"stdout"},{"output_type":"stream","text":[" 24%|██▎       | 120/508 [01:52<05:59,  1.08it/s]"],"name":"stderr"},{"output_type":"stream","text":["[ Sat Aug 14 16:33:53 2021 ] \tBatch(119/508) done. Loss: 0.0055  lr:0.010000\n"],"name":"stdout"},{"output_type":"stream","text":[" 43%|████▎     | 220/508 [03:25<04:27,  1.08it/s]"],"name":"stderr"},{"output_type":"stream","text":["[ Sat Aug 14 16:35:26 2021 ] \tBatch(219/508) done. Loss: 0.0019  lr:0.010000\n"],"name":"stdout"},{"output_type":"stream","text":[" 63%|██████▎   | 320/508 [04:57<02:54,  1.08it/s]"],"name":"stderr"},{"output_type":"stream","text":["[ Sat Aug 14 16:36:58 2021 ] \tBatch(319/508) done. Loss: 0.0015  lr:0.010000\n"],"name":"stdout"},{"output_type":"stream","text":[" 83%|████████▎ | 420/508 [06:30<01:21,  1.08it/s]"],"name":"stderr"},{"output_type":"stream","text":["[ Sat Aug 14 16:38:30 2021 ] \tBatch(419/508) done. Loss: 0.0011  lr:0.010000\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 508/508 [07:52<00:00,  1.08it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["[ Sat Aug 14 16:39:53 2021 ] Eval epoch: 11\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 59/59 [00:27<00:00,  2.13it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["Eval Accuracy:  0.9150187065740246  model:  /content/drive/MyDrive/Colab Notebooks/CVPR21-Bh/Final_train/finetune/joint/save_models/joint_27_2_finetune\n","[ Sat Aug 14 16:40:21 2021 ] \tMean test loss of 59 batches: 0.38179439306259155.\n","[ Sat Aug 14 16:40:21 2021 ] \tTop1: 91.50%\n","[ Sat Aug 14 16:40:21 2021 ] \tTop5: 98.88%\n","[ Sat Aug 14 16:40:21 2021 ] Training epoch: 12\n"],"name":"stdout"},{"output_type":"stream","text":["\r  0%|          | 0/508 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["only train part, require grad\n","l1.gcn1.DecoupleA-require grad\n","l2.gcn1.DecoupleA-require grad\n","l3.gcn1.DecoupleA-require grad\n","l4.gcn1.DecoupleA-require grad\n","l5.gcn1.DecoupleA-require grad\n","l6.gcn1.DecoupleA-require grad\n","l7.gcn1.DecoupleA-require grad\n","l8.gcn1.DecoupleA-require grad\n","l9.gcn1.DecoupleA-require grad\n","l10.gcn1.DecoupleA-require grad\n"],"name":"stdout"},{"output_type":"stream","text":["  2%|▏         | 12/508 [00:13<07:43,  1.07it/s]"],"name":"stderr"},{"output_type":"stream","text":["[ Sat Aug 14 16:40:34 2021 ] \tBatch(11/508) done. Loss: 0.0020  lr:0.010000\n"],"name":"stdout"},{"output_type":"stream","text":[" 22%|██▏       | 112/508 [01:45<06:04,  1.09it/s]"],"name":"stderr"},{"output_type":"stream","text":["[ Sat Aug 14 16:42:06 2021 ] \tBatch(111/508) done. Loss: 0.0014  lr:0.010000\n"],"name":"stdout"},{"output_type":"stream","text":[" 42%|████▏     | 212/508 [03:17<04:34,  1.08it/s]"],"name":"stderr"},{"output_type":"stream","text":["[ Sat Aug 14 16:43:39 2021 ] \tBatch(211/508) done. Loss: 0.0016  lr:0.010000\n"],"name":"stdout"},{"output_type":"stream","text":[" 61%|██████▏   | 312/508 [04:50<03:01,  1.08it/s]"],"name":"stderr"},{"output_type":"stream","text":["[ Sat Aug 14 16:45:11 2021 ] \tBatch(311/508) done. Loss: 0.0131  lr:0.010000\n"],"name":"stdout"},{"output_type":"stream","text":[" 81%|████████  | 412/508 [06:22<01:28,  1.08it/s]"],"name":"stderr"},{"output_type":"stream","text":["[ Sat Aug 14 16:46:43 2021 ] \tBatch(411/508) done. Loss: 0.0022  lr:0.010000\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 508/508 [07:51<00:00,  1.08it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["[ Sat Aug 14 16:48:13 2021 ] Eval epoch: 12\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 59/59 [00:27<00:00,  2.13it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["Eval Accuracy:  0.9160876536611438  model:  /content/drive/MyDrive/Colab Notebooks/CVPR21-Bh/Final_train/finetune/joint/save_models/joint_27_2_finetune\n","[ Sat Aug 14 16:48:41 2021 ] \tMean test loss of 59 batches: 0.36766135692596436.\n","[ Sat Aug 14 16:48:41 2021 ] \tTop1: 91.61%\n","[ Sat Aug 14 16:48:41 2021 ] \tTop5: 98.77%\n","[ Sat Aug 14 16:48:41 2021 ] Training epoch: 13\n"],"name":"stdout"},{"output_type":"stream","text":["\r  0%|          | 0/508 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["only train part, require grad\n","l1.gcn1.DecoupleA-require grad\n","l2.gcn1.DecoupleA-require grad\n","l3.gcn1.DecoupleA-require grad\n","l4.gcn1.DecoupleA-require grad\n","l5.gcn1.DecoupleA-require grad\n","l6.gcn1.DecoupleA-require grad\n","l7.gcn1.DecoupleA-require grad\n","l8.gcn1.DecoupleA-require grad\n","l9.gcn1.DecoupleA-require grad\n","l10.gcn1.DecoupleA-require grad\n"],"name":"stdout"},{"output_type":"stream","text":["  1%|          | 4/508 [00:05<10:13,  1.22s/it]"],"name":"stderr"},{"output_type":"stream","text":["[ Sat Aug 14 16:48:47 2021 ] \tBatch(3/508) done. Loss: 0.0010  lr:0.010000\n"],"name":"stdout"},{"output_type":"stream","text":[" 20%|██        | 104/508 [01:38<06:12,  1.08it/s]"],"name":"stderr"},{"output_type":"stream","text":["[ Sat Aug 14 16:50:19 2021 ] \tBatch(103/508) done. Loss: 0.0019  lr:0.010000\n"],"name":"stdout"},{"output_type":"stream","text":[" 40%|████      | 204/508 [03:10<04:41,  1.08it/s]"],"name":"stderr"},{"output_type":"stream","text":["[ Sat Aug 14 16:51:51 2021 ] \tBatch(203/508) done. Loss: 0.0040  lr:0.010000\n"],"name":"stdout"},{"output_type":"stream","text":[" 60%|█████▉    | 304/508 [04:42<03:08,  1.08it/s]"],"name":"stderr"},{"output_type":"stream","text":["[ Sat Aug 14 16:53:23 2021 ] \tBatch(303/508) done. Loss: 0.0014  lr:0.010000\n"],"name":"stdout"},{"output_type":"stream","text":[" 80%|███████▉  | 404/508 [06:14<01:36,  1.08it/s]"],"name":"stderr"},{"output_type":"stream","text":["[ Sat Aug 14 16:54:56 2021 ] \tBatch(403/508) done. Loss: 0.0569  lr:0.010000\n"],"name":"stdout"},{"output_type":"stream","text":[" 99%|█████████▉| 504/508 [07:47<00:03,  1.08it/s]"],"name":"stderr"},{"output_type":"stream","text":["[ Sat Aug 14 16:56:28 2021 ] \tBatch(503/508) done. Loss: 0.0023  lr:0.010000\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 508/508 [07:51<00:00,  1.08it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["[ Sat Aug 14 16:56:33 2021 ] Eval epoch: 13\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 59/59 [00:27<00:00,  2.14it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["Eval Accuracy:  0.9163548904329236  model:  /content/drive/MyDrive/Colab Notebooks/CVPR21-Bh/Final_train/finetune/joint/save_models/joint_27_2_finetune\n","[ Sat Aug 14 16:57:00 2021 ] \tMean test loss of 59 batches: 0.36042699217796326.\n","[ Sat Aug 14 16:57:01 2021 ] \tTop1: 91.64%\n","[ Sat Aug 14 16:57:01 2021 ] \tTop5: 98.74%\n","[ Sat Aug 14 16:57:01 2021 ] Training epoch: 14\n"],"name":"stdout"},{"output_type":"stream","text":["\r  0%|          | 0/508 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["only train part, require grad\n","l1.gcn1.DecoupleA-require grad\n","l2.gcn1.DecoupleA-require grad\n","l3.gcn1.DecoupleA-require grad\n","l4.gcn1.DecoupleA-require grad\n","l5.gcn1.DecoupleA-require grad\n","l6.gcn1.DecoupleA-require grad\n","l7.gcn1.DecoupleA-require grad\n","l8.gcn1.DecoupleA-require grad\n","l9.gcn1.DecoupleA-require grad\n","l10.gcn1.DecoupleA-require grad\n"],"name":"stdout"},{"output_type":"stream","text":[" 19%|█▉        | 96/508 [01:30<06:19,  1.09it/s]"],"name":"stderr"},{"output_type":"stream","text":["[ Sat Aug 14 16:58:31 2021 ] \tBatch(95/508) done. Loss: 0.0021  lr:0.010000\n"],"name":"stdout"},{"output_type":"stream","text":[" 39%|███▊      | 196/508 [03:03<04:48,  1.08it/s]"],"name":"stderr"},{"output_type":"stream","text":["[ Sat Aug 14 17:00:04 2021 ] \tBatch(195/508) done. Loss: 0.0018  lr:0.010000\n"],"name":"stdout"},{"output_type":"stream","text":[" 58%|█████▊    | 296/508 [04:35<03:15,  1.08it/s]"],"name":"stderr"},{"output_type":"stream","text":["[ Sat Aug 14 17:01:36 2021 ] \tBatch(295/508) done. Loss: 0.0006  lr:0.010000\n"],"name":"stdout"},{"output_type":"stream","text":[" 78%|███████▊  | 396/508 [06:07<01:43,  1.08it/s]"],"name":"stderr"},{"output_type":"stream","text":["[ Sat Aug 14 17:03:08 2021 ] \tBatch(395/508) done. Loss: 0.0043  lr:0.010000\n"],"name":"stdout"},{"output_type":"stream","text":[" 98%|█████████▊| 496/508 [07:40<00:11,  1.08it/s]"],"name":"stderr"},{"output_type":"stream","text":["[ Sat Aug 14 17:04:41 2021 ] \tBatch(495/508) done. Loss: 0.0030  lr:0.010000\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 508/508 [07:52<00:00,  1.08it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["[ Sat Aug 14 17:04:53 2021 ] Eval epoch: 14\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 59/59 [00:27<00:00,  2.14it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["Eval Accuracy:  0.9200962052378407  model:  /content/drive/MyDrive/Colab Notebooks/CVPR21-Bh/Final_train/finetune/joint/save_models/joint_27_2_finetune\n","[ Sat Aug 14 17:05:21 2021 ] \tMean test loss of 59 batches: 0.3617406487464905.\n","[ Sat Aug 14 17:05:21 2021 ] \tTop1: 92.01%\n","[ Sat Aug 14 17:05:21 2021 ] \tTop5: 98.80%\n","[ Sat Aug 14 17:05:21 2021 ] Training epoch: 15\n"],"name":"stdout"},{"output_type":"stream","text":["\r  0%|          | 0/508 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["only train part, require grad\n","l1.gcn1.DecoupleA-require grad\n","l2.gcn1.DecoupleA-require grad\n","l3.gcn1.DecoupleA-require grad\n","l4.gcn1.DecoupleA-require grad\n","l5.gcn1.DecoupleA-require grad\n","l6.gcn1.DecoupleA-require grad\n","l7.gcn1.DecoupleA-require grad\n","l8.gcn1.DecoupleA-require grad\n","l9.gcn1.DecoupleA-require grad\n","l10.gcn1.DecoupleA-require grad\n"],"name":"stdout"},{"output_type":"stream","text":[" 17%|█▋        | 88/508 [01:23<06:28,  1.08it/s]"],"name":"stderr"},{"output_type":"stream","text":["[ Sat Aug 14 17:06:44 2021 ] \tBatch(87/508) done. Loss: 0.0135  lr:0.010000\n"],"name":"stdout"},{"output_type":"stream","text":[" 37%|███▋      | 188/508 [02:55<04:56,  1.08it/s]"],"name":"stderr"},{"output_type":"stream","text":["[ Sat Aug 14 17:08:16 2021 ] \tBatch(187/508) done. Loss: 0.0047  lr:0.010000\n"],"name":"stdout"},{"output_type":"stream","text":[" 57%|█████▋    | 288/508 [04:27<03:23,  1.08it/s]"],"name":"stderr"},{"output_type":"stream","text":["[ Sat Aug 14 17:09:49 2021 ] \tBatch(287/508) done. Loss: 0.0038  lr:0.010000\n"],"name":"stdout"},{"output_type":"stream","text":[" 76%|███████▋  | 388/508 [06:00<01:50,  1.08it/s]"],"name":"stderr"},{"output_type":"stream","text":["[ Sat Aug 14 17:11:21 2021 ] \tBatch(387/508) done. Loss: 0.0015  lr:0.010000\n"],"name":"stdout"},{"output_type":"stream","text":[" 96%|█████████▌| 488/508 [07:32<00:18,  1.08it/s]"],"name":"stderr"},{"output_type":"stream","text":["[ Sat Aug 14 17:12:53 2021 ] \tBatch(487/508) done. Loss: 0.0040  lr:0.010000\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 508/508 [07:51<00:00,  1.08it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["[ Sat Aug 14 17:13:13 2021 ] Eval epoch: 15\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 59/59 [00:27<00:00,  2.13it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["Eval Accuracy:  0.9187600213789417  model:  /content/drive/MyDrive/Colab Notebooks/CVPR21-Bh/Final_train/finetune/joint/save_models/joint_27_2_finetune\n","[ Sat Aug 14 17:13:41 2021 ] \tMean test loss of 59 batches: 0.35029104351997375.\n","[ Sat Aug 14 17:13:41 2021 ] \tTop1: 91.88%\n","[ Sat Aug 14 17:13:41 2021 ] \tTop5: 98.88%\n","[ Sat Aug 14 17:13:41 2021 ] Training epoch: 16\n"],"name":"stdout"},{"output_type":"stream","text":["\r  0%|          | 0/508 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["only train part, require grad\n","l1.gcn1.DecoupleA-require grad\n","l2.gcn1.DecoupleA-require grad\n","l3.gcn1.DecoupleA-require grad\n","l4.gcn1.DecoupleA-require grad\n","l5.gcn1.DecoupleA-require grad\n","l6.gcn1.DecoupleA-require grad\n","l7.gcn1.DecoupleA-require grad\n","l8.gcn1.DecoupleA-require grad\n","l9.gcn1.DecoupleA-require grad\n","l10.gcn1.DecoupleA-require grad\n"],"name":"stdout"},{"output_type":"stream","text":[" 16%|█▌        | 80/508 [01:16<06:34,  1.09it/s]"],"name":"stderr"},{"output_type":"stream","text":["[ Sat Aug 14 17:14:57 2021 ] \tBatch(79/508) done. Loss: 0.0024  lr:0.010000\n"],"name":"stdout"},{"output_type":"stream","text":[" 35%|███▌      | 180/508 [02:48<05:02,  1.08it/s]"],"name":"stderr"},{"output_type":"stream","text":["[ Sat Aug 14 17:16:29 2021 ] \tBatch(179/508) done. Loss: 0.1058  lr:0.010000\n"],"name":"stdout"},{"output_type":"stream","text":[" 55%|█████▌    | 280/508 [04:20<03:30,  1.08it/s]"],"name":"stderr"},{"output_type":"stream","text":["[ Sat Aug 14 17:18:02 2021 ] \tBatch(279/508) done. Loss: 0.0013  lr:0.010000\n"],"name":"stdout"},{"output_type":"stream","text":[" 75%|███████▍  | 380/508 [05:53<01:58,  1.08it/s]"],"name":"stderr"},{"output_type":"stream","text":["[ Sat Aug 14 17:19:34 2021 ] \tBatch(379/508) done. Loss: 0.0037  lr:0.010000\n"],"name":"stdout"},{"output_type":"stream","text":[" 94%|█████████▍| 480/508 [07:25<00:25,  1.08it/s]"],"name":"stderr"},{"output_type":"stream","text":["[ Sat Aug 14 17:21:06 2021 ] \tBatch(479/508) done. Loss: 0.0022  lr:0.010000\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 508/508 [07:52<00:00,  1.08it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["[ Sat Aug 14 17:21:33 2021 ] Eval epoch: 16\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 59/59 [00:27<00:00,  2.13it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["Eval Accuracy:  0.917156600748263  model:  /content/drive/MyDrive/Colab Notebooks/CVPR21-Bh/Final_train/finetune/joint/save_models/joint_27_2_finetune\n","[ Sat Aug 14 17:22:01 2021 ] \tMean test loss of 59 batches: 0.3718782067298889.\n","[ Sat Aug 14 17:22:01 2021 ] \tTop1: 91.72%\n","[ Sat Aug 14 17:22:01 2021 ] \tTop5: 98.72%\n","[ Sat Aug 14 17:22:01 2021 ] Training epoch: 17\n"],"name":"stdout"},{"output_type":"stream","text":["\r  0%|          | 0/508 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["only train part, require grad\n","l1.gcn1.DecoupleA-require grad\n","l2.gcn1.DecoupleA-require grad\n","l3.gcn1.DecoupleA-require grad\n","l4.gcn1.DecoupleA-require grad\n","l5.gcn1.DecoupleA-require grad\n","l6.gcn1.DecoupleA-require grad\n","l7.gcn1.DecoupleA-require grad\n","l8.gcn1.DecoupleA-require grad\n","l9.gcn1.DecoupleA-require grad\n","l10.gcn1.DecoupleA-require grad\n"],"name":"stdout"},{"output_type":"stream","text":[" 14%|█▍        | 72/508 [01:08<06:43,  1.08it/s]"],"name":"stderr"},{"output_type":"stream","text":["[ Sat Aug 14 17:23:10 2021 ] \tBatch(71/508) done. Loss: 0.0012  lr:0.010000\n"],"name":"stdout"},{"output_type":"stream","text":[" 34%|███▍      | 172/508 [02:40<05:10,  1.08it/s]"],"name":"stderr"},{"output_type":"stream","text":["[ Sat Aug 14 17:24:42 2021 ] \tBatch(171/508) done. Loss: 0.0069  lr:0.010000\n"],"name":"stdout"},{"output_type":"stream","text":[" 54%|█████▎    | 272/508 [04:13<03:38,  1.08it/s]"],"name":"stderr"},{"output_type":"stream","text":["[ Sat Aug 14 17:26:14 2021 ] \tBatch(271/508) done. Loss: 0.0025  lr:0.010000\n"],"name":"stdout"},{"output_type":"stream","text":[" 73%|███████▎  | 372/508 [05:45<02:06,  1.08it/s]"],"name":"stderr"},{"output_type":"stream","text":["[ Sat Aug 14 17:27:47 2021 ] \tBatch(371/508) done. Loss: 0.0028  lr:0.010000\n"],"name":"stdout"},{"output_type":"stream","text":[" 93%|█████████▎| 472/508 [07:17<00:33,  1.08it/s]"],"name":"stderr"},{"output_type":"stream","text":["[ Sat Aug 14 17:29:19 2021 ] \tBatch(471/508) done. Loss: 0.0009  lr:0.010000\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 508/508 [07:51<00:00,  1.08it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["[ Sat Aug 14 17:29:53 2021 ] Eval epoch: 17\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 59/59 [00:27<00:00,  2.13it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["Eval Accuracy:  0.9160876536611438  model:  /content/drive/MyDrive/Colab Notebooks/CVPR21-Bh/Final_train/finetune/joint/save_models/joint_27_2_finetune\n","[ Sat Aug 14 17:30:21 2021 ] \tMean test loss of 59 batches: 0.3624497056007385.\n","[ Sat Aug 14 17:30:21 2021 ] \tTop1: 91.61%\n","[ Sat Aug 14 17:30:21 2021 ] \tTop5: 98.69%\n","[ Sat Aug 14 17:30:21 2021 ] Training epoch: 18\n"],"name":"stdout"},{"output_type":"stream","text":["\r  0%|          | 0/508 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["only train part, require grad\n","l1.gcn1.DecoupleA-require grad\n","l2.gcn1.DecoupleA-require grad\n","l3.gcn1.DecoupleA-require grad\n","l4.gcn1.DecoupleA-require grad\n","l5.gcn1.DecoupleA-require grad\n","l6.gcn1.DecoupleA-require grad\n","l7.gcn1.DecoupleA-require grad\n","l8.gcn1.DecoupleA-require grad\n","l9.gcn1.DecoupleA-require grad\n","l10.gcn1.DecoupleA-require grad\n"],"name":"stdout"},{"output_type":"stream","text":[" 13%|█▎        | 64/508 [01:01<06:49,  1.08it/s]"],"name":"stderr"},{"output_type":"stream","text":["[ Sat Aug 14 17:31:22 2021 ] \tBatch(63/508) done. Loss: 0.0093  lr:0.010000\n"],"name":"stdout"},{"output_type":"stream","text":[" 32%|███▏      | 164/508 [02:33<05:18,  1.08it/s]"],"name":"stderr"},{"output_type":"stream","text":["[ Sat Aug 14 17:32:55 2021 ] \tBatch(163/508) done. Loss: 0.0027  lr:0.010000\n"],"name":"stdout"},{"output_type":"stream","text":[" 52%|█████▏    | 264/508 [04:05<03:46,  1.08it/s]"],"name":"stderr"},{"output_type":"stream","text":["[ Sat Aug 14 17:34:27 2021 ] \tBatch(263/508) done. Loss: 0.0027  lr:0.010000\n"],"name":"stdout"},{"output_type":"stream","text":[" 72%|███████▏  | 364/508 [05:38<02:12,  1.08it/s]"],"name":"stderr"},{"output_type":"stream","text":["[ Sat Aug 14 17:35:59 2021 ] \tBatch(363/508) done. Loss: 0.0005  lr:0.010000\n"],"name":"stdout"},{"output_type":"stream","text":[" 91%|█████████▏| 464/508 [07:10<00:40,  1.08it/s]"],"name":"stderr"},{"output_type":"stream","text":["[ Sat Aug 14 17:37:31 2021 ] \tBatch(463/508) done. Loss: 0.0016  lr:0.010000\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 508/508 [07:51<00:00,  1.08it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["[ Sat Aug 14 17:38:13 2021 ] Eval epoch: 18\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 59/59 [00:27<00:00,  2.14it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["Eval Accuracy:  0.9160876536611438  model:  /content/drive/MyDrive/Colab Notebooks/CVPR21-Bh/Final_train/finetune/joint/save_models/joint_27_2_finetune\n","[ Sat Aug 14 17:38:41 2021 ] \tMean test loss of 59 batches: 0.3664698302745819.\n","[ Sat Aug 14 17:38:41 2021 ] \tTop1: 91.61%\n","[ Sat Aug 14 17:38:41 2021 ] \tTop5: 98.82%\n","[ Sat Aug 14 17:38:41 2021 ] Training epoch: 19\n"],"name":"stdout"},{"output_type":"stream","text":["\r  0%|          | 0/508 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["only train part, require grad\n","l1.gcn1.DecoupleA-require grad\n","l2.gcn1.DecoupleA-require grad\n","l3.gcn1.DecoupleA-require grad\n","l4.gcn1.DecoupleA-require grad\n","l5.gcn1.DecoupleA-require grad\n","l6.gcn1.DecoupleA-require grad\n","l7.gcn1.DecoupleA-require grad\n","l8.gcn1.DecoupleA-require grad\n","l9.gcn1.DecoupleA-require grad\n","l10.gcn1.DecoupleA-require grad\n"],"name":"stdout"},{"output_type":"stream","text":[" 11%|█         | 56/508 [00:54<06:57,  1.08it/s]"],"name":"stderr"},{"output_type":"stream","text":["[ Sat Aug 14 17:39:35 2021 ] \tBatch(55/508) done. Loss: 0.0013  lr:0.010000\n"],"name":"stdout"},{"output_type":"stream","text":[" 31%|███       | 156/508 [02:26<05:24,  1.08it/s]"],"name":"stderr"},{"output_type":"stream","text":["[ Sat Aug 14 17:41:07 2021 ] \tBatch(155/508) done. Loss: 0.0013  lr:0.010000\n"],"name":"stdout"},{"output_type":"stream","text":[" 50%|█████     | 256/508 [03:58<03:52,  1.08it/s]"],"name":"stderr"},{"output_type":"stream","text":["[ Sat Aug 14 17:42:40 2021 ] \tBatch(255/508) done. Loss: 0.0042  lr:0.010000\n"],"name":"stdout"},{"output_type":"stream","text":[" 70%|███████   | 356/508 [05:30<02:20,  1.08it/s]"],"name":"stderr"},{"output_type":"stream","text":["[ Sat Aug 14 17:44:12 2021 ] \tBatch(355/508) done. Loss: 0.0041  lr:0.010000\n"],"name":"stdout"},{"output_type":"stream","text":[" 90%|████████▉ | 456/508 [07:02<00:47,  1.09it/s]"],"name":"stderr"},{"output_type":"stream","text":["[ Sat Aug 14 17:45:44 2021 ] \tBatch(455/508) done. Loss: 0.0012  lr:0.010000\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 508/508 [07:51<00:00,  1.08it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["[ Sat Aug 14 17:46:33 2021 ] Eval epoch: 19\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 59/59 [00:27<00:00,  2.14it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["Eval Accuracy:  0.915820416889364  model:  /content/drive/MyDrive/Colab Notebooks/CVPR21-Bh/Final_train/finetune/joint/save_models/joint_27_2_finetune\n","[ Sat Aug 14 17:47:01 2021 ] \tMean test loss of 59 batches: 0.36341819167137146.\n","[ Sat Aug 14 17:47:01 2021 ] \tTop1: 91.58%\n","[ Sat Aug 14 17:47:01 2021 ] \tTop5: 98.80%\n","[ Sat Aug 14 17:47:01 2021 ] Training epoch: 20\n"],"name":"stdout"},{"output_type":"stream","text":["\r  0%|          | 0/508 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["only train part, require grad\n","l1.gcn1.DecoupleA-require grad\n","l2.gcn1.DecoupleA-require grad\n","l3.gcn1.DecoupleA-require grad\n","l4.gcn1.DecoupleA-require grad\n","l5.gcn1.DecoupleA-require grad\n","l6.gcn1.DecoupleA-require grad\n","l7.gcn1.DecoupleA-require grad\n","l8.gcn1.DecoupleA-require grad\n","l9.gcn1.DecoupleA-require grad\n","l10.gcn1.DecoupleA-require grad\n"],"name":"stdout"},{"output_type":"stream","text":["  9%|▉         | 48/508 [00:46<07:05,  1.08it/s]"],"name":"stderr"},{"output_type":"stream","text":["[ Sat Aug 14 17:47:47 2021 ] \tBatch(47/508) done. Loss: 0.0020  lr:0.010000\n"],"name":"stdout"},{"output_type":"stream","text":[" 29%|██▉       | 148/508 [02:18<05:32,  1.08it/s]"],"name":"stderr"},{"output_type":"stream","text":["[ Sat Aug 14 17:49:19 2021 ] \tBatch(147/508) done. Loss: 0.0032  lr:0.010000\n"],"name":"stdout"},{"output_type":"stream","text":[" 49%|████▉     | 248/508 [03:50<04:00,  1.08it/s]"],"name":"stderr"},{"output_type":"stream","text":["[ Sat Aug 14 17:50:52 2021 ] \tBatch(247/508) done. Loss: 0.0122  lr:0.010000\n"],"name":"stdout"},{"output_type":"stream","text":[" 69%|██████▊   | 348/508 [05:23<02:27,  1.08it/s]"],"name":"stderr"},{"output_type":"stream","text":["[ Sat Aug 14 17:52:24 2021 ] \tBatch(347/508) done. Loss: 0.0018  lr:0.010000\n"],"name":"stdout"},{"output_type":"stream","text":[" 88%|████████▊ | 448/508 [06:55<00:55,  1.08it/s]"],"name":"stderr"},{"output_type":"stream","text":["[ Sat Aug 14 17:53:56 2021 ] \tBatch(447/508) done. Loss: 0.0017  lr:0.010000\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 508/508 [07:51<00:00,  1.08it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["[ Sat Aug 14 17:54:53 2021 ] Eval epoch: 20\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 59/59 [00:27<00:00,  2.14it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["Eval Accuracy:  0.9163548904329236  model:  /content/drive/MyDrive/Colab Notebooks/CVPR21-Bh/Final_train/finetune/joint/save_models/joint_27_2_finetune\n","[ Sat Aug 14 17:55:20 2021 ] \tMean test loss of 59 batches: 0.3644524812698364.\n","[ Sat Aug 14 17:55:20 2021 ] \tTop1: 91.64%\n","[ Sat Aug 14 17:55:20 2021 ] \tTop5: 98.74%\n","[ Sat Aug 14 17:55:20 2021 ] Training epoch: 21\n"],"name":"stdout"},{"output_type":"stream","text":["\r  0%|          | 0/508 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["only train part, require grad\n","l1.gcn1.DecoupleA-require grad\n","l2.gcn1.DecoupleA-require grad\n","l3.gcn1.DecoupleA-require grad\n","l4.gcn1.DecoupleA-require grad\n","l5.gcn1.DecoupleA-require grad\n","l6.gcn1.DecoupleA-require grad\n","l7.gcn1.DecoupleA-require grad\n","l8.gcn1.DecoupleA-require grad\n","l9.gcn1.DecoupleA-require grad\n","l10.gcn1.DecoupleA-require grad\n"],"name":"stdout"},{"output_type":"stream","text":["  8%|▊         | 40/508 [00:39<07:13,  1.08it/s]"],"name":"stderr"},{"output_type":"stream","text":["[ Sat Aug 14 17:55:59 2021 ] \tBatch(39/508) done. Loss: 0.0023  lr:0.010000\n"],"name":"stdout"},{"output_type":"stream","text":[" 28%|██▊       | 140/508 [02:11<05:40,  1.08it/s]"],"name":"stderr"},{"output_type":"stream","text":["[ Sat Aug 14 17:57:32 2021 ] \tBatch(139/508) done. Loss: 0.0069  lr:0.010000\n"],"name":"stdout"},{"output_type":"stream","text":[" 47%|████▋     | 240/508 [03:43<04:07,  1.08it/s]"],"name":"stderr"},{"output_type":"stream","text":["[ Sat Aug 14 17:59:04 2021 ] \tBatch(239/508) done. Loss: 0.0068  lr:0.010000\n"],"name":"stdout"},{"output_type":"stream","text":[" 67%|██████▋   | 340/508 [05:15<02:36,  1.07it/s]"],"name":"stderr"},{"output_type":"stream","text":["[ Sat Aug 14 18:00:36 2021 ] \tBatch(339/508) done. Loss: 0.0013  lr:0.010000\n"],"name":"stdout"},{"output_type":"stream","text":[" 87%|████████▋ | 440/508 [06:48<01:02,  1.08it/s]"],"name":"stderr"},{"output_type":"stream","text":["[ Sat Aug 14 18:02:09 2021 ] \tBatch(439/508) done. Loss: 0.0034  lr:0.010000\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 508/508 [07:51<00:00,  1.08it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["[ Sat Aug 14 18:03:12 2021 ] Eval epoch: 21\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 59/59 [00:27<00:00,  2.13it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["Eval Accuracy:  0.9147514698022448  model:  /content/drive/MyDrive/Colab Notebooks/CVPR21-Bh/Final_train/finetune/joint/save_models/joint_27_2_finetune\n","[ Sat Aug 14 18:03:40 2021 ] \tMean test loss of 59 batches: 0.3713230490684509.\n","[ Sat Aug 14 18:03:40 2021 ] \tTop1: 91.48%\n","[ Sat Aug 14 18:03:40 2021 ] \tTop5: 98.69%\n","[ Sat Aug 14 18:03:40 2021 ] Training epoch: 22\n"],"name":"stdout"},{"output_type":"stream","text":["\r  0%|          | 0/508 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["only train part, require grad\n","l1.gcn1.DecoupleA-require grad\n","l2.gcn1.DecoupleA-require grad\n","l3.gcn1.DecoupleA-require grad\n","l4.gcn1.DecoupleA-require grad\n","l5.gcn1.DecoupleA-require grad\n","l6.gcn1.DecoupleA-require grad\n","l7.gcn1.DecoupleA-require grad\n","l8.gcn1.DecoupleA-require grad\n","l9.gcn1.DecoupleA-require grad\n","l10.gcn1.DecoupleA-require grad\n"],"name":"stdout"},{"output_type":"stream","text":["  6%|▋         | 32/508 [00:31<07:22,  1.07it/s]"],"name":"stderr"},{"output_type":"stream","text":["[ Sat Aug 14 18:04:12 2021 ] \tBatch(31/508) done. Loss: 0.0036  lr:0.010000\n"],"name":"stdout"},{"output_type":"stream","text":[" 26%|██▌       | 132/508 [02:03<05:46,  1.08it/s]"],"name":"stderr"},{"output_type":"stream","text":["[ Sat Aug 14 18:05:44 2021 ] \tBatch(131/508) done. Loss: 0.0117  lr:0.010000\n"],"name":"stdout"},{"output_type":"stream","text":[" 46%|████▌     | 232/508 [03:36<04:15,  1.08it/s]"],"name":"stderr"},{"output_type":"stream","text":["[ Sat Aug 14 18:07:17 2021 ] \tBatch(231/508) done. Loss: 0.0050  lr:0.010000\n"],"name":"stdout"},{"output_type":"stream","text":[" 65%|██████▌   | 332/508 [05:08<02:42,  1.08it/s]"],"name":"stderr"},{"output_type":"stream","text":["[ Sat Aug 14 18:08:49 2021 ] \tBatch(331/508) done. Loss: 0.0029  lr:0.010000\n"],"name":"stdout"},{"output_type":"stream","text":[" 85%|████████▌ | 432/508 [06:40<01:10,  1.08it/s]"],"name":"stderr"},{"output_type":"stream","text":["[ Sat Aug 14 18:10:21 2021 ] \tBatch(431/508) done. Loss: 0.0010  lr:0.010000\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 508/508 [07:51<00:00,  1.08it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["[ Sat Aug 14 18:11:33 2021 ] Eval epoch: 22\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 59/59 [00:27<00:00,  2.14it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["Eval Accuracy:  0.9160876536611438  model:  /content/drive/MyDrive/Colab Notebooks/CVPR21-Bh/Final_train/finetune/joint/save_models/joint_27_2_finetune\n","[ Sat Aug 14 18:12:00 2021 ] \tMean test loss of 59 batches: 0.3604264259338379.\n","[ Sat Aug 14 18:12:00 2021 ] \tTop1: 91.61%\n","[ Sat Aug 14 18:12:00 2021 ] \tTop5: 98.85%\n","[ Sat Aug 14 18:12:00 2021 ] Training epoch: 23\n"],"name":"stdout"},{"output_type":"stream","text":["\r  0%|          | 0/508 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["only train part, require grad\n","l1.gcn1.DecoupleA-require grad\n","l2.gcn1.DecoupleA-require grad\n","l3.gcn1.DecoupleA-require grad\n","l4.gcn1.DecoupleA-require grad\n","l5.gcn1.DecoupleA-require grad\n","l6.gcn1.DecoupleA-require grad\n","l7.gcn1.DecoupleA-require grad\n","l8.gcn1.DecoupleA-require grad\n","l9.gcn1.DecoupleA-require grad\n","l10.gcn1.DecoupleA-require grad\n"],"name":"stdout"},{"output_type":"stream","text":["  5%|▍         | 24/508 [00:24<07:28,  1.08it/s]"],"name":"stderr"},{"output_type":"stream","text":["[ Sat Aug 14 18:12:25 2021 ] \tBatch(23/508) done. Loss: 0.0021  lr:0.010000\n"],"name":"stdout"},{"output_type":"stream","text":[" 24%|██▍       | 124/508 [01:56<05:56,  1.08it/s]"],"name":"stderr"},{"output_type":"stream","text":["[ Sat Aug 14 18:13:57 2021 ] \tBatch(123/508) done. Loss: 0.0032  lr:0.010000\n"],"name":"stdout"},{"output_type":"stream","text":[" 44%|████▍     | 224/508 [03:28<04:23,  1.08it/s]"],"name":"stderr"},{"output_type":"stream","text":["[ Sat Aug 14 18:15:29 2021 ] \tBatch(223/508) done. Loss: 0.0035  lr:0.010000\n"],"name":"stdout"},{"output_type":"stream","text":[" 64%|██████▍   | 324/508 [05:00<02:50,  1.08it/s]"],"name":"stderr"},{"output_type":"stream","text":["[ Sat Aug 14 18:17:01 2021 ] \tBatch(323/508) done. Loss: 0.0037  lr:0.010000\n"],"name":"stdout"},{"output_type":"stream","text":[" 83%|████████▎ | 424/508 [06:33<01:17,  1.08it/s]"],"name":"stderr"},{"output_type":"stream","text":["[ Sat Aug 14 18:18:34 2021 ] \tBatch(423/508) done. Loss: 0.0065  lr:0.010000\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 508/508 [07:51<00:00,  1.08it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["[ Sat Aug 14 18:19:52 2021 ] Eval epoch: 23\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 59/59 [00:27<00:00,  2.13it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["Eval Accuracy:  0.9142169962586852  model:  /content/drive/MyDrive/Colab Notebooks/CVPR21-Bh/Final_train/finetune/joint/save_models/joint_27_2_finetune\n","[ Sat Aug 14 18:20:20 2021 ] \tMean test loss of 59 batches: 0.3637809157371521.\n","[ Sat Aug 14 18:20:20 2021 ] \tTop1: 91.42%\n","[ Sat Aug 14 18:20:20 2021 ] \tTop5: 98.72%\n","[ Sat Aug 14 18:20:20 2021 ] Training epoch: 24\n"],"name":"stdout"},{"output_type":"stream","text":["\r  0%|          | 0/508 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["only train part, require grad\n","l1.gcn1.DecoupleA-require grad\n","l2.gcn1.DecoupleA-require grad\n","l3.gcn1.DecoupleA-require grad\n","l4.gcn1.DecoupleA-require grad\n","l5.gcn1.DecoupleA-require grad\n","l6.gcn1.DecoupleA-require grad\n","l7.gcn1.DecoupleA-require grad\n","l8.gcn1.DecoupleA-require grad\n","l9.gcn1.DecoupleA-require grad\n","l10.gcn1.DecoupleA-require grad\n"],"name":"stdout"},{"output_type":"stream","text":["  3%|▎         | 16/508 [00:16<07:37,  1.08it/s]"],"name":"stderr"},{"output_type":"stream","text":["[ Sat Aug 14 18:20:37 2021 ] \tBatch(15/508) done. Loss: 0.0031  lr:0.010000\n"],"name":"stdout"},{"output_type":"stream","text":[" 23%|██▎       | 116/508 [01:49<06:02,  1.08it/s]"],"name":"stderr"},{"output_type":"stream","text":["[ Sat Aug 14 18:22:09 2021 ] \tBatch(115/508) done. Loss: 0.0022  lr:0.010000\n"],"name":"stdout"},{"output_type":"stream","text":[" 43%|████▎     | 216/508 [03:21<04:29,  1.08it/s]"],"name":"stderr"},{"output_type":"stream","text":["[ Sat Aug 14 18:23:42 2021 ] \tBatch(215/508) done. Loss: 0.0009  lr:0.010000\n"],"name":"stdout"},{"output_type":"stream","text":[" 62%|██████▏   | 316/508 [04:53<02:57,  1.08it/s]"],"name":"stderr"},{"output_type":"stream","text":["[ Sat Aug 14 18:25:14 2021 ] \tBatch(315/508) done. Loss: 0.0021  lr:0.010000\n"],"name":"stdout"},{"output_type":"stream","text":[" 82%|████████▏ | 416/508 [06:26<01:25,  1.08it/s]"],"name":"stderr"},{"output_type":"stream","text":["[ Sat Aug 14 18:26:46 2021 ] \tBatch(415/508) done. Loss: 0.0031  lr:0.010000\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 508/508 [07:51<00:00,  1.08it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["[ Sat Aug 14 18:28:12 2021 ] Eval epoch: 24\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 59/59 [00:27<00:00,  2.14it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["Eval Accuracy:  0.9150187065740246  model:  /content/drive/MyDrive/Colab Notebooks/CVPR21-Bh/Final_train/finetune/joint/save_models/joint_27_2_finetune\n","[ Sat Aug 14 18:28:40 2021 ] \tMean test loss of 59 batches: 0.3617401719093323.\n","[ Sat Aug 14 18:28:40 2021 ] \tTop1: 91.50%\n","[ Sat Aug 14 18:28:40 2021 ] \tTop5: 98.77%\n","[ Sat Aug 14 18:28:40 2021 ] Training epoch: 25\n"],"name":"stdout"},{"output_type":"stream","text":["\r  0%|          | 0/508 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["only train part, require grad\n","l1.gcn1.DecoupleA-require grad\n","l2.gcn1.DecoupleA-require grad\n","l3.gcn1.DecoupleA-require grad\n","l4.gcn1.DecoupleA-require grad\n","l5.gcn1.DecoupleA-require grad\n","l6.gcn1.DecoupleA-require grad\n","l7.gcn1.DecoupleA-require grad\n","l8.gcn1.DecoupleA-require grad\n","l9.gcn1.DecoupleA-require grad\n","l10.gcn1.DecoupleA-require grad\n"],"name":"stdout"},{"output_type":"stream","text":["  2%|▏         | 8/508 [00:09<08:11,  1.02it/s]"],"name":"stderr"},{"output_type":"stream","text":["[ Sat Aug 14 18:28:50 2021 ] \tBatch(7/508) done. Loss: 0.0044  lr:0.010000\n"],"name":"stdout"},{"output_type":"stream","text":[" 21%|██▏       | 108/508 [01:41<06:09,  1.08it/s]"],"name":"stderr"},{"output_type":"stream","text":["[ Sat Aug 14 18:30:22 2021 ] \tBatch(107/508) done. Loss: 0.0018  lr:0.010000\n"],"name":"stdout"},{"output_type":"stream","text":[" 41%|████      | 208/508 [03:14<04:37,  1.08it/s]"],"name":"stderr"},{"output_type":"stream","text":["[ Sat Aug 14 18:31:54 2021 ] \tBatch(207/508) done. Loss: 0.0089  lr:0.010000\n"],"name":"stdout"},{"output_type":"stream","text":[" 61%|██████    | 308/508 [04:46<03:04,  1.08it/s]"],"name":"stderr"},{"output_type":"stream","text":["[ Sat Aug 14 18:33:27 2021 ] \tBatch(307/508) done. Loss: 0.0043  lr:0.010000\n"],"name":"stdout"},{"output_type":"stream","text":[" 80%|████████  | 408/508 [06:18<01:32,  1.08it/s]"],"name":"stderr"},{"output_type":"stream","text":["[ Sat Aug 14 18:34:59 2021 ] \tBatch(407/508) done. Loss: 0.0035  lr:0.010000\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 508/508 [07:51<00:00,  1.08it/s]"],"name":"stderr"},{"output_type":"stream","text":["[ Sat Aug 14 18:36:31 2021 ] \tBatch(507/508) done. Loss: 0.0019  lr:0.010000\n"],"name":"stdout"},{"output_type":"stream","text":["\r100%|██████████| 508/508 [07:52<00:00,  1.08it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["[ Sat Aug 14 18:36:32 2021 ] Eval epoch: 25\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 59/59 [00:27<00:00,  2.13it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["Eval Accuracy:  0.913148049171566  model:  /content/drive/MyDrive/Colab Notebooks/CVPR21-Bh/Final_train/finetune/joint/save_models/joint_27_2_finetune\n","[ Sat Aug 14 18:37:00 2021 ] \tMean test loss of 59 batches: 0.36290228366851807.\n","[ Sat Aug 14 18:37:00 2021 ] \tTop1: 91.31%\n","[ Sat Aug 14 18:37:00 2021 ] \tTop5: 98.72%\n","[ Sat Aug 14 18:37:00 2021 ] Training epoch: 26\n"],"name":"stdout"},{"output_type":"stream","text":["\r  0%|          | 0/508 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["only train part, require grad\n","l1.gcn1.DecoupleA-require grad\n","l2.gcn1.DecoupleA-require grad\n","l3.gcn1.DecoupleA-require grad\n","l4.gcn1.DecoupleA-require grad\n","l5.gcn1.DecoupleA-require grad\n","l6.gcn1.DecoupleA-require grad\n","l7.gcn1.DecoupleA-require grad\n","l8.gcn1.DecoupleA-require grad\n","l9.gcn1.DecoupleA-require grad\n","l10.gcn1.DecoupleA-require grad\n"],"name":"stdout"},{"output_type":"stream","text":[" 20%|█▉        | 100/508 [01:34<06:17,  1.08it/s]"],"name":"stderr"},{"output_type":"stream","text":["[ Sat Aug 14 18:38:35 2021 ] \tBatch(99/508) done. Loss: 0.0075  lr:0.010000\n"],"name":"stdout"},{"output_type":"stream","text":[" 39%|███▉      | 200/508 [03:06<04:44,  1.08it/s]"],"name":"stderr"},{"output_type":"stream","text":["[ Sat Aug 14 18:40:07 2021 ] \tBatch(199/508) done. Loss: 0.0009  lr:0.010000\n"],"name":"stdout"},{"output_type":"stream","text":[" 59%|█████▉    | 300/508 [04:38<03:11,  1.09it/s]"],"name":"stderr"},{"output_type":"stream","text":["[ Sat Aug 14 18:41:39 2021 ] \tBatch(299/508) done. Loss: 0.0201  lr:0.010000\n"],"name":"stdout"},{"output_type":"stream","text":[" 79%|███████▊  | 400/508 [06:10<01:39,  1.08it/s]"],"name":"stderr"},{"output_type":"stream","text":["[ Sat Aug 14 18:43:11 2021 ] \tBatch(399/508) done. Loss: 0.0053  lr:0.010000\n"],"name":"stdout"},{"output_type":"stream","text":[" 98%|█████████▊| 500/508 [07:42<00:07,  1.09it/s]"],"name":"stderr"},{"output_type":"stream","text":["[ Sat Aug 14 18:44:43 2021 ] \tBatch(499/508) done. Loss: 0.0018  lr:0.010000\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 508/508 [07:50<00:00,  1.08it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["[ Sat Aug 14 18:44:51 2021 ] Eval epoch: 26\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 59/59 [00:27<00:00,  2.14it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["Eval Accuracy:  0.9136825227151256  model:  /content/drive/MyDrive/Colab Notebooks/CVPR21-Bh/Final_train/finetune/joint/save_models/joint_27_2_finetune\n","[ Sat Aug 14 18:45:19 2021 ] \tMean test loss of 59 batches: 0.3632941246032715.\n","[ Sat Aug 14 18:45:19 2021 ] \tTop1: 91.37%\n","[ Sat Aug 14 18:45:19 2021 ] \tTop5: 98.69%\n","[ Sat Aug 14 18:45:19 2021 ] Training epoch: 27\n"],"name":"stdout"},{"output_type":"stream","text":["\r  0%|          | 0/508 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["only train part, require grad\n","l1.gcn1.DecoupleA-require grad\n","l2.gcn1.DecoupleA-require grad\n","l3.gcn1.DecoupleA-require grad\n","l4.gcn1.DecoupleA-require grad\n","l5.gcn1.DecoupleA-require grad\n","l6.gcn1.DecoupleA-require grad\n","l7.gcn1.DecoupleA-require grad\n","l8.gcn1.DecoupleA-require grad\n","l9.gcn1.DecoupleA-require grad\n","l10.gcn1.DecoupleA-require grad\n"],"name":"stdout"},{"output_type":"stream","text":[" 18%|█▊        | 92/508 [01:26<06:22,  1.09it/s]"],"name":"stderr"},{"output_type":"stream","text":["[ Sat Aug 14 18:46:45 2021 ] \tBatch(91/508) done. Loss: 0.0018  lr:0.010000\n"],"name":"stdout"},{"output_type":"stream","text":[" 38%|███▊      | 192/508 [02:58<04:51,  1.08it/s]"],"name":"stderr"},{"output_type":"stream","text":["[ Sat Aug 14 18:48:17 2021 ] \tBatch(191/508) done. Loss: 0.0070  lr:0.010000\n"],"name":"stdout"},{"output_type":"stream","text":[" 57%|█████▋    | 292/508 [04:30<03:19,  1.08it/s]"],"name":"stderr"},{"output_type":"stream","text":["[ Sat Aug 14 18:49:49 2021 ] \tBatch(291/508) done. Loss: 0.0042  lr:0.010000\n"],"name":"stdout"},{"output_type":"stream","text":[" 77%|███████▋  | 392/508 [06:02<01:46,  1.08it/s]"],"name":"stderr"},{"output_type":"stream","text":["[ Sat Aug 14 18:51:21 2021 ] \tBatch(391/508) done. Loss: 0.0021  lr:0.010000\n"],"name":"stdout"},{"output_type":"stream","text":[" 97%|█████████▋| 492/508 [07:34<00:14,  1.09it/s]"],"name":"stderr"},{"output_type":"stream","text":["[ Sat Aug 14 18:52:53 2021 ] \tBatch(491/508) done. Loss: 0.0154  lr:0.010000\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 508/508 [07:49<00:00,  1.08it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["[ Sat Aug 14 18:53:09 2021 ] Eval epoch: 27\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 59/59 [00:27<00:00,  2.14it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["Eval Accuracy:  0.9163548904329236  model:  /content/drive/MyDrive/Colab Notebooks/CVPR21-Bh/Final_train/finetune/joint/save_models/joint_27_2_finetune\n","[ Sat Aug 14 18:53:37 2021 ] \tMean test loss of 59 batches: 0.35668572783470154.\n","[ Sat Aug 14 18:53:37 2021 ] \tTop1: 91.64%\n","[ Sat Aug 14 18:53:37 2021 ] \tTop5: 98.80%\n","[ Sat Aug 14 18:53:37 2021 ] Training epoch: 28\n"],"name":"stdout"},{"output_type":"stream","text":["\r  0%|          | 0/508 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["only train part, require grad\n","l1.gcn1.DecoupleA-require grad\n","l2.gcn1.DecoupleA-require grad\n","l3.gcn1.DecoupleA-require grad\n","l4.gcn1.DecoupleA-require grad\n","l5.gcn1.DecoupleA-require grad\n","l6.gcn1.DecoupleA-require grad\n","l7.gcn1.DecoupleA-require grad\n","l8.gcn1.DecoupleA-require grad\n","l9.gcn1.DecoupleA-require grad\n","l10.gcn1.DecoupleA-require grad\n"],"name":"stdout"},{"output_type":"stream","text":[" 17%|█▋        | 84/508 [01:19<06:28,  1.09it/s]"],"name":"stderr"},{"output_type":"stream","text":["[ Sat Aug 14 18:54:56 2021 ] \tBatch(83/508) done. Loss: 0.0019  lr:0.010000\n"],"name":"stdout"},{"output_type":"stream","text":[" 36%|███▌      | 184/508 [02:51<04:58,  1.08it/s]"],"name":"stderr"},{"output_type":"stream","text":["[ Sat Aug 14 18:56:28 2021 ] \tBatch(183/508) done. Loss: 0.0039  lr:0.010000\n"],"name":"stdout"},{"output_type":"stream","text":[" 56%|█████▌    | 284/508 [04:23<03:26,  1.08it/s]"],"name":"stderr"},{"output_type":"stream","text":["[ Sat Aug 14 18:58:00 2021 ] \tBatch(283/508) done. Loss: 0.0031  lr:0.010000\n"],"name":"stdout"},{"output_type":"stream","text":[" 76%|███████▌  | 384/508 [05:55<01:54,  1.08it/s]"],"name":"stderr"},{"output_type":"stream","text":["[ Sat Aug 14 18:59:32 2021 ] \tBatch(383/508) done. Loss: 0.0018  lr:0.010000\n"],"name":"stdout"},{"output_type":"stream","text":[" 95%|█████████▌| 484/508 [07:27<00:22,  1.09it/s]"],"name":"stderr"},{"output_type":"stream","text":["[ Sat Aug 14 19:01:05 2021 ] \tBatch(483/508) done. Loss: 0.0071  lr:0.010000\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 508/508 [07:50<00:00,  1.08it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["[ Sat Aug 14 19:01:28 2021 ] Eval epoch: 28\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 59/59 [00:27<00:00,  2.13it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["Eval Accuracy:  0.9139497594869054  model:  /content/drive/MyDrive/Colab Notebooks/CVPR21-Bh/Final_train/finetune/joint/save_models/joint_27_2_finetune\n","[ Sat Aug 14 19:01:56 2021 ] \tMean test loss of 59 batches: 0.3602013885974884.\n","[ Sat Aug 14 19:01:56 2021 ] \tTop1: 91.39%\n","[ Sat Aug 14 19:01:56 2021 ] \tTop5: 98.66%\n","[ Sat Aug 14 19:01:56 2021 ] Training epoch: 29\n"],"name":"stdout"},{"output_type":"stream","text":["\r  0%|          | 0/508 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["only train part, require grad\n","l1.gcn1.DecoupleA-require grad\n","l2.gcn1.DecoupleA-require grad\n","l3.gcn1.DecoupleA-require grad\n","l4.gcn1.DecoupleA-require grad\n","l5.gcn1.DecoupleA-require grad\n","l6.gcn1.DecoupleA-require grad\n","l7.gcn1.DecoupleA-require grad\n","l8.gcn1.DecoupleA-require grad\n","l9.gcn1.DecoupleA-require grad\n","l10.gcn1.DecoupleA-require grad\n"],"name":"stdout"},{"output_type":"stream","text":[" 15%|█▍        | 76/508 [01:12<06:38,  1.08it/s]"],"name":"stderr"},{"output_type":"stream","text":["[ Sat Aug 14 19:03:08 2021 ] \tBatch(75/508) done. Loss: 0.0012  lr:0.010000\n"],"name":"stdout"},{"output_type":"stream","text":[" 35%|███▍      | 176/508 [02:44<05:05,  1.09it/s]"],"name":"stderr"},{"output_type":"stream","text":["[ Sat Aug 14 19:04:40 2021 ] \tBatch(175/508) done. Loss: 0.0078  lr:0.010000\n"],"name":"stdout"},{"output_type":"stream","text":[" 54%|█████▍    | 276/508 [04:16<03:33,  1.08it/s]"],"name":"stderr"},{"output_type":"stream","text":["[ Sat Aug 14 19:06:12 2021 ] \tBatch(275/508) done. Loss: 0.0085  lr:0.010000\n"],"name":"stdout"},{"output_type":"stream","text":[" 74%|███████▍  | 376/508 [05:48<02:01,  1.09it/s]"],"name":"stderr"},{"output_type":"stream","text":["[ Sat Aug 14 19:07:44 2021 ] \tBatch(375/508) done. Loss: 0.0032  lr:0.010000\n"],"name":"stdout"},{"output_type":"stream","text":[" 94%|█████████▎| 476/508 [07:20<00:29,  1.08it/s]"],"name":"stderr"},{"output_type":"stream","text":["[ Sat Aug 14 19:09:16 2021 ] \tBatch(475/508) done. Loss: 0.0020  lr:0.010000\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 508/508 [07:50<00:00,  1.08it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["[ Sat Aug 14 19:09:47 2021 ] Eval epoch: 29\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 59/59 [00:27<00:00,  2.14it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["Eval Accuracy:  0.917156600748263  model:  /content/drive/MyDrive/Colab Notebooks/CVPR21-Bh/Final_train/finetune/joint/save_models/joint_27_2_finetune\n","[ Sat Aug 14 19:10:14 2021 ] \tMean test loss of 59 batches: 0.35105106234550476.\n","[ Sat Aug 14 19:10:14 2021 ] \tTop1: 91.72%\n","[ Sat Aug 14 19:10:14 2021 ] \tTop5: 98.69%\n","[ Sat Aug 14 19:10:14 2021 ] Training epoch: 30\n"],"name":"stdout"},{"output_type":"stream","text":["\r  0%|          | 0/508 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["only train part, require grad\n","l1.gcn1.DecoupleA-require grad\n","l2.gcn1.DecoupleA-require grad\n","l3.gcn1.DecoupleA-require grad\n","l4.gcn1.DecoupleA-require grad\n","l5.gcn1.DecoupleA-require grad\n","l6.gcn1.DecoupleA-require grad\n","l7.gcn1.DecoupleA-require grad\n","l8.gcn1.DecoupleA-require grad\n","l9.gcn1.DecoupleA-require grad\n","l10.gcn1.DecoupleA-require grad\n"],"name":"stdout"},{"output_type":"stream","text":[" 13%|█▎        | 68/508 [01:04<06:44,  1.09it/s]"],"name":"stderr"},{"output_type":"stream","text":["[ Sat Aug 14 19:11:19 2021 ] \tBatch(67/508) done. Loss: 0.0022  lr:0.010000\n"],"name":"stdout"},{"output_type":"stream","text":[" 33%|███▎      | 168/508 [02:36<05:14,  1.08it/s]"],"name":"stderr"},{"output_type":"stream","text":["[ Sat Aug 14 19:12:51 2021 ] \tBatch(167/508) done. Loss: 0.0016  lr:0.010000\n"],"name":"stdout"},{"output_type":"stream","text":[" 53%|█████▎    | 268/508 [04:08<03:41,  1.09it/s]"],"name":"stderr"},{"output_type":"stream","text":["[ Sat Aug 14 19:14:23 2021 ] \tBatch(267/508) done. Loss: 0.0115  lr:0.010000\n"],"name":"stdout"},{"output_type":"stream","text":[" 72%|███████▏  | 368/508 [05:40<02:09,  1.09it/s]"],"name":"stderr"},{"output_type":"stream","text":["[ Sat Aug 14 19:15:55 2021 ] \tBatch(367/508) done. Loss: 0.0042  lr:0.010000\n"],"name":"stdout"},{"output_type":"stream","text":[" 92%|█████████▏| 468/508 [07:12<00:36,  1.09it/s]"],"name":"stderr"},{"output_type":"stream","text":["[ Sat Aug 14 19:17:27 2021 ] \tBatch(467/508) done. Loss: 0.0090  lr:0.010000\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 508/508 [07:50<00:00,  1.08it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["[ Sat Aug 14 19:18:05 2021 ] Eval epoch: 30\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 59/59 [00:27<00:00,  2.15it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["Eval Accuracy:  0.9182255478353821  model:  /content/drive/MyDrive/Colab Notebooks/CVPR21-Bh/Final_train/finetune/joint/save_models/joint_27_2_finetune\n","[ Sat Aug 14 19:18:32 2021 ] \tMean test loss of 59 batches: 0.3562118113040924.\n","[ Sat Aug 14 19:18:32 2021 ] \tTop1: 91.82%\n","[ Sat Aug 14 19:18:32 2021 ] \tTop5: 98.77%\n","[ Sat Aug 14 19:18:32 2021 ] Training epoch: 31\n"],"name":"stdout"},{"output_type":"stream","text":["\r  0%|          | 0/508 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["only train part, require grad\n","l1.gcn1.DecoupleA-require grad\n","l2.gcn1.DecoupleA-require grad\n","l3.gcn1.DecoupleA-require grad\n","l4.gcn1.DecoupleA-require grad\n","l5.gcn1.DecoupleA-require grad\n","l6.gcn1.DecoupleA-require grad\n","l7.gcn1.DecoupleA-require grad\n","l8.gcn1.DecoupleA-require grad\n","l9.gcn1.DecoupleA-require grad\n","l10.gcn1.DecoupleA-require grad\n"],"name":"stdout"},{"output_type":"stream","text":[" 12%|█▏        | 60/508 [00:57<06:50,  1.09it/s]"],"name":"stderr"},{"output_type":"stream","text":["[ Sat Aug 14 19:19:29 2021 ] \tBatch(59/508) done. Loss: 0.0024  lr:0.010000\n"],"name":"stdout"},{"output_type":"stream","text":[" 31%|███▏      | 160/508 [02:28<05:19,  1.09it/s]"],"name":"stderr"},{"output_type":"stream","text":["[ Sat Aug 14 19:21:01 2021 ] \tBatch(159/508) done. Loss: 0.0059  lr:0.010000\n"],"name":"stdout"},{"output_type":"stream","text":[" 51%|█████     | 260/508 [04:00<03:48,  1.09it/s]"],"name":"stderr"},{"output_type":"stream","text":["[ Sat Aug 14 19:22:33 2021 ] \tBatch(259/508) done. Loss: 0.0025  lr:0.010000\n"],"name":"stdout"},{"output_type":"stream","text":[" 71%|███████   | 360/508 [05:32<02:16,  1.08it/s]"],"name":"stderr"},{"output_type":"stream","text":["[ Sat Aug 14 19:24:05 2021 ] \tBatch(359/508) done. Loss: 0.0122  lr:0.010000\n"],"name":"stdout"},{"output_type":"stream","text":[" 91%|█████████ | 460/508 [07:04<00:44,  1.09it/s]"],"name":"stderr"},{"output_type":"stream","text":["[ Sat Aug 14 19:25:37 2021 ] \tBatch(459/508) done. Loss: 0.0048  lr:0.010000\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 508/508 [07:49<00:00,  1.08it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["[ Sat Aug 14 19:26:22 2021 ] Eval epoch: 31\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 59/59 [00:27<00:00,  2.12it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["Eval Accuracy:  0.917156600748263  model:  /content/drive/MyDrive/Colab Notebooks/CVPR21-Bh/Final_train/finetune/joint/save_models/joint_27_2_finetune\n","[ Sat Aug 14 19:26:50 2021 ] \tMean test loss of 59 batches: 0.34490320086479187.\n","[ Sat Aug 14 19:26:50 2021 ] \tTop1: 91.72%\n","[ Sat Aug 14 19:26:50 2021 ] \tTop5: 98.69%\n","[ Sat Aug 14 19:26:51 2021 ] Training epoch: 32\n"],"name":"stdout"},{"output_type":"stream","text":["\r  0%|          | 0/508 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["only train part, require grad\n","l1.gcn1.DecoupleA-require grad\n","l2.gcn1.DecoupleA-require grad\n","l3.gcn1.DecoupleA-require grad\n","l4.gcn1.DecoupleA-require grad\n","l5.gcn1.DecoupleA-require grad\n","l6.gcn1.DecoupleA-require grad\n","l7.gcn1.DecoupleA-require grad\n","l8.gcn1.DecoupleA-require grad\n","l9.gcn1.DecoupleA-require grad\n","l10.gcn1.DecoupleA-require grad\n"],"name":"stdout"},{"output_type":"stream","text":[" 10%|█         | 52/508 [00:50<07:02,  1.08it/s]"],"name":"stderr"},{"output_type":"stream","text":["[ Sat Aug 14 19:27:41 2021 ] \tBatch(51/508) done. Loss: 0.0028  lr:0.010000\n"],"name":"stdout"},{"output_type":"stream","text":[" 30%|██▉       | 152/508 [02:22<05:29,  1.08it/s]"],"name":"stderr"},{"output_type":"stream","text":["[ Sat Aug 14 19:29:13 2021 ] \tBatch(151/508) done. Loss: 0.0019  lr:0.010000\n"],"name":"stdout"},{"output_type":"stream","text":[" 50%|████▉     | 252/508 [03:54<03:56,  1.08it/s]"],"name":"stderr"},{"output_type":"stream","text":["[ Sat Aug 14 19:30:45 2021 ] \tBatch(251/508) done. Loss: 0.0020  lr:0.010000\n"],"name":"stdout"},{"output_type":"stream","text":[" 69%|██████▉   | 352/508 [05:27<02:23,  1.09it/s]"],"name":"stderr"},{"output_type":"stream","text":["[ Sat Aug 14 19:32:18 2021 ] \tBatch(351/508) done. Loss: 0.0065  lr:0.010000\n"],"name":"stdout"},{"output_type":"stream","text":[" 89%|████████▉ | 452/508 [06:58<00:51,  1.09it/s]"],"name":"stderr"},{"output_type":"stream","text":["[ Sat Aug 14 19:33:49 2021 ] \tBatch(451/508) done. Loss: 0.0057  lr:0.010000\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 508/508 [07:51<00:00,  1.08it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["[ Sat Aug 14 19:34:42 2021 ] Eval epoch: 32\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 59/59 [00:27<00:00,  2.14it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["Eval Accuracy:  0.9168893639764831  model:  /content/drive/MyDrive/Colab Notebooks/CVPR21-Bh/Final_train/finetune/joint/save_models/joint_27_2_finetune\n","[ Sat Aug 14 19:35:10 2021 ] \tMean test loss of 59 batches: 0.34787383675575256.\n","[ Sat Aug 14 19:35:10 2021 ] \tTop1: 91.69%\n","[ Sat Aug 14 19:35:10 2021 ] \tTop5: 98.72%\n","[ Sat Aug 14 19:35:10 2021 ] Training epoch: 33\n"],"name":"stdout"},{"output_type":"stream","text":["\r  0%|          | 0/508 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["only train part, require grad\n","l1.gcn1.DecoupleA-require grad\n","l2.gcn1.DecoupleA-require grad\n","l3.gcn1.DecoupleA-require grad\n","l4.gcn1.DecoupleA-require grad\n","l5.gcn1.DecoupleA-require grad\n","l6.gcn1.DecoupleA-require grad\n","l7.gcn1.DecoupleA-require grad\n","l8.gcn1.DecoupleA-require grad\n","l9.gcn1.DecoupleA-require grad\n","l10.gcn1.DecoupleA-require grad\n"],"name":"stdout"},{"output_type":"stream","text":["  9%|▊         | 44/508 [00:42<07:05,  1.09it/s]"],"name":"stderr"},{"output_type":"stream","text":["[ Sat Aug 14 19:35:52 2021 ] \tBatch(43/508) done. Loss: 0.0012  lr:0.010000\n"],"name":"stdout"},{"output_type":"stream","text":[" 26%|██▌       | 130/508 [02:00<05:45,  1.09it/s]"],"name":"stderr"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"-T4VEC-zf-ov","executionInfo":{"status":"error","timestamp":1628176880188,"user_tz":-360,"elapsed":6785322,"user":{"displayName":"Md.safirur Rashid, 170041020","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj4vsxiS6hdwcIxlWkCOlOKX6Yb9qvDnhTv0OE=s64","userId":"07083869211232678860"}},"outputId":"75e2c36c-c045-4fa1-e72a-9209419aaff2"},"source":["%cd /content/CVPR21Chal-SLR/SL-GCN\n","init_seed(0)\n","processor = Processor(arg)\n","processor.start()\n","%cd /content"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/content/CVPR21Chal-SLR/SL-GCN\n"],"name":"stdout"},{"output_type":"stream","text":["/content/CVPR21Chal-SLR/SL-GCN/model/decouple_gcn_attn.py:29: UserWarning: nn.init.kaiming_normal is now deprecated in favor of nn.init.kaiming_normal_.\n","  nn.init.kaiming_normal(conv.weight, mode='fan_out')\n","/content/CVPR21Chal-SLR/SL-GCN/model/decouple_gcn_attn.py:30: UserWarning: nn.init.constant is now deprecated in favor of nn.init.constant_.\n","  nn.init.constant(conv.bias, 0)\n","/content/CVPR21Chal-SLR/SL-GCN/model/decouple_gcn_attn.py:34: UserWarning: nn.init.constant is now deprecated in favor of nn.init.constant_.\n","  nn.init.constant(bn.weight, scale)\n","/content/CVPR21Chal-SLR/SL-GCN/model/decouple_gcn_attn.py:35: UserWarning: nn.init.constant is now deprecated in favor of nn.init.constant_.\n","  nn.init.constant(bn.bias, 0)\n","/content/CVPR21Chal-SLR/SL-GCN/model/decouple_gcn_attn.py:113: UserWarning: nn.init.constant is now deprecated in favor of nn.init.constant_.\n","  nn.init.constant(self.Linear_bias, 1e-6)\n","/content/CVPR21Chal-SLR/SL-GCN/model/decouple_gcn_attn.py:119: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  eye_array), requires_grad=False, device='cuda'), requires_grad=False)  # [c,25,25]\n","/content/CVPR21Chal-SLR/SL-GCN/model/decouple_gcn_attn.py:252: UserWarning: nn.init.normal is now deprecated in favor of nn.init.normal_.\n","  nn.init.normal(self.fc.weight, 0, math.sqrt(2. / num_class))\n"],"name":"stderr"},{"output_type":"stream","text":["Attention Enabled!\n","Attention Enabled!\n","Attention Enabled!\n","Attention Enabled!\n","Attention Enabled!\n","Attention Enabled!\n","Attention Enabled!\n","Attention Enabled!\n","Attention Enabled!\n","Attention Enabled!\n","[ Thu Aug  5 13:28:24 2021 ] Load weights from /content/drive/MyDrive/Colab Notebooks/CVPR21-Bh/train2/idk/sign_joint_final-30.pt.\n","28142\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 32 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n","  0%|          | 0/439 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["28142\n","[ Thu Aug  5 13:28:31 2021 ] Parameters:\n","{'Experiment_name': 'sign_joint_final', 'base_lr': 0.1, 'batch_size': 64, 'config': '/content/CVPR21Chal-SLR/SL-GCN/config/sign/train/train_joint.yaml', 'device': [0], 'eval_interval': 5, 'feeder': 'feeders.feeder.Feeder', 'groups': 8, 'ignore_weights': [], 'keep_rate': 0.9, 'log_interval': 100, 'model': 'model.decouple_gcn_attn.Model', 'model_args': {'num_class': 226, 'num_point': 27, 'num_person': 1, 'graph': 'graph.sign_27.Graph', 'groups': 16, 'block_size': 41, 'graph_args': {'labeling_mode': 'spatial'}}, 'model_saved_name': './save_models/sign_joint_final', 'nesterov': True, 'num_epoch': 250, 'num_worker': 32, 'only_train_epoch': 1, 'only_train_part': True, 'optimizer': 'SGD', 'phase': 'train', 'print_log': True, 'save_interval': 2, 'save_score': False, 'seed': 1, 'show_topk': [1, 5], 'start_epoch': 0, 'step': [150, 200], 'test_batch_size': 64, 'test_feeder_args': {'data_path': '/content/data/sign/27_2/train_data_joint.npy', 'label_path': '/content/data/sign/27_2/train_label.pkl', 'random_mirror': False, 'normalization': True}, 'train_feeder_args': {'data_path': '/content/data/sign/27_2/train_data_joint.npy', 'label_path': '/content/data/sign/27_2/train_label.pkl', 'debug': False, 'random_choose': True, 'window_size': 100, 'random_shift': True, 'normalization': True, 'random_mirror': True, 'random_mirror_p': 0.5, 'is_vector': False}, 'warm_up_epoch': 20, 'weight_decay': 0.0001, 'weights': '/content/drive/MyDrive/Colab Notebooks/CVPR21-Bh/train2/idk/sign_joint_final-30.pt', 'work_dir': './work_dir/sign_joint_final'}\n","\n","[ Thu Aug  5 13:28:31 2021 ] Training epoch: 1\n","only train part, do not require grad\n","l1.gcn1.DecoupleA-not require grad\n","l2.gcn1.DecoupleA-not require grad\n","l3.gcn1.DecoupleA-not require grad\n","l4.gcn1.DecoupleA-not require grad\n","l5.gcn1.DecoupleA-not require grad\n","l6.gcn1.DecoupleA-not require grad\n","l7.gcn1.DecoupleA-not require grad\n","l8.gcn1.DecoupleA-not require grad\n","l9.gcn1.DecoupleA-not require grad\n","l10.gcn1.DecoupleA-not require grad\n"],"name":"stdout"},{"output_type":"stream","text":[" 23%|██▎       | 100/439 [03:13<10:54,  1.93s/it]"],"name":"stderr"},{"output_type":"stream","text":["[ Thu Aug  5 13:31:44 2021 ] \tBatch(99/439) done. Loss: 0.0818  lr:0.005000\n"],"name":"stdout"},{"output_type":"stream","text":[" 46%|████▌     | 200/439 [06:26<07:41,  1.93s/it]"],"name":"stderr"},{"output_type":"stream","text":["[ Thu Aug  5 13:34:57 2021 ] \tBatch(199/439) done. Loss: 0.0563  lr:0.005000\n"],"name":"stdout"},{"output_type":"stream","text":[" 68%|██████▊   | 300/439 [09:38<04:27,  1.92s/it]"],"name":"stderr"},{"output_type":"stream","text":["[ Thu Aug  5 13:38:10 2021 ] \tBatch(299/439) done. Loss: 0.0554  lr:0.005000\n"],"name":"stdout"},{"output_type":"stream","text":[" 91%|█████████ | 400/439 [12:50<01:14,  1.92s/it]"],"name":"stderr"},{"output_type":"stream","text":["[ Thu Aug  5 13:41:22 2021 ] \tBatch(399/439) done. Loss: 0.0319  lr:0.005000\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 439/439 [14:06<00:00,  1.93s/it]\n","  0%|          | 0/440 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["[ Thu Aug  5 13:42:37 2021 ] Eval epoch: 1\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 440/440 [07:45<00:00,  1.06s/it]\n"],"name":"stderr"},{"output_type":"stream","text":["Eval Accuracy:  0.9941013431881174  model:  ./save_models/sign_joint_final\n","[ Thu Aug  5 13:50:24 2021 ] \tMean test loss of 440 batches: 0.02263963781297207.\n","[ Thu Aug  5 13:50:24 2021 ] \tTop1: 99.41%\n","[ Thu Aug  5 13:50:25 2021 ] \tTop5: 100.00%\n"],"name":"stdout"},{"output_type":"stream","text":["\r  0%|          | 0/439 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["[ Thu Aug  5 13:50:25 2021 ] Training epoch: 2\n","only train part, require grad\n","l1.gcn1.DecoupleA-require grad\n","l2.gcn1.DecoupleA-require grad\n","l3.gcn1.DecoupleA-require grad\n","l4.gcn1.DecoupleA-require grad\n","l5.gcn1.DecoupleA-require grad\n","l6.gcn1.DecoupleA-require grad\n","l7.gcn1.DecoupleA-require grad\n","l8.gcn1.DecoupleA-require grad\n","l9.gcn1.DecoupleA-require grad\n","l10.gcn1.DecoupleA-require grad\n"],"name":"stdout"},{"output_type":"stream","text":["/content/CVPR21Chal-SLR/SL-GCN/model/dropSke.py:29: UserWarning: undefined skeleton graph\n","  warnings.warn('undefined skeleton graph')\n","/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:652: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)\n","  return torch.max_pool1d(input, kernel_size, stride, padding, dilation, ceil_mode)\n"," 14%|█▍        | 61/439 [02:15<13:47,  2.19s/it]"],"name":"stderr"},{"output_type":"stream","text":["[ Thu Aug  5 13:52:40 2021 ] \tBatch(60/439) done. Loss: 0.0116  lr:0.010000\n"],"name":"stdout"},{"output_type":"stream","text":[" 37%|███▋      | 161/439 [05:54<10:09,  2.19s/it]"],"name":"stderr"},{"output_type":"stream","text":["[ Thu Aug  5 13:56:19 2021 ] \tBatch(160/439) done. Loss: 0.0302  lr:0.010000\n"],"name":"stdout"},{"output_type":"stream","text":[" 59%|█████▉    | 261/439 [09:33<06:31,  2.20s/it]"],"name":"stderr"},{"output_type":"stream","text":["[ Thu Aug  5 13:59:58 2021 ] \tBatch(260/439) done. Loss: 0.0100  lr:0.010000\n"],"name":"stdout"},{"output_type":"stream","text":[" 82%|████████▏ | 361/439 [13:13<02:51,  2.20s/it]"],"name":"stderr"},{"output_type":"stream","text":["[ Thu Aug  5 14:03:38 2021 ] \tBatch(360/439) done. Loss: 0.0181  lr:0.010000\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 439/439 [16:04<00:00,  2.20s/it]\n","  0%|          | 0/440 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["[ Thu Aug  5 14:06:30 2021 ] Eval epoch: 2\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 440/440 [07:43<00:00,  1.05s/it]\n"],"name":"stderr"},{"output_type":"stream","text":["Eval Accuracy:  0.9962333878189183  model:  ./save_models/sign_joint_final\n","[ Thu Aug  5 14:14:14 2021 ] \tMean test loss of 440 batches: 0.014988066628575325.\n","[ Thu Aug  5 14:14:15 2021 ] \tTop1: 99.62%\n","[ Thu Aug  5 14:14:15 2021 ] \tTop5: 100.00%\n"],"name":"stdout"},{"output_type":"stream","text":["\r  0%|          | 0/439 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["[ Thu Aug  5 14:14:15 2021 ] Training epoch: 3\n","only train part, require grad\n","l1.gcn1.DecoupleA-require grad\n","l2.gcn1.DecoupleA-require grad\n","l3.gcn1.DecoupleA-require grad\n","l4.gcn1.DecoupleA-require grad\n","l5.gcn1.DecoupleA-require grad\n","l6.gcn1.DecoupleA-require grad\n","l7.gcn1.DecoupleA-require grad\n","l8.gcn1.DecoupleA-require grad\n","l9.gcn1.DecoupleA-require grad\n","l10.gcn1.DecoupleA-require grad\n"],"name":"stdout"},{"output_type":"stream","text":["  5%|▌         | 22/439 [00:49<15:11,  2.19s/it]"],"name":"stderr"},{"output_type":"stream","text":["[ Thu Aug  5 14:15:05 2021 ] \tBatch(21/439) done. Loss: 0.0617  lr:0.015000\n"],"name":"stdout"},{"output_type":"stream","text":[" 28%|██▊       | 122/439 [04:27<11:31,  2.18s/it]"],"name":"stderr"},{"output_type":"stream","text":["[ Thu Aug  5 14:18:43 2021 ] \tBatch(121/439) done. Loss: 0.0282  lr:0.015000\n"],"name":"stdout"},{"output_type":"stream","text":[" 51%|█████     | 222/439 [08:05<07:52,  2.18s/it]"],"name":"stderr"},{"output_type":"stream","text":["[ Thu Aug  5 14:22:21 2021 ] \tBatch(221/439) done. Loss: 0.0070  lr:0.015000\n"],"name":"stdout"},{"output_type":"stream","text":[" 73%|███████▎  | 322/439 [11:43<04:15,  2.18s/it]"],"name":"stderr"},{"output_type":"stream","text":["[ Thu Aug  5 14:25:59 2021 ] \tBatch(321/439) done. Loss: 0.0107  lr:0.015000\n"],"name":"stdout"},{"output_type":"stream","text":[" 96%|█████████▌| 422/439 [15:21<00:37,  2.18s/it]"],"name":"stderr"},{"output_type":"stream","text":["[ Thu Aug  5 14:29:37 2021 ] \tBatch(421/439) done. Loss: 0.0058  lr:0.015000\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 439/439 [15:59<00:00,  2.19s/it]\n","  0%|          | 0/440 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["[ Thu Aug  5 14:30:15 2021 ] Eval epoch: 3\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 440/440 [07:44<00:00,  1.06s/it]\n"],"name":"stderr"},{"output_type":"stream","text":["Eval Accuracy:  0.9971572738255987  model:  ./save_models/sign_joint_final\n","[ Thu Aug  5 14:38:00 2021 ] \tMean test loss of 440 batches: 0.011403367854654789.\n","[ Thu Aug  5 14:38:01 2021 ] \tTop1: 99.72%\n","[ Thu Aug  5 14:38:01 2021 ] \tTop5: 100.00%\n"],"name":"stdout"},{"output_type":"stream","text":["\r  0%|          | 0/439 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["[ Thu Aug  5 14:38:01 2021 ] Training epoch: 4\n","only train part, require grad\n","l1.gcn1.DecoupleA-require grad\n","l2.gcn1.DecoupleA-require grad\n","l3.gcn1.DecoupleA-require grad\n","l4.gcn1.DecoupleA-require grad\n","l5.gcn1.DecoupleA-require grad\n","l6.gcn1.DecoupleA-require grad\n","l7.gcn1.DecoupleA-require grad\n","l8.gcn1.DecoupleA-require grad\n","l9.gcn1.DecoupleA-require grad\n","l10.gcn1.DecoupleA-require grad\n"],"name":"stdout"},{"output_type":"stream","text":[" 19%|█▉        | 83/439 [03:02<12:55,  2.18s/it]"],"name":"stderr"},{"output_type":"stream","text":["[ Thu Aug  5 14:41:04 2021 ] \tBatch(82/439) done. Loss: 0.0555  lr:0.020000\n"],"name":"stdout"},{"output_type":"stream","text":[" 42%|████▏     | 183/439 [06:41<09:19,  2.19s/it]"],"name":"stderr"},{"output_type":"stream","text":["[ Thu Aug  5 14:44:42 2021 ] \tBatch(182/439) done. Loss: 0.0292  lr:0.020000\n"],"name":"stdout"},{"output_type":"stream","text":[" 64%|██████▍   | 283/439 [10:19<05:40,  2.18s/it]"],"name":"stderr"},{"output_type":"stream","text":["[ Thu Aug  5 14:48:20 2021 ] \tBatch(282/439) done. Loss: 0.0826  lr:0.020000\n"],"name":"stdout"},{"output_type":"stream","text":[" 87%|████████▋ | 383/439 [13:57<02:02,  2.18s/it]"],"name":"stderr"},{"output_type":"stream","text":["[ Thu Aug  5 14:51:58 2021 ] \tBatch(382/439) done. Loss: 0.0255  lr:0.020000\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 439/439 [15:59<00:00,  2.19s/it]\n","  0%|          | 0/440 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["[ Thu Aug  5 14:54:01 2021 ] Eval epoch: 4\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 440/440 [07:44<00:00,  1.05s/it]\n"],"name":"stderr"},{"output_type":"stream","text":["Eval Accuracy:  0.9985786369127994  model:  ./save_models/sign_joint_final\n","[ Thu Aug  5 15:01:46 2021 ] \tMean test loss of 440 batches: 0.008795651607215405.\n","[ Thu Aug  5 15:01:46 2021 ] \tTop1: 99.86%\n","[ Thu Aug  5 15:01:47 2021 ] \tTop5: 100.00%\n"],"name":"stdout"},{"output_type":"stream","text":["\r  0%|          | 0/439 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["[ Thu Aug  5 15:01:47 2021 ] Training epoch: 5\n","only train part, require grad\n","l1.gcn1.DecoupleA-require grad\n","l2.gcn1.DecoupleA-require grad\n","l3.gcn1.DecoupleA-require grad\n","l4.gcn1.DecoupleA-require grad\n","l5.gcn1.DecoupleA-require grad\n","l6.gcn1.DecoupleA-require grad\n","l7.gcn1.DecoupleA-require grad\n","l8.gcn1.DecoupleA-require grad\n","l9.gcn1.DecoupleA-require grad\n","l10.gcn1.DecoupleA-require grad\n"],"name":"stdout"},{"output_type":"stream","text":[" 10%|█         | 44/439 [01:37<14:22,  2.18s/it]"],"name":"stderr"},{"output_type":"stream","text":["[ Thu Aug  5 15:03:25 2021 ] \tBatch(43/439) done. Loss: 0.0093  lr:0.025000\n"],"name":"stdout"},{"output_type":"stream","text":[" 33%|███▎      | 144/439 [05:15<10:44,  2.18s/it]"],"name":"stderr"},{"output_type":"stream","text":["[ Thu Aug  5 15:07:03 2021 ] \tBatch(143/439) done. Loss: 0.0245  lr:0.025000\n"],"name":"stdout"},{"output_type":"stream","text":[" 56%|█████▌    | 244/439 [08:53<07:05,  2.18s/it]"],"name":"stderr"},{"output_type":"stream","text":["[ Thu Aug  5 15:10:41 2021 ] \tBatch(243/439) done. Loss: 0.0616  lr:0.025000\n"],"name":"stdout"},{"output_type":"stream","text":[" 78%|███████▊  | 344/439 [12:31<03:27,  2.18s/it]"],"name":"stderr"},{"output_type":"stream","text":["[ Thu Aug  5 15:14:19 2021 ] \tBatch(343/439) done. Loss: 0.0079  lr:0.025000\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 439/439 [15:59<00:00,  2.19s/it]\n","  0%|          | 0/440 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["[ Thu Aug  5 15:17:47 2021 ] Eval epoch: 5\n"],"name":"stdout"},{"output_type":"stream","text":[" 45%|████▌     | 199/440 [03:30<04:13,  1.05s/it]"],"name":"stderr"},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-11-69f8114b0d65>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0minit_seed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprocessor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mProcessor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mprocessor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmagic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cd /content'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-7-1d77e7829680>\u001b[0m in \u001b[0;36mstart\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    342\u001b[0m                     \u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    343\u001b[0m                     \u001b[0msave_score\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_score\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 344\u001b[0;31m                     loader_name=['test'])\n\u001b[0m\u001b[1;32m    345\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    346\u001b[0m                 \u001b[0;31m# self.lr_scheduler.step(val_loss)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-7-1d77e7829680>\u001b[0m in \u001b[0;36meval\u001b[0;34m(self, epoch, save_score, loader_name, wrong_file, result_file)\u001b[0m\n\u001b[1;32m    283\u001b[0m                         \u001b[0ml1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    284\u001b[0m                     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 285\u001b[0;31m                     \u001b[0mscore_frag\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    286\u001b[0m                     \u001b[0mloss_value\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    287\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"markdown","metadata":{"id":"zPjAh6GBZIbE"},"source":["# To copy all the output files in /content/CVPR21Chal-SLR/SL-GCN/save_models"]},{"cell_type":"code","metadata":{"id":"RcmO5tC4l8Um"},"source":["import os, shutil\n","def copytree(src, dst, symlinks=False, ignore=None):\n","    for item in os.listdir(src):\n","        s = os.path.join(src, item)\n","        d = os.path.join(dst, item)\n","        if os.path.isdir(s):\n","            shutil.copytree(s, d, symlinks, ignore)\n","        else:\n","            shutil.copy2(s, d)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"EbVx4cA7mB6o"},"source":["copytree('/content/CVPR21Chal-SLR/SL-GCN/save_models','/content/drive/MyDrive/Colab Notebooks/CVPR21-Bh/train2/irdk')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Bv54___SZbuj"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"6yG9LjIiZbsH"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"_mSgvex9ZbpT"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"wCDh1Jf_ZcJJ"},"source":["# personal debugging"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":371},"id":"yMKfV6iLffRu","executionInfo":{"status":"error","timestamp":1627281887303,"user_tz":-360,"elapsed":474,"user":{"displayName":"Md.safirur Rashid, 170041020","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj4vsxiS6hdwcIxlWkCOlOKX6Yb9qvDnhTv0OE=s64","userId":"07083869211232678860"}},"outputId":"a40dcd18-4fda-4f02-9311-997d707d9c78"},"source":["parser = get_parser()\n","if p.config is not None:\n","    with open(p.config, 'r') as f:\n","        default_arg = yaml.load(f)\n","    key = vars(p).keys()\n","    for k in default_arg.keys():\n","        if k not in key:\n","            print('WRONG ARG: {}'.format(k))\n","            assert (k in key)\n","    parser.set_defaults(**default_arg)"],"execution_count":null,"outputs":[{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-19-872d6c31d352>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_parser\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0mdefault_arg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0myaml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvars\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-14-f5dd850b61c5>\u001b[0m in \u001b[0;36mget_parser\u001b[0;34m()\u001b[0m\n\u001b[1;32m     20\u001b[0m     parser.add_argument(\n\u001b[1;32m     21\u001b[0m         \u001b[0;34m'--save-score'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m         \u001b[0mtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstr2bool\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m         \u001b[0mdefault\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m         help='if ture, the classification score will be stored')\n","\u001b[0;31mNameError\u001b[0m: name 'str2bool' is not defined"]}]},{"cell_type":"code","metadata":{"id":"lCRaSluhffJA"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"15d7jyxaffBv"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"FxUs6Vxqfe-m"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"6WM2Lg6mrFoB"},"source":["p = Namespace(\n","    Experiment_name='', \n","    base_lr=0.01, \n","    batch_size=256, \n","    config='/content/CVPR21Chal-SLR/SL-GCN/config/sign/train/train_joint.yaml', \n","    device=0, \n","    eval_interval=5, \n","    feeder='feeder.feeder', \n","    groups=8, \n","    ignore_weights=[], \n","    keep_rate=0.9, \n","    log_interval=100, \n","    model=None, \n","    model_args={}, \n","    model_saved_name='', \n","    nesterov=False, \n","    num_epoch=80, \n","    num_worker=32, \n","    only_train_epoch=0, \n","    only_train_part=True, \n","    optimizer='SGD', \n","    phase='train', \n","    print_log=True, \n","    save_interval=2, \n","    save_score=False, \n","    seed=1, \n","    show_topk=[1, 5], \n","    start_epoch=0, \n","    step=[20, 40, 60], \n","    test_batch_size=256, \n","    test_feeder_args={}, \n","    train_feeder_args={}, \n","    warm_up_epoch=0, \n","    weight_decay=0.0005, \n","    weights=None, \n","    work_dir='./work_dir/temp')\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"q1VWvgZhOt_m"},"source":["Namespace(\n","    Experiment_name='sign_joint_final', \n","    base_lr=0.1, \n","    batch_size=64, \n","    config='/content/CVPR21Chal-SLR/SL-GCN/config/sign/train/train_joint.yaml', \n","    device=[0, 1, 2, 3], \n","    eval_interval=5, \n","    feeder='feeders.feeder.Feeder', \n","    groups=8, \n","    ignore_weights=[], \n","    keep_rate=0.9, \n","    log_interval=100, \n","    model='model.decouple_gcn_attn.Model', \n","    model_args={\n","        'num_class': 226, \n","        'num_point': 27, \n","        'num_person': 1, \n","        'graph': 'graph.sign_27.Graph', \n","        'groups': 16, \n","        'block_size': 41, \n","        'graph_args': {'labeling_mode': 'spatial'}\n","    }, \n","    model_saved_name='', \n","    nesterov=True, \n","    num_epoch=250, \n","    num_worker=32, \n","    only_train_epoch=1, \n","    only_train_part=True, \n","    optimizer='SGD', \n","    phase='train', \n","    print_log=True, \n","    save_interval=2, \n","    save_score=False, \n","    seed=1, \n","    show_topk=[1, 5], \n","    start_epoch=0, \n","    step=[150, 200], \n","    test_batch_size=64, \n","    test_feeder_args={\n","        'data_path': './data/sign/27_2/val_data_joint.npy', \n","        'label_path': './data/sign/27_2/val_gt.pkl', \n","        'random_mirror': False, \n","        'normalization': True\n","    }, \n","    train_feeder_args={\n","        'data_path': './data/sign/27_2/train_data_joint.npy', \n","        'label_path': './data/sign/27_2/train_label.pkl', \n","        'debug': False, \n","        'random_choose': True, \n","        'window_size': 100, \n","        'random_shift': True, \n","        'normalization': True, \n","        'random_mirror': True, \n","        'random_mirror_p': 0.5, \n","        'is_vector': False\n","    }, \n","    warm_up_epoch=20, \n","    weight_decay=0.0001, \n","    weights=None, \n","    work_dir='./work_dir/temp'\n",")\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"976xN7LflsHG"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"1Ge3F9MblsEH","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1627413338236,"user_tz":-360,"elapsed":8,"user":{"displayName":"Md.safirur Rashid, 170041020","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj4vsxiS6hdwcIxlWkCOlOKX6Yb9qvDnhTv0OE=s64","userId":"07083869211232678860"}},"outputId":"2a0e269b-be2b-4679-d473-b5166233c061"},"source":["!pwd"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/content/CVPR21Chal-SLR/SL-GCN\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pp1RNY2hls9q","executionInfo":{"status":"ok","timestamp":1627285719897,"user_tz":-360,"elapsed":393,"user":{"displayName":"Md.safirur Rashid, 170041020","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj4vsxiS6hdwcIxlWkCOlOKX6Yb9qvDnhTv0OE=s64","userId":"07083869211232678860"}},"outputId":"5254697f-994c-4822-b281-b0acaa0c3b51"},"source":["%cd /content/data/sign/27_2\n","!ls"],"execution_count":null,"outputs":[{"output_type":"stream","text":["[Errno 20] Not a directory: '/content/data/sign/27_2'\n","/content/drive/.shortcut-targets-by-id/1GhEIIcgxzMyFdfLihYOKuui9LUxm_E7T/copy_test_123\n","test_data_bone_motion.npy   test_label.pkl\t\t train_data_joint.npy\n","test_data_bone.npy\t    train_data_bone_motion.npy\t train_label.pkl\n","test_data_joint_motion.npy  train_data_bone.npy\n","test_data_joint.npy\t    train_data_joint_motion.npy\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"QCIi2P5vZzVl"},"source":[""],"execution_count":null,"outputs":[]}]}